“CUDA_VISIBLE_DEVICES=0”
/home/rth/jdekok/thesis_folder/nnunetv2/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-25 14:58:52.785994: do_dummy_2d_data_aug: True
2025-02-25 14:58:52.786691: Creating new 5-fold cross-validation split...
2025-02-25 14:58:52.788185: Desired fold for training: 0
2025-02-25 14:58:52.788244: This split has 62 training and 16 validation cases.
using pin_memory on device 0
/home/rth/jdekok/.conda/envs/nnunet_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-25 14:59:11.909459: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [16, 320, 320], 'median_image_size_in_voxels': [29.0, 521.0, 560.0], 'spacing': [4.400000095367432, 0.4296875, 0.4296875], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset520_NeckTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [4.400000095367432, 0.4296875, 0.4296875], 'original_median_shape_after_transp': [29, 521, 560], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 877.055419921875, 'mean': 105.18428802490234, 'median': 99.0, 'min': 4.0, 'percentile_00_5': 50.0, 'percentile_99_5': 538.07080078125, 'std': 51.62640380859375}, '1': {'max': 1496.849365234375, 'mean': 293.0503234863281, 'median': 285.0, 'min': 0.0, 'percentile_00_5': 106.0, 'percentile_99_5': 992.8849487304688, 'std': 102.57643127441406}, '2': {'max': 1193.1431884765625, 'mean': 91.38609313964844, 'median': 81.17990112304688, 'min': 0.3250216841697693, 'percentile_00_5': 18.39603614807129, 'percentile_99_5': 778.589599609375, 'std': 80.37003326416016}, '3': {'max': 709.135009765625, 'mean': 249.99417114257812, 'median': 252.59104919433594, 'min': 0.18024106323719025, 'percentile_00_5': 49.78506088256836, 'percentile_99_5': 438.50341796875, 'std': 66.26053619384766}, '4': {'max': 1877.02587890625, 'mean': 110.42361450195312, 'median': 38.046051025390625, 'min': 4.0235748291015625, 'percentile_00_5': 8.580612182617188, 'percentile_99_5': 690.7913208007812, 'std': 144.51866149902344}, '5': {'max': 4095.0, 'mean': 1535.79443359375, 'median': 1510.547119140625, 'min': 0.0, 'percentile_00_5': 8.739675649849232e-13, 'percentile_99_5': 3630.7978515625, 'std': 736.5648803710938}}} 

2025-02-25 14:59:16.607538: unpacking dataset...
2025-02-25 14:59:49.160513: unpacking done...
2025-02-25 14:59:49.172315: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-25 14:59:49.181542: 
2025-02-25 14:59:49.181647: Epoch 0
2025-02-25 14:59:49.181800: Current learning rate: 0.01
2025-02-25 15:01:44.211225: train_loss -0.2104
2025-02-25 15:01:44.218260: val_loss -0.524
2025-02-25 15:01:44.218544: Pseudo dice [0.6136]
2025-02-25 15:01:44.218642: Epoch time: 115.03 s
2025-02-25 15:01:44.218715: Yayy! New best EMA pseudo Dice: 0.6136
2025-02-25 15:01:45.837489: 
2025-02-25 15:01:45.837728: Epoch 1
2025-02-25 15:01:45.837857: Current learning rate: 0.00999
2025-02-25 15:03:20.703801: train_loss -0.3808
2025-02-25 15:03:20.704199: val_loss -0.5327
2025-02-25 15:03:20.704329: Pseudo dice [0.6253]
2025-02-25 15:03:20.704454: Epoch time: 94.87 s
2025-02-25 15:03:20.704559: Yayy! New best EMA pseudo Dice: 0.6148
2025-02-25 15:03:22.670066: 
2025-02-25 15:03:22.670303: Epoch 2
2025-02-25 15:03:22.670466: Current learning rate: 0.00998
2025-02-25 15:04:52.989435: train_loss -0.4397
2025-02-25 15:04:52.990041: val_loss -0.5867
2025-02-25 15:04:52.990145: Pseudo dice [0.6664]
2025-02-25 15:04:52.990271: Epoch time: 90.32 s
2025-02-25 15:04:52.999185: Yayy! New best EMA pseudo Dice: 0.62
2025-02-25 15:04:55.319655: 
2025-02-25 15:04:55.319975: Epoch 3
2025-02-25 15:04:55.320115: Current learning rate: 0.00997
2025-02-25 15:06:26.182633: train_loss -0.4215
2025-02-25 15:06:26.202742: val_loss -0.5935
2025-02-25 15:06:26.202850: Pseudo dice [0.6786]
2025-02-25 15:06:26.202961: Epoch time: 90.86 s
2025-02-25 15:06:26.203045: Yayy! New best EMA pseudo Dice: 0.6258
2025-02-25 15:06:28.259683: 
2025-02-25 15:06:28.259944: Epoch 4
2025-02-25 15:06:28.260071: Current learning rate: 0.00996
2025-02-25 15:08:02.810086: train_loss -0.4421
2025-02-25 15:08:02.810811: val_loss -0.5746
2025-02-25 15:08:02.810903: Pseudo dice [0.6792]
2025-02-25 15:08:02.811016: Epoch time: 94.55 s
2025-02-25 15:08:02.811089: Yayy! New best EMA pseudo Dice: 0.6312
2025-02-25 15:08:05.040229: 
2025-02-25 15:08:05.040496: Epoch 5
2025-02-25 15:08:05.040627: Current learning rate: 0.00995
2025-02-25 15:09:36.835954: train_loss -0.4656
2025-02-25 15:09:36.838363: val_loss -0.5826
2025-02-25 15:09:36.838523: Pseudo dice [0.6771]
2025-02-25 15:09:36.838637: Epoch time: 91.8 s
2025-02-25 15:09:36.838719: Yayy! New best EMA pseudo Dice: 0.6358
2025-02-25 15:09:38.840120: 
2025-02-25 15:09:38.840356: Epoch 6
2025-02-25 15:09:38.840486: Current learning rate: 0.00995
2025-02-25 15:11:11.704545: train_loss -0.4784
2025-02-25 15:11:11.705039: val_loss -0.6345
2025-02-25 15:11:11.705129: Pseudo dice [0.7188]
2025-02-25 15:11:11.705233: Epoch time: 92.87 s
2025-02-25 15:11:11.705323: Yayy! New best EMA pseudo Dice: 0.6441
2025-02-25 15:11:13.796249: 
2025-02-25 15:11:13.796536: Epoch 7
2025-02-25 15:11:13.796669: Current learning rate: 0.00994
2025-02-25 15:12:52.264364: train_loss -0.5084
2025-02-25 15:12:52.264783: val_loss -0.6399
2025-02-25 15:12:52.264872: Pseudo dice [0.7155]
2025-02-25 15:12:52.264978: Epoch time: 98.47 s
2025-02-25 15:12:52.265068: Yayy! New best EMA pseudo Dice: 0.6512
2025-02-25 15:12:54.416043: 
2025-02-25 15:12:54.416333: Epoch 8
2025-02-25 15:12:54.416481: Current learning rate: 0.00993
2025-02-25 15:14:30.817075: train_loss -0.5254
2025-02-25 15:14:30.817501: val_loss -0.6647
2025-02-25 15:14:30.817591: Pseudo dice [0.7364]
2025-02-25 15:14:30.817695: Epoch time: 96.4 s
2025-02-25 15:14:30.817772: Yayy! New best EMA pseudo Dice: 0.6597
2025-02-25 15:14:33.097273: 
2025-02-25 15:14:33.097513: Epoch 9
2025-02-25 15:14:33.097642: Current learning rate: 0.00992
2025-02-25 15:16:13.376998: train_loss -0.485
2025-02-25 15:16:13.377415: val_loss -0.6228
2025-02-25 15:16:13.377527: Pseudo dice [0.692]
2025-02-25 15:16:13.377634: Epoch time: 100.28 s
2025-02-25 15:16:13.377713: Yayy! New best EMA pseudo Dice: 0.6629
2025-02-25 15:16:15.513813: 
2025-02-25 15:16:15.514059: Epoch 10
2025-02-25 15:16:15.514193: Current learning rate: 0.00991
2025-02-25 15:17:52.468115: train_loss -0.5234
2025-02-25 15:17:52.468588: val_loss -0.6543
2025-02-25 15:17:52.468690: Pseudo dice [0.7339]
2025-02-25 15:17:52.468805: Epoch time: 96.96 s
2025-02-25 15:17:52.468891: Yayy! New best EMA pseudo Dice: 0.67
2025-02-25 15:17:55.275256: 
2025-02-25 15:17:55.275547: Epoch 11
2025-02-25 15:17:55.275680: Current learning rate: 0.0099
2025-02-25 15:19:32.835157: train_loss -0.5626
2025-02-25 15:19:32.835682: val_loss -0.6723
2025-02-25 15:19:32.835788: Pseudo dice [0.7442]
2025-02-25 15:19:32.835917: Epoch time: 97.56 s
2025-02-25 15:19:32.836016: Yayy! New best EMA pseudo Dice: 0.6775
2025-02-25 15:19:34.964336: 
2025-02-25 15:19:34.964570: Epoch 12
2025-02-25 15:19:34.964700: Current learning rate: 0.00989
2025-02-25 15:21:13.274871: train_loss -0.5534
2025-02-25 15:21:13.275331: val_loss -0.6317
2025-02-25 15:21:13.275428: Pseudo dice [0.7326]
2025-02-25 15:21:13.275537: Epoch time: 98.31 s
2025-02-25 15:21:13.275619: Yayy! New best EMA pseudo Dice: 0.683
2025-02-25 15:21:15.366355: 
2025-02-25 15:21:15.366639: Epoch 13
2025-02-25 15:21:15.366769: Current learning rate: 0.00988
2025-02-25 15:22:53.470803: train_loss -0.5753
2025-02-25 15:22:53.471200: val_loss -0.6604
2025-02-25 15:22:53.471327: Pseudo dice [0.7299]
2025-02-25 15:22:53.471446: Epoch time: 98.11 s
2025-02-25 15:22:53.471532: Yayy! New best EMA pseudo Dice: 0.6877
2025-02-25 15:22:55.795341: 
2025-02-25 15:22:55.795609: Epoch 14
2025-02-25 15:22:55.795740: Current learning rate: 0.00987
2025-02-25 15:24:34.664452: train_loss -0.5874
2025-02-25 15:24:34.664885: val_loss -0.6624
2025-02-25 15:24:34.664982: Pseudo dice [0.7343]
2025-02-25 15:24:34.665096: Epoch time: 98.87 s
2025-02-25 15:24:34.665189: Yayy! New best EMA pseudo Dice: 0.6923
2025-02-25 15:24:36.852855: 
2025-02-25 15:24:36.853098: Epoch 15
2025-02-25 15:24:36.853224: Current learning rate: 0.00986
2025-02-25 15:26:10.862968: train_loss -0.5833
2025-02-25 15:26:10.863541: val_loss -0.6727
2025-02-25 15:26:10.863640: Pseudo dice [0.74]
2025-02-25 15:26:10.863751: Epoch time: 94.01 s
2025-02-25 15:26:10.863834: Yayy! New best EMA pseudo Dice: 0.6971
2025-02-25 15:26:12.891082: 
2025-02-25 15:26:12.891309: Epoch 16
2025-02-25 15:26:12.891443: Current learning rate: 0.00986
2025-02-25 15:27:45.782263: train_loss -0.5788
2025-02-25 15:27:45.782601: val_loss -0.7045
2025-02-25 15:27:45.782691: Pseudo dice [0.759]
2025-02-25 15:27:45.782795: Epoch time: 92.89 s
2025-02-25 15:27:45.782873: Yayy! New best EMA pseudo Dice: 0.7033
2025-02-25 15:27:47.942505: 
2025-02-25 15:27:47.942771: Epoch 17
2025-02-25 15:27:47.942913: Current learning rate: 0.00985
2025-02-25 15:29:22.803116: train_loss -0.5929
2025-02-25 15:29:22.803526: val_loss -0.6681
2025-02-25 15:29:22.803621: Pseudo dice [0.7399]
2025-02-25 15:29:22.803727: Epoch time: 94.86 s
2025-02-25 15:29:22.803808: Yayy! New best EMA pseudo Dice: 0.7069
2025-02-25 15:29:24.898189: 
2025-02-25 15:29:24.898412: Epoch 18
2025-02-25 15:29:24.898544: Current learning rate: 0.00984
2025-02-25 15:31:00.872377: train_loss -0.5637
2025-02-25 15:31:00.872814: val_loss -0.6577
2025-02-25 15:31:00.872928: Pseudo dice [0.7308]
2025-02-25 15:31:00.873062: Epoch time: 95.98 s
2025-02-25 15:31:00.873153: Yayy! New best EMA pseudo Dice: 0.7093
2025-02-25 15:31:03.038712: 
2025-02-25 15:31:03.038985: Epoch 19
2025-02-25 15:31:03.039127: Current learning rate: 0.00983
2025-02-25 15:32:38.189821: train_loss -0.5954
2025-02-25 15:32:38.190271: val_loss -0.6957
2025-02-25 15:32:38.190382: Pseudo dice [0.7613]
2025-02-25 15:32:38.190488: Epoch time: 95.15 s
2025-02-25 15:32:38.190569: Yayy! New best EMA pseudo Dice: 0.7145
2025-02-25 15:32:40.325353: 
2025-02-25 15:32:40.325581: Epoch 20
2025-02-25 15:32:40.325721: Current learning rate: 0.00982
2025-02-25 15:34:12.120405: train_loss -0.5298
2025-02-25 15:34:12.120805: val_loss -0.6571
2025-02-25 15:34:12.120898: Pseudo dice [0.7395]
2025-02-25 15:34:12.121123: Epoch time: 91.8 s
2025-02-25 15:34:12.121213: Yayy! New best EMA pseudo Dice: 0.717
2025-02-25 15:34:14.339247: 
2025-02-25 15:34:14.339459: Epoch 21
2025-02-25 15:34:14.339592: Current learning rate: 0.00981
2025-02-25 15:35:47.688197: train_loss -0.5667
2025-02-25 15:35:47.688646: val_loss -0.6795
2025-02-25 15:35:47.688740: Pseudo dice [0.7505]
2025-02-25 15:35:47.688850: Epoch time: 93.35 s
2025-02-25 15:35:47.688938: Yayy! New best EMA pseudo Dice: 0.7204
2025-02-25 15:35:49.713137: 
2025-02-25 15:35:49.713395: Epoch 22
2025-02-25 15:35:49.713537: Current learning rate: 0.0098
2025-02-25 15:37:24.150233: train_loss -0.5883
2025-02-25 15:37:24.151065: val_loss -0.6981
2025-02-25 15:37:24.151181: Pseudo dice [0.7665]
2025-02-25 15:37:24.151394: Epoch time: 94.44 s
2025-02-25 15:37:24.151536: Yayy! New best EMA pseudo Dice: 0.725
2025-02-25 15:37:26.894138: 
2025-02-25 15:37:26.894392: Epoch 23
2025-02-25 15:37:26.894535: Current learning rate: 0.00979
2025-02-25 15:38:59.781540: train_loss -0.5994
2025-02-25 15:38:59.781997: val_loss -0.6903
2025-02-25 15:38:59.782092: Pseudo dice [0.761]
2025-02-25 15:38:59.782200: Epoch time: 92.89 s
2025-02-25 15:38:59.782280: Yayy! New best EMA pseudo Dice: 0.7286
2025-02-25 15:39:01.774522: 
2025-02-25 15:39:01.774758: Epoch 24
2025-02-25 15:39:01.774930: Current learning rate: 0.00978
2025-02-25 15:40:32.773972: train_loss -0.606
2025-02-25 15:40:32.774418: val_loss -0.692
2025-02-25 15:40:32.774513: Pseudo dice [0.7537]
2025-02-25 15:40:32.774617: Epoch time: 91.0 s
2025-02-25 15:40:32.774702: Yayy! New best EMA pseudo Dice: 0.7311
2025-02-25 15:40:34.809819: 
2025-02-25 15:40:34.810061: Epoch 25
2025-02-25 15:40:34.810190: Current learning rate: 0.00977
2025-02-25 15:42:00.676621: train_loss -0.6205
2025-02-25 15:42:00.677043: val_loss -0.6737
2025-02-25 15:42:00.677134: Pseudo dice [0.7459]
2025-02-25 15:42:00.677239: Epoch time: 85.87 s
2025-02-25 15:42:00.677334: Yayy! New best EMA pseudo Dice: 0.7326
2025-02-25 15:42:02.642737: 
2025-02-25 15:42:02.643003: Epoch 26
2025-02-25 15:42:02.643133: Current learning rate: 0.00977
2025-02-25 15:43:32.182930: train_loss -0.6082
2025-02-25 15:43:32.183362: val_loss -0.6974
2025-02-25 15:43:32.183467: Pseudo dice [0.7666]
2025-02-25 15:43:32.183574: Epoch time: 89.54 s
2025-02-25 15:43:32.183656: Yayy! New best EMA pseudo Dice: 0.736
2025-02-25 15:43:34.186772: 
2025-02-25 15:43:34.187010: Epoch 27
2025-02-25 15:43:34.187135: Current learning rate: 0.00976
2025-02-25 15:45:04.304841: train_loss -0.6385
2025-02-25 15:45:04.305280: val_loss -0.7113
2025-02-25 15:45:04.305391: Pseudo dice [0.7729]
2025-02-25 15:45:04.305491: Epoch time: 90.12 s
2025-02-25 15:45:04.305570: Yayy! New best EMA pseudo Dice: 0.7397
2025-02-25 15:45:06.397357: 
2025-02-25 15:45:06.397612: Epoch 28
2025-02-25 15:45:06.397837: Current learning rate: 0.00975
2025-02-25 15:46:37.132104: train_loss -0.6189
2025-02-25 15:46:37.132606: val_loss -0.6982
2025-02-25 15:46:37.132714: Pseudo dice [0.7609]
2025-02-25 15:46:37.132832: Epoch time: 90.74 s
2025-02-25 15:46:37.132922: Yayy! New best EMA pseudo Dice: 0.7418
2025-02-25 15:46:39.187162: 
2025-02-25 15:46:39.187385: Epoch 29
2025-02-25 15:46:39.187558: Current learning rate: 0.00974
2025-02-25 15:48:11.978377: train_loss -0.6132
2025-02-25 15:48:11.979136: val_loss -0.6888
2025-02-25 15:48:11.979249: Pseudo dice [0.7602]
2025-02-25 15:48:11.979377: Epoch time: 92.79 s
2025-02-25 15:48:11.979472: Yayy! New best EMA pseudo Dice: 0.7436
2025-02-25 15:48:14.059331: 
2025-02-25 15:48:14.059561: Epoch 30
2025-02-25 15:48:14.059715: Current learning rate: 0.00973
2025-02-25 15:49:49.194942: train_loss -0.602
2025-02-25 15:49:49.195400: val_loss -0.6699
2025-02-25 15:49:49.195486: Pseudo dice [0.7495]
2025-02-25 15:49:49.195587: Epoch time: 95.14 s
2025-02-25 15:49:49.195655: Yayy! New best EMA pseudo Dice: 0.7442
2025-02-25 15:49:51.198014: 
2025-02-25 15:49:51.198239: Epoch 31
2025-02-25 15:49:51.198381: Current learning rate: 0.00972
2025-02-25 15:51:27.328389: train_loss -0.6169
2025-02-25 15:51:27.328803: val_loss -0.6984
2025-02-25 15:51:27.328894: Pseudo dice [0.7696]
2025-02-25 15:51:27.329001: Epoch time: 96.13 s
2025-02-25 15:51:27.329082: Yayy! New best EMA pseudo Dice: 0.7468
2025-02-25 15:51:29.360699: 
2025-02-25 15:51:29.360952: Epoch 32
2025-02-25 15:51:29.361079: Current learning rate: 0.00971
2025-02-25 15:53:03.234056: train_loss -0.6302
2025-02-25 15:53:03.234463: val_loss -0.6778
2025-02-25 15:53:03.234549: Pseudo dice [0.7486]
2025-02-25 15:53:03.234647: Epoch time: 93.87 s
2025-02-25 15:53:03.234719: Yayy! New best EMA pseudo Dice: 0.7469
2025-02-25 15:53:05.378835: 
2025-02-25 15:53:05.379027: Epoch 33
2025-02-25 15:53:05.379155: Current learning rate: 0.0097
2025-02-25 15:54:29.498322: train_loss -0.6248
2025-02-25 15:54:29.498769: val_loss -0.6959
2025-02-25 15:54:29.498861: Pseudo dice [0.7716]
2025-02-25 15:54:29.498972: Epoch time: 84.12 s
2025-02-25 15:54:29.499056: Yayy! New best EMA pseudo Dice: 0.7494
2025-02-25 15:54:31.960319: 
2025-02-25 15:54:31.960545: Epoch 34
2025-02-25 15:54:31.960677: Current learning rate: 0.00969
2025-02-25 15:55:57.079834: train_loss -0.614
2025-02-25 15:55:57.080250: val_loss -0.734
2025-02-25 15:55:57.080372: Pseudo dice [0.7995]
2025-02-25 15:55:57.080482: Epoch time: 85.12 s
2025-02-25 15:55:57.080566: Yayy! New best EMA pseudo Dice: 0.7544
2025-02-25 15:55:59.050431: 
2025-02-25 15:55:59.050680: Epoch 35
2025-02-25 15:55:59.050825: Current learning rate: 0.00968
2025-02-25 15:57:27.410122: train_loss -0.5951
2025-02-25 15:57:27.410540: val_loss -0.6939
2025-02-25 15:57:27.410633: Pseudo dice [0.7639]
2025-02-25 15:57:27.410737: Epoch time: 88.36 s
2025-02-25 15:57:27.410814: Yayy! New best EMA pseudo Dice: 0.7554
2025-02-25 15:57:29.370366: 
2025-02-25 15:57:29.370670: Epoch 36
2025-02-25 15:57:29.370804: Current learning rate: 0.00968
2025-02-25 15:58:52.342538: train_loss -0.6229
2025-02-25 15:58:52.342948: val_loss -0.7234
2025-02-25 15:58:52.343041: Pseudo dice [0.7818]
2025-02-25 15:58:52.343141: Epoch time: 82.97 s
2025-02-25 15:58:52.343220: Yayy! New best EMA pseudo Dice: 0.758
2025-02-25 15:58:54.332933: 
2025-02-25 15:58:54.333160: Epoch 37
2025-02-25 15:58:54.333284: Current learning rate: 0.00967
2025-02-25 16:00:18.884219: train_loss -0.6366
2025-02-25 16:00:18.884662: val_loss -0.6817
2025-02-25 16:00:18.884746: Pseudo dice [0.764]
2025-02-25 16:00:18.884845: Epoch time: 84.55 s
2025-02-25 16:00:18.884927: Yayy! New best EMA pseudo Dice: 0.7586
2025-02-25 16:00:20.890788: 
2025-02-25 16:00:20.891029: Epoch 38
2025-02-25 16:00:20.891151: Current learning rate: 0.00966
2025-02-25 16:01:47.943459: train_loss -0.652
2025-02-25 16:01:47.943916: val_loss -0.7174
2025-02-25 16:01:47.944012: Pseudo dice [0.7799]
2025-02-25 16:01:47.944121: Epoch time: 87.05 s
2025-02-25 16:01:47.944200: Yayy! New best EMA pseudo Dice: 0.7608
2025-02-25 16:01:49.988200: 
2025-02-25 16:01:49.988454: Epoch 39
2025-02-25 16:01:49.988579: Current learning rate: 0.00965
2025-02-25 16:03:17.205405: train_loss -0.641
2025-02-25 16:03:17.205858: val_loss -0.7037
2025-02-25 16:03:17.205970: Pseudo dice [0.7656]
2025-02-25 16:03:17.206091: Epoch time: 87.22 s
2025-02-25 16:03:17.206179: Yayy! New best EMA pseudo Dice: 0.7612
2025-02-25 16:03:19.295814: 
2025-02-25 16:03:19.296033: Epoch 40
2025-02-25 16:03:19.296156: Current learning rate: 0.00964
2025-02-25 16:04:43.375967: train_loss -0.6517
2025-02-25 16:04:43.376420: val_loss -0.7211
2025-02-25 16:04:43.376515: Pseudo dice [0.7808]
2025-02-25 16:04:43.376627: Epoch time: 84.08 s
2025-02-25 16:04:43.376707: Yayy! New best EMA pseudo Dice: 0.7632
2025-02-25 16:04:45.485840: 
2025-02-25 16:04:45.486072: Epoch 41
2025-02-25 16:04:45.486248: Current learning rate: 0.00963
2025-02-25 16:06:10.967991: train_loss -0.651
2025-02-25 16:06:10.968360: val_loss -0.7207
2025-02-25 16:06:10.968440: Pseudo dice [0.777]
2025-02-25 16:06:10.968533: Epoch time: 85.48 s
2025-02-25 16:06:10.968600: Yayy! New best EMA pseudo Dice: 0.7646
2025-02-25 16:06:13.005113: 
2025-02-25 16:06:13.005355: Epoch 42
2025-02-25 16:06:13.005482: Current learning rate: 0.00962
2025-02-25 16:07:41.849561: train_loss -0.6854
2025-02-25 16:07:41.860693: val_loss -0.7304
2025-02-25 16:07:41.860922: Pseudo dice [0.7893]
2025-02-25 16:07:41.861039: Epoch time: 88.85 s
2025-02-25 16:07:41.861528: Yayy! New best EMA pseudo Dice: 0.7671
2025-02-25 16:07:43.948995: 
2025-02-25 16:07:43.949224: Epoch 43
2025-02-25 16:07:43.949388: Current learning rate: 0.00961
2025-02-25 16:09:14.607038: train_loss -0.6448
2025-02-25 16:09:14.607545: val_loss -0.7178
2025-02-25 16:09:14.607653: Pseudo dice [0.7737]
2025-02-25 16:09:14.607780: Epoch time: 90.66 s
2025-02-25 16:09:14.607875: Yayy! New best EMA pseudo Dice: 0.7677
2025-02-25 16:09:16.765818: 
2025-02-25 16:09:16.766042: Epoch 44
2025-02-25 16:09:16.766174: Current learning rate: 0.0096
2025-02-25 16:10:49.225893: train_loss -0.6581
2025-02-25 16:10:49.226263: val_loss -0.6914
2025-02-25 16:10:49.226370: Pseudo dice [0.7572]
2025-02-25 16:10:49.226475: Epoch time: 92.46 s
2025-02-25 16:10:51.281549: 
2025-02-25 16:10:51.281766: Epoch 45
2025-02-25 16:10:51.281898: Current learning rate: 0.00959
2025-02-25 16:12:18.803385: train_loss -0.6471
2025-02-25 16:12:18.803802: val_loss -0.7009
2025-02-25 16:12:18.803897: Pseudo dice [0.7662]
2025-02-25 16:12:18.804009: Epoch time: 87.52 s
2025-02-25 16:12:20.292831: 
2025-02-25 16:12:20.293105: Epoch 46
2025-02-25 16:12:20.293233: Current learning rate: 0.00959
2025-02-25 16:13:48.984986: train_loss -0.6463
2025-02-25 16:13:48.985436: val_loss -0.6866
2025-02-25 16:13:48.985533: Pseudo dice [0.7605]
2025-02-25 16:13:48.985642: Epoch time: 88.69 s
2025-02-25 16:13:50.394899: 
2025-02-25 16:13:50.395175: Epoch 47
2025-02-25 16:13:50.395316: Current learning rate: 0.00958
2025-02-25 16:15:14.278661: train_loss -0.6271
2025-02-25 16:15:14.279136: val_loss -0.6971
2025-02-25 16:15:14.279233: Pseudo dice [0.7613]
2025-02-25 16:15:14.279358: Epoch time: 83.89 s
2025-02-25 16:15:15.598104: 
2025-02-25 16:15:15.598358: Epoch 48
2025-02-25 16:15:15.598491: Current learning rate: 0.00957
2025-02-25 16:16:50.493270: train_loss -0.6489
2025-02-25 16:16:50.493695: val_loss -0.7216
2025-02-25 16:16:50.493785: Pseudo dice [0.7815]
2025-02-25 16:16:50.493887: Epoch time: 94.9 s
2025-02-25 16:16:52.145025: 
2025-02-25 16:16:52.145267: Epoch 49
2025-02-25 16:16:52.145413: Current learning rate: 0.00956
2025-02-25 16:18:21.315475: train_loss -0.6724
2025-02-25 16:18:21.315998: val_loss -0.7183
2025-02-25 16:18:21.316094: Pseudo dice [0.7821]
2025-02-25 16:18:21.316204: Epoch time: 89.17 s
2025-02-25 16:18:21.909653: Yayy! New best EMA pseudo Dice: 0.7686
2025-02-25 16:18:23.719743: 
2025-02-25 16:18:23.720004: Epoch 50
2025-02-25 16:18:23.720163: Current learning rate: 0.00955
2025-02-25 16:19:49.466502: train_loss -0.6605
2025-02-25 16:19:49.466960: val_loss -0.7229
2025-02-25 16:19:49.467051: Pseudo dice [0.7887]
2025-02-25 16:19:49.467175: Epoch time: 85.75 s
2025-02-25 16:19:49.467262: Yayy! New best EMA pseudo Dice: 0.7706
2025-02-25 16:19:51.588826: 
2025-02-25 16:19:51.589073: Epoch 51
2025-02-25 16:19:51.589212: Current learning rate: 0.00954
2025-02-25 16:21:14.794718: train_loss -0.6591
2025-02-25 16:21:14.795227: val_loss -0.7125
2025-02-25 16:21:14.795343: Pseudo dice [0.7719]
2025-02-25 16:21:14.795454: Epoch time: 83.21 s
2025-02-25 16:21:14.795532: Yayy! New best EMA pseudo Dice: 0.7708
2025-02-25 16:21:16.722142: 
2025-02-25 16:21:16.722380: Epoch 52
2025-02-25 16:21:16.722508: Current learning rate: 0.00953
2025-02-25 16:22:37.535470: train_loss -0.6602
2025-02-25 16:22:37.535935: val_loss -0.7146
2025-02-25 16:22:37.536031: Pseudo dice [0.7709]
2025-02-25 16:22:37.536155: Epoch time: 80.81 s
2025-02-25 16:22:37.536240: Yayy! New best EMA pseudo Dice: 0.7708
2025-02-25 16:22:39.598155: 
2025-02-25 16:22:39.598440: Epoch 53
2025-02-25 16:22:39.598568: Current learning rate: 0.00952
2025-02-25 16:24:03.995230: train_loss -0.6459
2025-02-25 16:24:03.995632: val_loss -0.7135
2025-02-25 16:24:03.995737: Pseudo dice [0.7802]
2025-02-25 16:24:03.995852: Epoch time: 84.4 s
2025-02-25 16:24:03.995949: Yayy! New best EMA pseudo Dice: 0.7717
2025-02-25 16:24:06.020874: 
2025-02-25 16:24:06.021082: Epoch 54
2025-02-25 16:24:06.021204: Current learning rate: 0.00951
2025-02-25 16:25:39.489500: train_loss -0.6688
2025-02-25 16:25:39.489949: val_loss -0.711
2025-02-25 16:25:39.490043: Pseudo dice [0.7643]
2025-02-25 16:25:39.490147: Epoch time: 93.47 s
2025-02-25 16:25:40.922997: 
2025-02-25 16:25:40.923223: Epoch 55
2025-02-25 16:25:40.923417: Current learning rate: 0.0095
2025-02-25 16:27:12.296811: train_loss -0.6514
2025-02-25 16:27:12.297263: val_loss -0.6998
2025-02-25 16:27:12.297362: Pseudo dice [0.77]
2025-02-25 16:27:12.297476: Epoch time: 91.38 s
2025-02-25 16:27:13.789032: 
2025-02-25 16:27:13.789247: Epoch 56
2025-02-25 16:27:13.789393: Current learning rate: 0.00949
2025-02-25 16:28:46.945020: train_loss -0.6767
2025-02-25 16:28:46.945462: val_loss -0.7268
2025-02-25 16:28:46.945557: Pseudo dice [0.783]
2025-02-25 16:28:46.945665: Epoch time: 93.16 s
2025-02-25 16:28:46.945746: Yayy! New best EMA pseudo Dice: 0.7721
2025-02-25 16:28:49.602033: 
2025-02-25 16:28:49.602314: Epoch 57
2025-02-25 16:28:49.602445: Current learning rate: 0.00949
2025-02-25 16:30:21.366018: train_loss -0.6834
2025-02-25 16:30:21.366576: val_loss -0.7262
2025-02-25 16:30:21.366717: Pseudo dice [0.7786]
2025-02-25 16:30:21.366847: Epoch time: 91.77 s
2025-02-25 16:30:21.366934: Yayy! New best EMA pseudo Dice: 0.7727
2025-02-25 16:30:23.390418: 
2025-02-25 16:30:23.390669: Epoch 58
2025-02-25 16:30:23.390799: Current learning rate: 0.00948
2025-02-25 16:31:56.397791: train_loss -0.6918
2025-02-25 16:31:56.398203: val_loss -0.7216
2025-02-25 16:31:56.398293: Pseudo dice [0.7812]
2025-02-25 16:31:56.398418: Epoch time: 93.01 s
2025-02-25 16:31:56.398500: Yayy! New best EMA pseudo Dice: 0.7736
2025-02-25 16:31:58.481689: 
2025-02-25 16:31:58.481936: Epoch 59
2025-02-25 16:31:58.482072: Current learning rate: 0.00947
2025-02-25 16:33:29.666436: train_loss -0.6947
2025-02-25 16:33:29.666902: val_loss -0.7259
2025-02-25 16:33:29.666996: Pseudo dice [0.7821]
2025-02-25 16:33:29.667104: Epoch time: 91.19 s
2025-02-25 16:33:29.667183: Yayy! New best EMA pseudo Dice: 0.7744
2025-02-25 16:33:31.772937: 
2025-02-25 16:33:31.773246: Epoch 60
2025-02-25 16:33:31.773399: Current learning rate: 0.00946
2025-02-25 16:35:04.199696: train_loss -0.6743
2025-02-25 16:35:04.200157: val_loss -0.7236
2025-02-25 16:35:04.200255: Pseudo dice [0.778]
2025-02-25 16:35:04.200390: Epoch time: 92.43 s
2025-02-25 16:35:04.200475: Yayy! New best EMA pseudo Dice: 0.7748
2025-02-25 16:35:06.349233: 
2025-02-25 16:35:06.349557: Epoch 61
2025-02-25 16:35:06.349695: Current learning rate: 0.00945
2025-02-25 16:36:43.672743: train_loss -0.6933
2025-02-25 16:36:43.673180: val_loss -0.7285
2025-02-25 16:36:43.673271: Pseudo dice [0.7914]
2025-02-25 16:36:43.673400: Epoch time: 97.32 s
2025-02-25 16:36:43.673481: Yayy! New best EMA pseudo Dice: 0.7765
2025-02-25 16:36:45.750190: 
2025-02-25 16:36:45.750443: Epoch 62
2025-02-25 16:36:45.750574: Current learning rate: 0.00944
2025-02-25 16:38:20.848813: train_loss -0.6751
2025-02-25 16:38:20.849372: val_loss -0.6882
2025-02-25 16:38:20.849483: Pseudo dice [0.738]
2025-02-25 16:38:20.849614: Epoch time: 95.1 s
2025-02-25 16:38:22.303963: 
2025-02-25 16:38:22.304206: Epoch 63
2025-02-25 16:38:22.304362: Current learning rate: 0.00943
2025-02-25 16:39:57.285855: train_loss -0.6589
2025-02-25 16:39:57.286287: val_loss -0.7028
2025-02-25 16:39:57.286397: Pseudo dice [0.7632]
2025-02-25 16:39:57.286524: Epoch time: 94.98 s
2025-02-25 16:39:58.890131: 
2025-02-25 16:39:58.890405: Epoch 64
2025-02-25 16:39:58.890592: Current learning rate: 0.00942
2025-02-25 16:41:27.466419: train_loss -0.6782
2025-02-25 16:41:27.466841: val_loss -0.7002
2025-02-25 16:41:27.466930: Pseudo dice [0.773]
2025-02-25 16:41:27.467029: Epoch time: 88.58 s
2025-02-25 16:41:28.982702: 
2025-02-25 16:41:28.982931: Epoch 65
2025-02-25 16:41:28.983059: Current learning rate: 0.00941
2025-02-25 16:43:00.612488: train_loss -0.6634
2025-02-25 16:43:00.612993: val_loss -0.7201
2025-02-25 16:43:00.613095: Pseudo dice [0.7824]
2025-02-25 16:43:00.613215: Epoch time: 91.63 s
2025-02-25 16:43:02.204242: 
2025-02-25 16:43:02.204478: Epoch 66
2025-02-25 16:43:02.204931: Current learning rate: 0.0094
2025-02-25 16:44:36.747943: train_loss -0.6725
2025-02-25 16:44:36.748420: val_loss -0.7141
2025-02-25 16:44:36.748534: Pseudo dice [0.7682]
2025-02-25 16:44:36.748645: Epoch time: 94.55 s
2025-02-25 16:44:38.259139: 
2025-02-25 16:44:38.259419: Epoch 67
2025-02-25 16:44:38.259552: Current learning rate: 0.00939
2025-02-25 16:46:13.570814: train_loss -0.6825
2025-02-25 16:46:13.571237: val_loss -0.7244
2025-02-25 16:46:13.571339: Pseudo dice [0.7803]
2025-02-25 16:46:13.571453: Epoch time: 95.31 s
2025-02-25 16:46:15.124026: 
2025-02-25 16:46:15.124258: Epoch 68
2025-02-25 16:46:15.124399: Current learning rate: 0.00939
2025-02-25 16:47:51.725069: train_loss -0.6742
2025-02-25 16:47:51.725540: val_loss -0.726
2025-02-25 16:47:51.725645: Pseudo dice [0.7889]
2025-02-25 16:47:51.725768: Epoch time: 96.6 s
2025-02-25 16:47:53.909429: 
2025-02-25 16:47:53.909699: Epoch 69
2025-02-25 16:47:53.909834: Current learning rate: 0.00938
2025-02-25 16:49:32.141133: train_loss -0.6672
2025-02-25 16:49:32.141644: val_loss -0.7024
2025-02-25 16:49:32.142086: Pseudo dice [0.7675]
2025-02-25 16:49:32.142232: Epoch time: 98.23 s
2025-02-25 16:49:33.546244: 
2025-02-25 16:49:33.546506: Epoch 70
2025-02-25 16:49:33.546640: Current learning rate: 0.00937
2025-02-25 16:51:07.732231: train_loss -0.6604
2025-02-25 16:51:07.732732: val_loss -0.7419
2025-02-25 16:51:07.732832: Pseudo dice [0.7897]
2025-02-25 16:51:07.732952: Epoch time: 94.19 s
2025-02-25 16:51:09.308074: 
2025-02-25 16:51:09.308347: Epoch 71
2025-02-25 16:51:09.308489: Current learning rate: 0.00936
2025-02-25 16:52:43.384753: train_loss -0.7002
2025-02-25 16:52:43.385169: val_loss -0.7304
2025-02-25 16:52:43.385262: Pseudo dice [0.7896]
2025-02-25 16:52:43.385387: Epoch time: 94.08 s
2025-02-25 16:52:43.385476: Yayy! New best EMA pseudo Dice: 0.777
2025-02-25 16:52:45.478055: 
2025-02-25 16:52:45.478351: Epoch 72
2025-02-25 16:52:45.478493: Current learning rate: 0.00935
2025-02-25 16:54:18.968229: train_loss -0.6807
2025-02-25 16:54:18.968658: val_loss -0.7358
2025-02-25 16:54:18.968746: Pseudo dice [0.7867]
2025-02-25 16:54:18.968850: Epoch time: 93.49 s
2025-02-25 16:54:18.968934: Yayy! New best EMA pseudo Dice: 0.778
2025-02-25 16:54:21.192095: 
2025-02-25 16:54:21.192381: Epoch 73
2025-02-25 16:54:21.192517: Current learning rate: 0.00934
2025-02-25 16:55:56.051528: train_loss -0.6712
2025-02-25 16:55:56.051959: val_loss -0.7273
2025-02-25 16:55:56.052048: Pseudo dice [0.79]
2025-02-25 16:55:56.052203: Epoch time: 94.86 s
2025-02-25 16:55:56.052311: Yayy! New best EMA pseudo Dice: 0.7792
2025-02-25 16:55:58.139637: 
2025-02-25 16:55:58.139895: Epoch 74
2025-02-25 16:55:58.140024: Current learning rate: 0.00933
2025-02-25 16:57:35.831863: train_loss -0.6811
2025-02-25 16:57:35.832358: val_loss -0.7361
2025-02-25 16:57:35.832496: Pseudo dice [0.792]
2025-02-25 16:57:35.832627: Epoch time: 97.69 s
2025-02-25 16:57:35.832716: Yayy! New best EMA pseudo Dice: 0.7804
2025-02-25 16:57:38.112478: 
2025-02-25 16:57:38.112708: Epoch 75
2025-02-25 16:57:38.112833: Current learning rate: 0.00932
2025-02-25 16:59:13.472859: train_loss -0.7061
2025-02-25 16:59:13.473253: val_loss -0.7099
2025-02-25 16:59:13.473361: Pseudo dice [0.7672]
2025-02-25 16:59:13.473488: Epoch time: 95.36 s
2025-02-25 16:59:15.035173: 
2025-02-25 16:59:15.035408: Epoch 76
2025-02-25 16:59:15.035536: Current learning rate: 0.00931
2025-02-25 17:00:51.186449: train_loss -0.6718
2025-02-25 17:00:51.186854: val_loss -0.7363
2025-02-25 17:00:51.186943: Pseudo dice [0.7949]
2025-02-25 17:00:51.187042: Epoch time: 96.15 s
2025-02-25 17:00:51.187125: Yayy! New best EMA pseudo Dice: 0.7807
2025-02-25 17:00:53.365546: 
2025-02-25 17:00:53.365767: Epoch 77
2025-02-25 17:00:53.365933: Current learning rate: 0.0093
2025-02-25 17:02:25.796828: train_loss -0.6909
2025-02-25 17:02:25.797254: val_loss -0.6894
2025-02-25 17:02:25.797362: Pseudo dice [0.7547]
2025-02-25 17:02:25.797470: Epoch time: 92.43 s
2025-02-25 17:02:27.417577: 
2025-02-25 17:02:27.417833: Epoch 78
2025-02-25 17:02:27.417961: Current learning rate: 0.0093
2025-02-25 17:04:01.059961: train_loss -0.692
2025-02-25 17:04:01.060391: val_loss -0.7308
2025-02-25 17:04:01.060489: Pseudo dice [0.7828]
2025-02-25 17:04:01.060595: Epoch time: 93.64 s
2025-02-25 17:04:02.686164: 
2025-02-25 17:04:02.686437: Epoch 79
2025-02-25 17:04:02.686563: Current learning rate: 0.00929
2025-02-25 17:05:34.808322: train_loss -0.6958
2025-02-25 17:05:34.808739: val_loss -0.7384
2025-02-25 17:05:34.808824: Pseudo dice [0.7931]
2025-02-25 17:05:34.808928: Epoch time: 92.12 s
2025-02-25 17:05:36.876381: 
2025-02-25 17:05:36.876698: Epoch 80
2025-02-25 17:05:36.876850: Current learning rate: 0.00928
2025-02-25 17:07:03.699554: train_loss -0.7087
2025-02-25 17:07:03.699961: val_loss -0.7521
2025-02-25 17:07:03.700052: Pseudo dice [0.7905]
2025-02-25 17:07:03.700156: Epoch time: 86.82 s
2025-02-25 17:07:03.700234: Yayy! New best EMA pseudo Dice: 0.7811
2025-02-25 17:07:05.764734: 
2025-02-25 17:07:05.765013: Epoch 81
2025-02-25 17:07:05.765154: Current learning rate: 0.00927
2025-02-25 17:08:33.772982: train_loss -0.6945
2025-02-25 17:08:33.773382: val_loss -0.7219
2025-02-25 17:08:33.773479: Pseudo dice [0.7844]
2025-02-25 17:08:33.773582: Epoch time: 88.01 s
2025-02-25 17:08:33.773660: Yayy! New best EMA pseudo Dice: 0.7814
2025-02-25 17:08:35.884582: 
2025-02-25 17:08:35.884852: Epoch 82
2025-02-25 17:08:35.884979: Current learning rate: 0.00926
2025-02-25 17:10:05.048608: train_loss -0.7056
2025-02-25 17:10:05.049016: val_loss -0.7198
2025-02-25 17:10:05.049121: Pseudo dice [0.7735]
2025-02-25 17:10:05.049241: Epoch time: 89.17 s
2025-02-25 17:10:06.437122: 
2025-02-25 17:10:06.437406: Epoch 83
2025-02-25 17:10:06.437547: Current learning rate: 0.00925
2025-02-25 17:11:25.912823: train_loss -0.6971
2025-02-25 17:11:25.913176: val_loss -0.7373
2025-02-25 17:11:25.913265: Pseudo dice [0.7922]
2025-02-25 17:11:25.913388: Epoch time: 79.48 s
2025-02-25 17:11:25.913467: Yayy! New best EMA pseudo Dice: 0.7818
2025-02-25 17:11:27.823369: 
2025-02-25 17:11:27.823702: Epoch 84
2025-02-25 17:11:27.823843: Current learning rate: 0.00924
2025-02-25 17:12:50.647341: train_loss -0.7055
2025-02-25 17:12:50.647777: val_loss -0.7387
2025-02-25 17:12:50.647876: Pseudo dice [0.7833]
2025-02-25 17:12:50.647983: Epoch time: 82.83 s
2025-02-25 17:12:50.648066: Yayy! New best EMA pseudo Dice: 0.7819
2025-02-25 17:12:52.667652: 
2025-02-25 17:12:52.667922: Epoch 85
2025-02-25 17:12:52.668070: Current learning rate: 0.00923
2025-02-25 17:14:17.275061: train_loss -0.7119
2025-02-25 17:14:17.275489: val_loss -0.7286
2025-02-25 17:14:17.275578: Pseudo dice [0.7911]
2025-02-25 17:14:17.275680: Epoch time: 84.61 s
2025-02-25 17:14:17.275758: Yayy! New best EMA pseudo Dice: 0.7828
2025-02-25 17:14:19.255076: 
2025-02-25 17:14:19.255313: Epoch 86
2025-02-25 17:14:19.255457: Current learning rate: 0.00922
2025-02-25 17:15:43.784717: train_loss -0.7159
2025-02-25 17:15:43.785072: val_loss -0.736
2025-02-25 17:15:43.785336: Pseudo dice [0.7835]
2025-02-25 17:15:43.785456: Epoch time: 84.53 s
2025-02-25 17:15:43.785796: Yayy! New best EMA pseudo Dice: 0.7829
2025-02-25 17:15:45.700401: 
2025-02-25 17:15:45.700682: Epoch 87
2025-02-25 17:15:45.700854: Current learning rate: 0.00921
2025-02-25 17:17:12.521908: train_loss -0.7068
2025-02-25 17:17:12.522650: val_loss -0.7345
2025-02-25 17:17:12.522774: Pseudo dice [0.7846]
2025-02-25 17:17:12.522882: Epoch time: 86.82 s
2025-02-25 17:17:12.523003: Yayy! New best EMA pseudo Dice: 0.7831
2025-02-25 17:17:14.554916: 
2025-02-25 17:17:14.555145: Epoch 88
2025-02-25 17:17:14.555276: Current learning rate: 0.0092
2025-02-25 17:18:40.452215: train_loss -0.7061
2025-02-25 17:18:40.452635: val_loss -0.7235
2025-02-25 17:18:40.452727: Pseudo dice [0.7789]
2025-02-25 17:18:40.452831: Epoch time: 85.9 s
2025-02-25 17:18:41.874995: 
2025-02-25 17:18:41.875196: Epoch 89
2025-02-25 17:18:41.875334: Current learning rate: 0.0092
2025-02-25 17:20:08.562264: train_loss -0.716
2025-02-25 17:20:08.562689: val_loss -0.7298
2025-02-25 17:20:08.562779: Pseudo dice [0.7881]
2025-02-25 17:20:08.563291: Epoch time: 86.69 s
2025-02-25 17:20:08.563403: Yayy! New best EMA pseudo Dice: 0.7832
2025-02-25 17:20:10.590888: 
2025-02-25 17:20:10.591118: Epoch 90
2025-02-25 17:20:10.591247: Current learning rate: 0.00919
2025-02-25 17:21:37.757944: train_loss -0.7126
2025-02-25 17:21:37.758373: val_loss -0.7525
2025-02-25 17:21:37.758472: Pseudo dice [0.8]
2025-02-25 17:21:37.758580: Epoch time: 87.17 s
2025-02-25 17:21:37.758660: Yayy! New best EMA pseudo Dice: 0.7849
2025-02-25 17:21:39.745229: 
2025-02-25 17:21:39.745525: Epoch 91
2025-02-25 17:21:39.745656: Current learning rate: 0.00918
2025-02-25 17:23:06.770045: train_loss -0.7119
2025-02-25 17:23:06.770481: val_loss -0.7489
2025-02-25 17:23:06.770571: Pseudo dice [0.7979]
2025-02-25 17:23:06.770680: Epoch time: 87.03 s
2025-02-25 17:23:06.770771: Yayy! New best EMA pseudo Dice: 0.7862
2025-02-25 17:23:09.392812: 
2025-02-25 17:23:09.393051: Epoch 92
2025-02-25 17:23:09.393178: Current learning rate: 0.00917
2025-02-25 17:24:33.190849: train_loss -0.7009
2025-02-25 17:24:33.191288: val_loss -0.7227
2025-02-25 17:24:33.191400: Pseudo dice [0.7847]
2025-02-25 17:24:33.191509: Epoch time: 83.8 s
2025-02-25 17:24:34.566599: 
2025-02-25 17:24:34.566782: Epoch 93
2025-02-25 17:24:34.566910: Current learning rate: 0.00916
2025-02-25 17:25:45.530487: train_loss -0.7157
2025-02-25 17:25:45.530948: val_loss -0.7325
2025-02-25 17:25:45.531036: Pseudo dice [0.7851]
2025-02-25 17:25:45.531154: Epoch time: 70.97 s
2025-02-25 17:25:46.839560: 
2025-02-25 17:25:46.839832: Epoch 94
2025-02-25 17:25:46.839968: Current learning rate: 0.00915
2025-02-25 17:26:59.761263: train_loss -0.709
2025-02-25 17:26:59.761694: val_loss -0.7416
2025-02-25 17:26:59.761776: Pseudo dice [0.7878]
2025-02-25 17:26:59.761863: Epoch time: 72.92 s
2025-02-25 17:27:01.141991: 
2025-02-25 17:27:01.142217: Epoch 95
2025-02-25 17:27:01.142351: Current learning rate: 0.00914
2025-02-25 17:28:13.119632: train_loss -0.714
2025-02-25 17:28:13.120204: val_loss -0.7386
2025-02-25 17:28:13.120289: Pseudo dice [0.7876]
2025-02-25 17:28:13.120405: Epoch time: 71.98 s
2025-02-25 17:28:13.120480: Yayy! New best EMA pseudo Dice: 0.7863
2025-02-25 17:28:15.016467: 
2025-02-25 17:28:15.016723: Epoch 96
2025-02-25 17:28:15.016871: Current learning rate: 0.00913
2025-02-25 17:29:24.629393: train_loss -0.7031
2025-02-25 17:29:24.629775: val_loss -0.7154
2025-02-25 17:29:24.629848: Pseudo dice [0.7781]
2025-02-25 17:29:24.629951: Epoch time: 69.61 s
2025-02-25 17:29:25.949057: 
2025-02-25 17:29:25.949273: Epoch 97
2025-02-25 17:29:25.949408: Current learning rate: 0.00912
2025-02-25 17:30:35.297345: train_loss -0.7169
2025-02-25 17:30:35.297751: val_loss -0.743
2025-02-25 17:30:35.297837: Pseudo dice [0.797]
2025-02-25 17:30:35.297934: Epoch time: 69.35 s
2025-02-25 17:30:35.298005: Yayy! New best EMA pseudo Dice: 0.7866
2025-02-25 17:30:37.312687: 
2025-02-25 17:30:37.312913: Epoch 98
2025-02-25 17:30:37.313043: Current learning rate: 0.00911
2025-02-25 17:31:46.534875: train_loss -0.7147
2025-02-25 17:31:46.535321: val_loss -0.7405
2025-02-25 17:31:46.535444: Pseudo dice [0.7873]
2025-02-25 17:31:46.535555: Epoch time: 69.22 s
2025-02-25 17:31:46.535635: Yayy! New best EMA pseudo Dice: 0.7867
2025-02-25 17:31:48.433692: 
2025-02-25 17:31:48.433913: Epoch 99
2025-02-25 17:31:48.434041: Current learning rate: 0.0091
2025-02-25 17:33:06.124752: train_loss -0.724
2025-02-25 17:33:06.125269: val_loss -0.7179
2025-02-25 17:33:06.125376: Pseudo dice [0.7666]
2025-02-25 17:33:06.125473: Epoch time: 77.69 s
2025-02-25 17:33:08.190561: 
2025-02-25 17:33:08.190805: Epoch 100
2025-02-25 17:33:08.190944: Current learning rate: 0.0091
2025-02-25 17:34:46.999691: train_loss -0.7073
2025-02-25 17:34:47.000229: val_loss -0.7341
2025-02-25 17:34:47.000351: Pseudo dice [0.7889]
2025-02-25 17:34:47.000477: Epoch time: 98.81 s
2025-02-25 17:34:48.666328: 
2025-02-25 17:34:48.666541: Epoch 101
2025-02-25 17:34:48.666669: Current learning rate: 0.00909
2025-02-25 17:37:12.915585: train_loss -0.7372
2025-02-25 17:37:12.916334: val_loss -0.7378
2025-02-25 17:37:12.916439: Pseudo dice [0.7841]
2025-02-25 17:37:12.916560: Epoch time: 144.25 s
2025-02-25 17:37:14.778199: 
2025-02-25 17:37:14.778453: Epoch 102
2025-02-25 17:37:14.778597: Current learning rate: 0.00908
2025-02-25 17:39:32.278769: train_loss -0.7184
2025-02-25 17:39:32.279346: val_loss -0.7473
2025-02-25 17:39:32.279452: Pseudo dice [0.8003]
2025-02-25 17:39:32.279587: Epoch time: 137.5 s
2025-02-25 17:39:33.912602: 
2025-02-25 17:39:33.912899: Epoch 103
2025-02-25 17:39:33.913120: Current learning rate: 0.00907
2025-02-25 17:42:09.257745: train_loss -0.7307
2025-02-25 17:42:09.258487: val_loss -0.7139
2025-02-25 17:42:09.258677: Pseudo dice [0.7734]
2025-02-25 17:42:09.258885: Epoch time: 155.35 s
2025-02-25 17:42:11.649031: 
2025-02-25 17:42:11.649285: Epoch 104
2025-02-25 17:42:11.649438: Current learning rate: 0.00906
2025-02-25 17:44:47.451030: train_loss -0.7256
2025-02-25 17:44:47.451984: val_loss -0.7369
2025-02-25 17:44:47.452186: Pseudo dice [0.7849]
2025-02-25 17:44:47.452397: Epoch time: 155.8 s
2025-02-25 17:44:49.311639: 
2025-02-25 17:44:49.311858: Epoch 105
2025-02-25 17:44:49.311991: Current learning rate: 0.00905
2025-02-25 17:47:17.823368: train_loss -0.7089
2025-02-25 17:47:17.824175: val_loss -0.7265
2025-02-25 17:47:17.824339: Pseudo dice [0.7887]
2025-02-25 17:47:17.824543: Epoch time: 148.51 s
2025-02-25 17:47:19.524419: 
2025-02-25 17:47:19.524679: Epoch 106
2025-02-25 17:47:19.524813: Current learning rate: 0.00904
2025-02-25 17:49:51.568439: train_loss -0.7307
2025-02-25 17:49:51.569133: val_loss -0.7519
2025-02-25 17:49:51.569258: Pseudo dice [0.8033]
2025-02-25 17:49:51.569400: Epoch time: 152.05 s
2025-02-25 17:49:51.569494: Yayy! New best EMA pseudo Dice: 0.7873
2025-02-25 17:49:54.147635: 
2025-02-25 17:49:54.147892: Epoch 107
2025-02-25 17:49:54.148046: Current learning rate: 0.00903
2025-02-25 17:52:13.287835: train_loss -0.7235
2025-02-25 17:52:13.288398: val_loss -0.7496
2025-02-25 17:52:13.288551: Pseudo dice [0.7994]
2025-02-25 17:52:13.288714: Epoch time: 139.14 s
2025-02-25 17:52:13.289001: Yayy! New best EMA pseudo Dice: 0.7885
2025-02-25 17:52:15.451390: 
2025-02-25 17:52:15.451609: Epoch 108
2025-02-25 17:52:15.451741: Current learning rate: 0.00902
2025-02-25 17:53:59.376208: train_loss -0.7304
2025-02-25 17:53:59.377066: val_loss -0.727
2025-02-25 17:53:59.377162: Pseudo dice [0.7815]
2025-02-25 17:53:59.377270: Epoch time: 103.93 s
2025-02-25 17:54:00.795948: 
2025-02-25 17:54:00.796229: Epoch 109
2025-02-25 17:54:00.796387: Current learning rate: 0.00901
2025-02-25 17:55:20.424538: train_loss -0.7431
2025-02-25 17:55:20.424969: val_loss -0.7342
2025-02-25 17:55:20.425056: Pseudo dice [0.7903]
2025-02-25 17:55:20.425160: Epoch time: 79.63 s
2025-02-25 17:55:21.843292: 
2025-02-25 17:55:21.843530: Epoch 110
2025-02-25 17:55:21.843656: Current learning rate: 0.009
2025-02-25 17:56:28.763842: train_loss -0.7295
2025-02-25 17:56:28.764332: val_loss -0.7416
2025-02-25 17:56:28.764455: Pseudo dice [0.7957]
2025-02-25 17:56:28.764575: Epoch time: 66.92 s
2025-02-25 17:56:28.764655: Yayy! New best EMA pseudo Dice: 0.7888
2025-02-25 17:56:30.669211: 
2025-02-25 17:56:30.669434: Epoch 111
2025-02-25 17:56:30.669559: Current learning rate: 0.009
2025-02-25 17:57:38.501115: train_loss -0.7282
2025-02-25 17:57:38.501518: val_loss -0.7433
2025-02-25 17:57:38.501617: Pseudo dice [0.7953]
2025-02-25 17:57:38.501749: Epoch time: 67.83 s
2025-02-25 17:57:38.501831: Yayy! New best EMA pseudo Dice: 0.7895
2025-02-25 17:57:40.392484: 
2025-02-25 17:57:40.392721: Epoch 112
2025-02-25 17:57:40.392845: Current learning rate: 0.00899
2025-02-25 17:58:49.878421: train_loss -0.7363
2025-02-25 17:58:49.878856: val_loss -0.7512
2025-02-25 17:58:49.878939: Pseudo dice [0.7935]
2025-02-25 17:58:49.879035: Epoch time: 69.49 s
2025-02-25 17:58:49.879099: Yayy! New best EMA pseudo Dice: 0.7899
2025-02-25 17:58:51.796462: 
2025-02-25 17:58:51.796726: Epoch 113
2025-02-25 17:58:51.796914: Current learning rate: 0.00898
2025-02-25 18:00:02.490445: train_loss -0.7257
2025-02-25 18:00:02.491633: val_loss -0.7343
2025-02-25 18:00:02.491820: Pseudo dice [0.7894]
2025-02-25 18:00:02.491948: Epoch time: 70.7 s
2025-02-25 18:00:03.884976: 
2025-02-25 18:00:03.885190: Epoch 114
2025-02-25 18:00:03.885324: Current learning rate: 0.00897
2025-02-25 18:01:13.869550: train_loss -0.7428
2025-02-25 18:01:13.869958: val_loss -0.7424
2025-02-25 18:01:13.870048: Pseudo dice [0.7928]
2025-02-25 18:01:13.870170: Epoch time: 69.99 s
2025-02-25 18:01:13.870279: Yayy! New best EMA pseudo Dice: 0.7901
2025-02-25 18:01:15.797612: 
2025-02-25 18:01:15.797813: Epoch 115
2025-02-25 18:01:15.797939: Current learning rate: 0.00896
2025-02-25 18:02:25.844973: train_loss -0.7494
2025-02-25 18:02:25.845414: val_loss -0.7402
2025-02-25 18:02:25.845502: Pseudo dice [0.8029]
2025-02-25 18:02:25.845608: Epoch time: 70.05 s
2025-02-25 18:02:25.845695: Yayy! New best EMA pseudo Dice: 0.7914
2025-02-25 18:02:28.194568: 
2025-02-25 18:02:28.194795: Epoch 116
2025-02-25 18:02:28.194951: Current learning rate: 0.00895
2025-02-25 18:03:41.186705: train_loss -0.7235
2025-02-25 18:03:41.187176: val_loss -0.7457
2025-02-25 18:03:41.187284: Pseudo dice [0.7896]
2025-02-25 18:03:41.187458: Epoch time: 72.99 s
2025-02-25 18:03:42.562890: 
2025-02-25 18:03:42.563118: Epoch 117
2025-02-25 18:03:42.563239: Current learning rate: 0.00894
2025-02-25 18:04:52.204869: train_loss -0.7344
2025-02-25 18:04:52.205346: val_loss -0.7422
2025-02-25 18:04:52.205452: Pseudo dice [0.7913]
2025-02-25 18:04:52.205565: Epoch time: 69.64 s
2025-02-25 18:04:53.575147: 
2025-02-25 18:04:53.575371: Epoch 118
2025-02-25 18:04:53.575497: Current learning rate: 0.00893
2025-02-25 18:06:00.519935: train_loss -0.7252
2025-02-25 18:06:00.520350: val_loss -0.7353
2025-02-25 18:06:00.520444: Pseudo dice [0.7921]
2025-02-25 18:06:00.520551: Epoch time: 66.95 s
2025-02-25 18:06:01.872996: 
2025-02-25 18:06:01.873217: Epoch 119
2025-02-25 18:06:01.873356: Current learning rate: 0.00892
2025-02-25 18:07:08.140967: train_loss -0.7482
2025-02-25 18:07:08.141398: val_loss -0.7317
2025-02-25 18:07:08.141496: Pseudo dice [0.7881]
2025-02-25 18:07:08.141607: Epoch time: 66.27 s
2025-02-25 18:07:09.532990: 
2025-02-25 18:07:09.533226: Epoch 120
2025-02-25 18:07:09.533367: Current learning rate: 0.00891
2025-02-25 18:08:16.811877: train_loss -0.7333
2025-02-25 18:08:16.812262: val_loss -0.7509
2025-02-25 18:08:16.812368: Pseudo dice [0.7996]
2025-02-25 18:08:16.812478: Epoch time: 67.28 s
2025-02-25 18:08:16.812595: Yayy! New best EMA pseudo Dice: 0.7919
2025-02-25 18:08:18.757512: 
2025-02-25 18:08:18.757743: Epoch 121
2025-02-25 18:08:18.757869: Current learning rate: 0.0089
2025-02-25 18:09:25.756437: train_loss -0.7454
2025-02-25 18:09:25.756922: val_loss -0.703
2025-02-25 18:09:25.757028: Pseudo dice [0.7651]
2025-02-25 18:09:25.757143: Epoch time: 67.0 s
2025-02-25 18:09:27.122738: 
2025-02-25 18:09:27.122974: Epoch 122
2025-02-25 18:09:27.123118: Current learning rate: 0.00889
2025-02-25 18:10:31.655369: train_loss -0.7068
2025-02-25 18:10:31.655867: val_loss -0.7277
2025-02-25 18:10:31.655966: Pseudo dice [0.7849]
2025-02-25 18:10:31.656086: Epoch time: 64.53 s
2025-02-25 18:10:33.036776: 
2025-02-25 18:10:33.036993: Epoch 123
2025-02-25 18:10:33.037116: Current learning rate: 0.00889
2025-02-25 18:11:38.954019: train_loss -0.7331
2025-02-25 18:11:38.954354: val_loss -0.7451
2025-02-25 18:11:38.954435: Pseudo dice [0.7975]
2025-02-25 18:11:38.954527: Epoch time: 65.92 s
2025-02-25 18:11:40.285470: 
2025-02-25 18:11:40.285697: Epoch 124
2025-02-25 18:11:40.285823: Current learning rate: 0.00888
2025-02-25 18:12:45.679258: train_loss -0.7602
2025-02-25 18:12:45.679625: val_loss -0.7497
2025-02-25 18:12:45.679780: Pseudo dice [0.8046]
2025-02-25 18:12:45.679958: Epoch time: 65.4 s
2025-02-25 18:12:47.046748: 
2025-02-25 18:12:47.046961: Epoch 125
2025-02-25 18:12:47.047084: Current learning rate: 0.00887
2025-02-25 18:13:53.657141: train_loss -0.7371
2025-02-25 18:13:53.657596: val_loss -0.7169
2025-02-25 18:13:53.657698: Pseudo dice [0.7851]
2025-02-25 18:13:53.657809: Epoch time: 66.61 s
2025-02-25 18:13:55.001179: 
2025-02-25 18:13:55.001403: Epoch 126
2025-02-25 18:13:55.001531: Current learning rate: 0.00886
2025-02-25 18:15:00.832325: train_loss -0.729
2025-02-25 18:15:00.832872: val_loss -0.7343
2025-02-25 18:15:00.832977: Pseudo dice [0.7907]
2025-02-25 18:15:00.833128: Epoch time: 65.83 s
2025-02-25 18:15:02.223592: 
2025-02-25 18:15:02.223806: Epoch 127
2025-02-25 18:15:02.223935: Current learning rate: 0.00885
2025-02-25 18:16:08.039753: train_loss -0.7364
2025-02-25 18:16:08.040102: val_loss -0.7067
2025-02-25 18:16:08.040175: Pseudo dice [0.7725]
2025-02-25 18:16:08.040271: Epoch time: 65.82 s
2025-02-25 18:16:09.787591: 
2025-02-25 18:16:09.787808: Epoch 128
2025-02-25 18:16:09.787936: Current learning rate: 0.00884
2025-02-25 18:17:14.506998: train_loss -0.7511
2025-02-25 18:17:14.507470: val_loss -0.7442
2025-02-25 18:17:14.507563: Pseudo dice [0.7971]
2025-02-25 18:17:14.507689: Epoch time: 64.72 s
2025-02-25 18:17:15.813693: 
2025-02-25 18:17:15.813903: Epoch 129
2025-02-25 18:17:15.814026: Current learning rate: 0.00883
2025-02-25 18:18:20.521899: train_loss -0.7381
2025-02-25 18:18:20.522336: val_loss -0.7267
2025-02-25 18:18:20.522430: Pseudo dice [0.7797]
2025-02-25 18:18:20.522533: Epoch time: 64.71 s
2025-02-25 18:18:21.900404: 
2025-02-25 18:18:21.900669: Epoch 130
2025-02-25 18:18:21.900851: Current learning rate: 0.00882
2025-02-25 18:19:30.941082: train_loss -0.7238
2025-02-25 18:19:30.941475: val_loss -0.7496
2025-02-25 18:19:30.941554: Pseudo dice [0.7963]
2025-02-25 18:19:30.941639: Epoch time: 69.04 s
2025-02-25 18:19:32.312617: 
2025-02-25 18:19:32.312832: Epoch 131
2025-02-25 18:19:32.312962: Current learning rate: 0.00881
2025-02-25 18:20:39.149834: train_loss -0.748
2025-02-25 18:20:39.150292: val_loss -0.7353
2025-02-25 18:20:39.150391: Pseudo dice [0.795]
2025-02-25 18:20:39.150578: Epoch time: 66.84 s
2025-02-25 18:20:40.506052: 
2025-02-25 18:20:40.506288: Epoch 132
2025-02-25 18:20:40.506428: Current learning rate: 0.0088
2025-02-25 18:21:48.041574: train_loss -0.73
2025-02-25 18:21:48.042076: val_loss -0.7379
2025-02-25 18:21:48.042219: Pseudo dice [0.7912]
2025-02-25 18:21:48.042350: Epoch time: 67.54 s
2025-02-25 18:21:49.414535: 
2025-02-25 18:21:49.414768: Epoch 133
2025-02-25 18:21:49.414898: Current learning rate: 0.00879
2025-02-25 18:22:53.306358: train_loss -0.7265
2025-02-25 18:22:53.306795: val_loss -0.7233
2025-02-25 18:22:53.306886: Pseudo dice [0.7737]
2025-02-25 18:22:53.306993: Epoch time: 63.89 s
2025-02-25 18:22:54.687377: 
2025-02-25 18:22:54.687605: Epoch 134
2025-02-25 18:22:54.687738: Current learning rate: 0.00879
2025-02-25 18:23:59.113313: train_loss -0.7399
2025-02-25 18:23:59.113732: val_loss -0.7506
2025-02-25 18:23:59.113822: Pseudo dice [0.7978]
2025-02-25 18:23:59.113931: Epoch time: 64.43 s
2025-02-25 18:24:00.439441: 
2025-02-25 18:24:00.439656: Epoch 135
2025-02-25 18:24:00.439778: Current learning rate: 0.00878
2025-02-25 18:25:05.027977: train_loss -0.7299
2025-02-25 18:25:05.028364: val_loss -0.754
2025-02-25 18:25:05.028454: Pseudo dice [0.7997]
2025-02-25 18:25:05.028553: Epoch time: 64.59 s
2025-02-25 18:25:06.481632: 
2025-02-25 18:25:06.481855: Epoch 136
2025-02-25 18:25:06.481982: Current learning rate: 0.00877
2025-02-25 18:26:13.789096: train_loss -0.7196
2025-02-25 18:26:13.789517: val_loss -0.7262
2025-02-25 18:26:13.789627: Pseudo dice [0.7839]
2025-02-25 18:26:13.789728: Epoch time: 67.31 s
2025-02-25 18:26:15.155874: 
2025-02-25 18:26:15.156153: Epoch 137
2025-02-25 18:26:15.156281: Current learning rate: 0.00876
2025-02-25 18:27:20.630644: train_loss -0.7367
2025-02-25 18:27:20.630944: val_loss -0.7368
2025-02-25 18:27:20.631038: Pseudo dice [0.7867]
2025-02-25 18:27:20.631139: Epoch time: 65.48 s
2025-02-25 18:27:22.009758: 
2025-02-25 18:27:22.009965: Epoch 138
2025-02-25 18:27:22.010091: Current learning rate: 0.00875
2025-02-25 18:28:27.437188: train_loss -0.7225
2025-02-25 18:28:27.437677: val_loss -0.7224
2025-02-25 18:28:27.437772: Pseudo dice [0.7891]
2025-02-25 18:28:27.438498: Epoch time: 65.43 s
2025-02-25 18:28:28.896992: 
2025-02-25 18:28:28.897189: Epoch 139
2025-02-25 18:28:28.897320: Current learning rate: 0.00874
2025-02-25 18:29:35.057202: train_loss -0.732
2025-02-25 18:29:35.057686: val_loss -0.7222
2025-02-25 18:29:35.057905: Pseudo dice [0.7826]
2025-02-25 18:29:35.058043: Epoch time: 66.16 s
2025-02-25 18:29:36.880751: 
2025-02-25 18:29:36.880975: Epoch 140
2025-02-25 18:29:36.881098: Current learning rate: 0.00873
2025-02-25 18:30:41.554764: train_loss -0.732
2025-02-25 18:30:41.555140: val_loss -0.7423
2025-02-25 18:30:41.555227: Pseudo dice [0.7943]
2025-02-25 18:30:41.555336: Epoch time: 64.68 s
2025-02-25 18:30:43.013630: 
2025-02-25 18:30:43.013883: Epoch 141
2025-02-25 18:30:43.014009: Current learning rate: 0.00872
2025-02-25 18:31:50.334386: train_loss -0.7514
2025-02-25 18:31:50.334821: val_loss -0.7388
2025-02-25 18:31:50.334912: Pseudo dice [0.799]
2025-02-25 18:31:50.335015: Epoch time: 67.32 s
2025-02-25 18:31:51.698527: 
2025-02-25 18:31:51.698740: Epoch 142
2025-02-25 18:31:51.698867: Current learning rate: 0.00871
2025-02-25 18:32:56.869720: train_loss -0.7541
2025-02-25 18:32:56.870166: val_loss -0.7418
2025-02-25 18:32:56.870264: Pseudo dice [0.7831]
2025-02-25 18:32:56.870396: Epoch time: 65.17 s
2025-02-25 18:32:58.223811: 
2025-02-25 18:32:58.224035: Epoch 143
2025-02-25 18:32:58.224159: Current learning rate: 0.0087
2025-02-25 18:34:03.671239: train_loss -0.7468
2025-02-25 18:34:03.671739: val_loss -0.7403
2025-02-25 18:34:03.671837: Pseudo dice [0.8033]
2025-02-25 18:34:03.671960: Epoch time: 65.45 s
2025-02-25 18:34:05.097346: 
2025-02-25 18:34:05.097561: Epoch 144
2025-02-25 18:34:05.097687: Current learning rate: 0.00869
2025-02-25 18:35:12.362099: train_loss -0.7499
2025-02-25 18:35:12.362518: val_loss -0.7505
2025-02-25 18:35:12.362603: Pseudo dice [0.797]
2025-02-25 18:35:12.362701: Epoch time: 67.27 s
2025-02-25 18:35:13.711143: 
2025-02-25 18:35:13.711369: Epoch 145
2025-02-25 18:35:13.711505: Current learning rate: 0.00868
2025-02-25 18:36:18.177026: train_loss -0.7505
2025-02-25 18:36:18.177423: val_loss -0.7323
2025-02-25 18:36:18.177516: Pseudo dice [0.7853]
2025-02-25 18:36:18.177617: Epoch time: 64.47 s
2025-02-25 18:36:19.563720: 
2025-02-25 18:36:19.563940: Epoch 146
2025-02-25 18:36:19.564069: Current learning rate: 0.00868
2025-02-25 18:37:25.821158: train_loss -0.7746
2025-02-25 18:37:25.821545: val_loss -0.7281
2025-02-25 18:37:25.821626: Pseudo dice [0.7806]
2025-02-25 18:37:25.821722: Epoch time: 66.26 s
2025-02-25 18:37:27.212424: 
2025-02-25 18:37:27.212677: Epoch 147
2025-02-25 18:37:27.212814: Current learning rate: 0.00867
2025-02-25 18:38:33.062913: train_loss -0.7681
2025-02-25 18:38:33.063422: val_loss -0.7393
2025-02-25 18:38:33.063541: Pseudo dice [0.792]
2025-02-25 18:38:33.063654: Epoch time: 65.85 s
2025-02-25 18:38:34.422361: 
2025-02-25 18:38:34.422566: Epoch 148
2025-02-25 18:38:34.422689: Current learning rate: 0.00866
2025-02-25 18:39:40.439418: train_loss -0.7397
2025-02-25 18:39:40.439804: val_loss -0.7299
2025-02-25 18:39:40.439885: Pseudo dice [0.7781]
2025-02-25 18:39:40.439982: Epoch time: 66.02 s
2025-02-25 18:39:41.793942: 
2025-02-25 18:39:41.794143: Epoch 149
2025-02-25 18:39:41.794267: Current learning rate: 0.00865
2025-02-25 18:40:47.017440: train_loss -0.7553
2025-02-25 18:40:47.017905: val_loss -0.7266
2025-02-25 18:40:47.018004: Pseudo dice [0.7799]
2025-02-25 18:40:47.018130: Epoch time: 65.22 s
2025-02-25 18:40:48.901022: 
2025-02-25 18:40:48.901237: Epoch 150
2025-02-25 18:40:48.901365: Current learning rate: 0.00864
2025-02-25 18:41:53.607120: train_loss -0.7543
2025-02-25 18:41:53.607676: val_loss -0.7399
2025-02-25 18:41:53.607814: Pseudo dice [0.7942]
2025-02-25 18:41:53.607934: Epoch time: 64.71 s
2025-02-25 18:41:55.394427: 
2025-02-25 18:41:55.394669: Epoch 151
2025-02-25 18:41:55.394798: Current learning rate: 0.00863
2025-02-25 18:42:59.019591: train_loss -0.7527
2025-02-25 18:42:59.020020: val_loss -0.7392
2025-02-25 18:42:59.020122: Pseudo dice [0.783]
2025-02-25 18:42:59.020228: Epoch time: 63.63 s
2025-02-25 18:43:00.343776: 
2025-02-25 18:43:00.343998: Epoch 152
2025-02-25 18:43:00.344119: Current learning rate: 0.00862
2025-02-25 18:44:06.743655: train_loss -0.7426
2025-02-25 18:44:06.744009: val_loss -0.7211
2025-02-25 18:44:06.744106: Pseudo dice [0.7728]
2025-02-25 18:44:06.744220: Epoch time: 66.4 s
2025-02-25 18:44:08.069507: 
2025-02-25 18:44:08.069744: Epoch 153
2025-02-25 18:44:08.069869: Current learning rate: 0.00861
2025-02-25 18:45:12.561469: train_loss -0.7334
2025-02-25 18:45:12.561878: val_loss -0.7255
2025-02-25 18:45:12.561958: Pseudo dice [0.7873]
2025-02-25 18:45:12.562054: Epoch time: 64.49 s
2025-02-25 18:45:13.936752: 
2025-02-25 18:45:13.936959: Epoch 154
2025-02-25 18:45:13.937085: Current learning rate: 0.0086
2025-02-25 18:46:19.847796: train_loss -0.7309
2025-02-25 18:46:19.848160: val_loss -0.7341
2025-02-25 18:46:19.848242: Pseudo dice [0.7882]
2025-02-25 18:46:19.848361: Epoch time: 65.91 s
2025-02-25 18:46:21.166842: 
2025-02-25 18:46:21.167073: Epoch 155
2025-02-25 18:46:21.167206: Current learning rate: 0.00859
2025-02-25 18:47:27.574539: train_loss -0.746
2025-02-25 18:47:27.574965: val_loss -0.7359
2025-02-25 18:47:27.575049: Pseudo dice [0.7977]
2025-02-25 18:47:27.575155: Epoch time: 66.41 s
2025-02-25 18:47:28.886719: 
2025-02-25 18:47:28.886935: Epoch 156
2025-02-25 18:47:28.887062: Current learning rate: 0.00858
2025-02-25 18:48:34.593755: train_loss -0.7637
2025-02-25 18:48:34.594175: val_loss -0.7442
2025-02-25 18:48:34.594258: Pseudo dice [0.802]
2025-02-25 18:48:34.594391: Epoch time: 65.71 s
2025-02-25 18:48:35.908117: 
2025-02-25 18:48:35.908337: Epoch 157
2025-02-25 18:48:35.908464: Current learning rate: 0.00858
2025-02-25 18:49:41.773582: train_loss -0.7777
2025-02-25 18:49:41.774013: val_loss -0.7404
2025-02-25 18:49:41.782475: Pseudo dice [0.7948]
2025-02-25 18:49:41.782757: Epoch time: 65.87 s
2025-02-25 18:49:43.138291: 
2025-02-25 18:49:43.138502: Epoch 158
2025-02-25 18:49:43.138620: Current learning rate: 0.00857
2025-02-25 18:50:50.694855: train_loss -0.7679
2025-02-25 18:50:50.695251: val_loss -0.7566
2025-02-25 18:50:50.695357: Pseudo dice [0.8034]
2025-02-25 18:50:50.695676: Epoch time: 67.56 s
2025-02-25 18:50:52.039779: 
2025-02-25 18:50:52.039988: Epoch 159
2025-02-25 18:50:52.040114: Current learning rate: 0.00856
2025-02-25 18:51:57.969751: train_loss -0.759
2025-02-25 18:51:57.970139: val_loss -0.7498
2025-02-25 18:51:57.970210: Pseudo dice [0.7984]
2025-02-25 18:51:57.970290: Epoch time: 65.93 s
2025-02-25 18:51:57.970373: Yayy! New best EMA pseudo Dice: 0.7919
2025-02-25 18:51:59.852342: 
2025-02-25 18:51:59.852573: Epoch 160
2025-02-25 18:51:59.852710: Current learning rate: 0.00855
2025-02-25 18:53:11.445236: train_loss -0.7455
2025-02-25 18:53:11.445615: val_loss -0.7264
2025-02-25 18:53:11.445700: Pseudo dice [0.785]
2025-02-25 18:53:11.446119: Epoch time: 71.59 s
2025-02-25 18:53:12.836602: 
2025-02-25 18:53:12.836816: Epoch 161
2025-02-25 18:53:12.836936: Current learning rate: 0.00854
2025-02-25 18:54:30.772118: train_loss -0.7463
2025-02-25 18:54:30.772534: val_loss -0.7425
2025-02-25 18:54:30.772625: Pseudo dice [0.7926]
2025-02-25 18:54:30.772726: Epoch time: 77.94 s
2025-02-25 18:54:32.575384: 
2025-02-25 18:54:32.575593: Epoch 162
2025-02-25 18:54:32.575722: Current learning rate: 0.00853
2025-02-25 18:55:45.213864: train_loss -0.7603
2025-02-25 18:55:45.214226: val_loss -0.7214
2025-02-25 18:55:45.214337: Pseudo dice [0.7802]
2025-02-25 18:55:45.214568: Epoch time: 72.64 s
2025-02-25 18:55:46.590530: 
2025-02-25 18:55:46.590755: Epoch 163
2025-02-25 18:55:46.590877: Current learning rate: 0.00852
2025-02-25 18:57:02.617667: train_loss -0.7016
2025-02-25 18:57:02.618135: val_loss -0.7231
2025-02-25 18:57:02.618243: Pseudo dice [0.7836]
2025-02-25 18:57:02.618362: Epoch time: 76.03 s
2025-02-25 18:57:04.047798: 
2025-02-25 18:57:04.048043: Epoch 164
2025-02-25 18:57:04.048168: Current learning rate: 0.00851
2025-02-25 18:58:23.218692: train_loss -0.7473
2025-02-25 18:58:23.219116: val_loss -0.7239
2025-02-25 18:58:23.219731: Pseudo dice [0.7874]
2025-02-25 18:58:23.219860: Epoch time: 79.17 s
2025-02-25 18:58:24.586765: 
2025-02-25 18:58:24.587000: Epoch 165
2025-02-25 18:58:24.587124: Current learning rate: 0.0085
2025-02-25 18:59:44.739420: train_loss -0.7414
2025-02-25 18:59:44.741626: val_loss -0.7384
2025-02-25 18:59:44.741817: Pseudo dice [0.7898]
2025-02-25 18:59:44.741919: Epoch time: 80.15 s
2025-02-25 18:59:46.137889: 
2025-02-25 18:59:46.138141: Epoch 166
2025-02-25 18:59:46.138265: Current learning rate: 0.00849
2025-02-25 19:01:08.762453: train_loss -0.7184
2025-02-25 19:01:08.762839: val_loss -0.738
2025-02-25 19:01:08.762919: Pseudo dice [0.7877]
2025-02-25 19:01:08.763016: Epoch time: 82.63 s
2025-02-25 19:01:10.146195: 
2025-02-25 19:01:10.146482: Epoch 167
2025-02-25 19:01:10.146610: Current learning rate: 0.00848
2025-02-25 19:02:32.938144: train_loss -0.7459
2025-02-25 19:02:32.938495: val_loss -0.7238
2025-02-25 19:02:32.938576: Pseudo dice [0.7826]
2025-02-25 19:02:32.938673: Epoch time: 82.79 s
2025-02-25 19:02:34.310797: 
2025-02-25 19:02:34.311019: Epoch 168
2025-02-25 19:02:34.311142: Current learning rate: 0.00847
2025-02-25 19:03:58.082444: train_loss -0.7498
2025-02-25 19:03:58.082856: val_loss -0.7279
2025-02-25 19:03:58.082936: Pseudo dice [0.783]
2025-02-25 19:03:58.083032: Epoch time: 83.77 s
2025-02-25 19:03:59.891560: 
2025-02-25 19:03:59.891829: Epoch 169
2025-02-25 19:03:59.891959: Current learning rate: 0.00847
2025-02-25 19:05:21.730890: train_loss -0.759
2025-02-25 19:05:21.731328: val_loss -0.7372
2025-02-25 19:05:21.731433: Pseudo dice [0.7889]
2025-02-25 19:05:21.731539: Epoch time: 81.84 s
2025-02-25 19:05:23.257183: 
2025-02-25 19:05:23.257418: Epoch 170
2025-02-25 19:05:23.257539: Current learning rate: 0.00846
2025-02-25 19:06:49.622267: train_loss -0.7724
2025-02-25 19:06:49.622599: val_loss -0.7306
2025-02-25 19:06:49.622689: Pseudo dice [0.7848]
2025-02-25 19:06:49.622790: Epoch time: 86.37 s
2025-02-25 19:06:51.104851: 
2025-02-25 19:06:51.105090: Epoch 171
2025-02-25 19:06:51.105213: Current learning rate: 0.00845
2025-02-25 19:08:10.989606: train_loss -0.7566
2025-02-25 19:08:10.989904: val_loss -0.7419
2025-02-25 19:08:10.989990: Pseudo dice [0.7874]
2025-02-25 19:08:10.990095: Epoch time: 79.89 s
2025-02-25 19:08:12.333028: 
2025-02-25 19:08:12.333224: Epoch 172
2025-02-25 19:08:12.333357: Current learning rate: 0.00844
2025-02-25 19:09:15.564095: train_loss -0.7548
2025-02-25 19:09:15.564522: val_loss -0.7346
2025-02-25 19:09:15.564605: Pseudo dice [0.7961]
2025-02-25 19:09:15.564718: Epoch time: 63.23 s
2025-02-25 19:09:17.363001: 
2025-02-25 19:09:17.363263: Epoch 173
2025-02-25 19:09:17.363398: Current learning rate: 0.00843
2025-02-25 19:10:21.721075: train_loss -0.7652
2025-02-25 19:10:21.721512: val_loss -0.752
2025-02-25 19:10:21.721610: Pseudo dice [0.8063]
2025-02-25 19:10:21.721718: Epoch time: 64.36 s
2025-02-25 19:10:23.033767: 
2025-02-25 19:10:23.033992: Epoch 174
2025-02-25 19:10:23.034110: Current learning rate: 0.00842
2025-02-25 19:11:26.649907: train_loss -0.7777
2025-02-25 19:11:26.650384: val_loss -0.7366
2025-02-25 19:11:26.650486: Pseudo dice [0.7883]
2025-02-25 19:11:26.650597: Epoch time: 63.62 s
2025-02-25 19:11:27.984966: 
2025-02-25 19:11:27.985191: Epoch 175
2025-02-25 19:11:27.985327: Current learning rate: 0.00841
2025-02-25 19:12:33.584366: train_loss -0.7834
2025-02-25 19:12:33.584670: val_loss -0.7331
2025-02-25 19:12:33.584757: Pseudo dice [0.7861]
2025-02-25 19:12:33.584851: Epoch time: 65.6 s
2025-02-25 19:12:34.999056: 
2025-02-25 19:12:34.999272: Epoch 176
2025-02-25 19:12:34.999409: Current learning rate: 0.0084
2025-02-25 19:13:40.543107: train_loss -0.7903
2025-02-25 19:13:40.543519: val_loss -0.7547
2025-02-25 19:13:40.543602: Pseudo dice [0.8008]
2025-02-25 19:13:40.543699: Epoch time: 65.55 s
2025-02-25 19:13:41.973912: 
2025-02-25 19:13:41.974133: Epoch 177
2025-02-25 19:13:41.974258: Current learning rate: 0.00839
2025-02-25 19:14:49.173843: train_loss -0.7796
2025-02-25 19:14:49.174248: val_loss -0.7481
2025-02-25 19:14:49.174351: Pseudo dice [0.7991]
2025-02-25 19:14:49.174449: Epoch time: 67.2 s
2025-02-25 19:14:50.569588: 
2025-02-25 19:14:50.569849: Epoch 178
2025-02-25 19:14:50.569985: Current learning rate: 0.00838
2025-02-25 19:15:56.854941: train_loss -0.7777
2025-02-25 19:15:56.855435: val_loss -0.7332
2025-02-25 19:15:56.855538: Pseudo dice [0.7867]
2025-02-25 19:15:56.855649: Epoch time: 66.29 s
2025-02-25 19:15:58.285895: 
2025-02-25 19:15:58.286118: Epoch 179
2025-02-25 19:15:58.286260: Current learning rate: 0.00837
2025-02-25 19:17:05.482514: train_loss -0.7651
2025-02-25 19:17:05.483049: val_loss -0.7591
2025-02-25 19:17:05.483140: Pseudo dice [0.8049]
2025-02-25 19:17:05.483227: Epoch time: 67.2 s
2025-02-25 19:17:05.483292: Yayy! New best EMA pseudo Dice: 0.7925
2025-02-25 19:17:07.456665: 
2025-02-25 19:17:07.456874: Epoch 180
2025-02-25 19:17:07.456997: Current learning rate: 0.00836
2025-02-25 19:18:13.321536: train_loss -0.7494
2025-02-25 19:18:13.322093: val_loss -0.7424
2025-02-25 19:18:13.322204: Pseudo dice [0.7925]
2025-02-25 19:18:13.322345: Epoch time: 65.87 s
2025-02-25 19:18:13.322432: Yayy! New best EMA pseudo Dice: 0.7925
2025-02-25 19:18:15.267565: 
2025-02-25 19:18:15.267788: Epoch 181
2025-02-25 19:18:15.267916: Current learning rate: 0.00836
2025-02-25 19:19:22.142430: train_loss -0.7515
2025-02-25 19:19:22.142812: val_loss -0.7029
2025-02-25 19:19:22.142895: Pseudo dice [0.7575]
2025-02-25 19:19:22.142994: Epoch time: 66.88 s
2025-02-25 19:19:23.530747: 
2025-02-25 19:19:23.531008: Epoch 182
2025-02-25 19:19:23.531193: Current learning rate: 0.00835
2025-02-25 19:20:31.617131: train_loss -0.7245
2025-02-25 19:20:31.617579: val_loss -0.7338
2025-02-25 19:20:31.617669: Pseudo dice [0.7919]
2025-02-25 19:20:31.617772: Epoch time: 68.09 s
2025-02-25 19:20:32.979311: 
2025-02-25 19:20:32.979525: Epoch 183
2025-02-25 19:20:32.979651: Current learning rate: 0.00834
2025-02-25 19:21:38.526093: train_loss -0.7534
2025-02-25 19:21:38.526491: val_loss -0.7241
2025-02-25 19:21:38.526588: Pseudo dice [0.7818]
2025-02-25 19:21:38.526694: Epoch time: 65.55 s
2025-02-25 19:21:40.310145: 
2025-02-25 19:21:40.310376: Epoch 184
2025-02-25 19:21:40.310518: Current learning rate: 0.00833
2025-02-25 19:22:46.199321: train_loss -0.7561
2025-02-25 19:22:46.199719: val_loss -0.7293
2025-02-25 19:22:46.199807: Pseudo dice [0.7884]
2025-02-25 19:22:46.199913: Epoch time: 65.89 s
2025-02-25 19:22:47.567850: 
2025-02-25 19:22:47.568109: Epoch 185
2025-02-25 19:22:47.568235: Current learning rate: 0.00832
2025-02-25 19:23:51.952044: train_loss -0.7712
2025-02-25 19:23:51.952409: val_loss -0.737
2025-02-25 19:23:51.952506: Pseudo dice [0.7892]
2025-02-25 19:23:51.952612: Epoch time: 64.39 s
2025-02-25 19:23:53.354512: 
2025-02-25 19:23:53.354744: Epoch 186
2025-02-25 19:23:53.354874: Current learning rate: 0.00831
2025-02-25 19:24:59.021672: train_loss -0.7274
2025-02-25 19:24:59.022064: val_loss -0.7329
2025-02-25 19:24:59.022155: Pseudo dice [0.7855]
2025-02-25 19:24:59.022251: Epoch time: 65.67 s
2025-02-25 19:25:00.437934: 
2025-02-25 19:25:00.438154: Epoch 187
2025-02-25 19:25:00.438286: Current learning rate: 0.0083
2025-02-25 19:26:07.897681: train_loss -0.7474
2025-02-25 19:26:07.898084: val_loss -0.7375
2025-02-25 19:26:07.898261: Pseudo dice [0.7871]
2025-02-25 19:26:07.898381: Epoch time: 67.46 s
2025-02-25 19:26:09.319722: 
2025-02-25 19:26:09.319978: Epoch 188
2025-02-25 19:26:09.320107: Current learning rate: 0.00829
2025-02-25 19:27:15.248220: train_loss -0.7703
2025-02-25 19:27:15.248646: val_loss -0.7281
2025-02-25 19:27:15.248733: Pseudo dice [0.7862]
2025-02-25 19:27:15.248833: Epoch time: 65.93 s
2025-02-25 19:27:16.715781: 
2025-02-25 19:27:16.715997: Epoch 189
2025-02-25 19:27:16.716119: Current learning rate: 0.00828
2025-02-25 19:28:22.446688: train_loss -0.7837
2025-02-25 19:28:22.447124: val_loss -0.7177
2025-02-25 19:28:22.447226: Pseudo dice [0.7721]
2025-02-25 19:28:22.447347: Epoch time: 65.73 s
2025-02-25 19:28:23.871966: 
2025-02-25 19:28:23.872197: Epoch 190
2025-02-25 19:28:23.872656: Current learning rate: 0.00827
2025-02-25 19:29:31.125512: train_loss -0.7334
2025-02-25 19:29:31.125867: val_loss -0.7226
2025-02-25 19:29:31.125945: Pseudo dice [0.7805]
2025-02-25 19:29:31.126049: Epoch time: 67.26 s
2025-02-25 19:29:32.517926: 
2025-02-25 19:29:32.518144: Epoch 191
2025-02-25 19:29:32.518265: Current learning rate: 0.00826
2025-02-25 19:30:40.263507: train_loss -0.7594
2025-02-25 19:30:40.263978: val_loss -0.7413
2025-02-25 19:30:40.264072: Pseudo dice [0.7977]
2025-02-25 19:30:40.264193: Epoch time: 67.75 s
2025-02-25 19:30:41.648625: 
2025-02-25 19:30:41.648837: Epoch 192
2025-02-25 19:30:41.648962: Current learning rate: 0.00825
2025-02-25 19:31:49.770018: train_loss -0.7598
2025-02-25 19:31:49.770456: val_loss -0.7152
2025-02-25 19:31:49.770545: Pseudo dice [0.7927]
2025-02-25 19:31:49.770652: Epoch time: 68.12 s
2025-02-25 19:31:51.234581: 
2025-02-25 19:31:51.234797: Epoch 193
2025-02-25 19:31:51.234923: Current learning rate: 0.00824
2025-02-25 19:32:57.737194: train_loss -0.7592
2025-02-25 19:32:57.737672: val_loss -0.7592
2025-02-25 19:32:57.737763: Pseudo dice [0.807]
2025-02-25 19:32:57.737867: Epoch time: 66.5 s
2025-02-25 19:32:59.218192: 
2025-02-25 19:32:59.218442: Epoch 194
2025-02-25 19:32:59.218570: Current learning rate: 0.00824
2025-02-25 19:34:08.931705: train_loss -0.7797
2025-02-25 19:34:08.932100: val_loss -0.7519
2025-02-25 19:34:08.932184: Pseudo dice [0.8041]
2025-02-25 19:34:08.932282: Epoch time: 69.71 s
2025-02-25 19:34:10.372858: 
2025-02-25 19:34:10.373073: Epoch 195
2025-02-25 19:34:10.373196: Current learning rate: 0.00823
2025-02-25 19:35:16.454320: train_loss -0.7896
2025-02-25 19:35:16.454675: val_loss -0.7533
2025-02-25 19:35:16.454761: Pseudo dice [0.7954]
2025-02-25 19:35:16.454860: Epoch time: 66.08 s
2025-02-25 19:35:17.860857: 
2025-02-25 19:35:17.861085: Epoch 196
2025-02-25 19:35:17.861207: Current learning rate: 0.00822
2025-02-25 19:36:23.886636: train_loss -0.7962
2025-02-25 19:36:23.887029: val_loss -0.744
2025-02-25 19:36:23.887114: Pseudo dice [0.796]
2025-02-25 19:36:23.887220: Epoch time: 66.03 s
2025-02-25 19:36:25.324487: 
2025-02-25 19:36:25.324715: Epoch 197
2025-02-25 19:36:25.324838: Current learning rate: 0.00821
2025-02-25 19:37:32.494935: train_loss -0.7917
2025-02-25 19:37:32.495390: val_loss -0.7542
2025-02-25 19:37:32.495493: Pseudo dice [0.8045]
2025-02-25 19:37:32.495610: Epoch time: 67.17 s
2025-02-25 19:37:32.495722: Yayy! New best EMA pseudo Dice: 0.7931
2025-02-25 19:37:34.476470: 
2025-02-25 19:37:34.476711: Epoch 198
2025-02-25 19:37:34.476830: Current learning rate: 0.0082
2025-02-25 19:38:40.619332: train_loss -0.7872
2025-02-25 19:38:40.619746: val_loss -0.7617
2025-02-25 19:38:40.619838: Pseudo dice [0.8095]
2025-02-25 19:38:40.619940: Epoch time: 66.14 s
2025-02-25 19:38:40.620013: Yayy! New best EMA pseudo Dice: 0.7948
2025-02-25 19:38:42.567098: 
2025-02-25 19:38:42.567335: Epoch 199
2025-02-25 19:38:42.567461: Current learning rate: 0.00819
2025-02-25 19:39:47.976088: train_loss -0.7705
2025-02-25 19:39:47.976513: val_loss -0.7367
2025-02-25 19:39:47.976598: Pseudo dice [0.7907]
2025-02-25 19:39:47.976697: Epoch time: 65.41 s
2025-02-25 19:39:49.911011: 
2025-02-25 19:39:49.911213: Epoch 200
2025-02-25 19:39:49.911344: Current learning rate: 0.00818
2025-02-25 19:40:58.129117: train_loss -0.757
2025-02-25 19:40:58.129469: val_loss -0.7425
2025-02-25 19:40:58.129554: Pseudo dice [0.7979]
2025-02-25 19:40:58.129636: Epoch time: 68.22 s
2025-02-25 19:40:59.541681: 
2025-02-25 19:40:59.541901: Epoch 201
2025-02-25 19:40:59.542022: Current learning rate: 0.00817
2025-02-25 19:42:05.566326: train_loss -0.7579
2025-02-25 19:42:05.566725: val_loss -0.7277
2025-02-25 19:42:05.566819: Pseudo dice [0.7846]
2025-02-25 19:42:05.566920: Epoch time: 66.03 s
2025-02-25 19:42:06.989461: 
2025-02-25 19:42:06.989697: Epoch 202
2025-02-25 19:42:06.989821: Current learning rate: 0.00816
2025-02-25 19:43:14.409311: train_loss -0.785
2025-02-25 19:43:14.409745: val_loss -0.7463
2025-02-25 19:43:14.409842: Pseudo dice [0.7981]
2025-02-25 19:43:14.409950: Epoch time: 67.42 s
2025-02-25 19:43:15.843346: 
2025-02-25 19:43:15.843583: Epoch 203
2025-02-25 19:43:15.843707: Current learning rate: 0.00815
2025-02-25 19:44:22.748657: train_loss -0.7669
2025-02-25 19:44:22.749075: val_loss -0.7389
2025-02-25 19:44:22.749164: Pseudo dice [0.7881]
2025-02-25 19:44:22.749268: Epoch time: 66.91 s
2025-02-25 19:44:24.223751: 
2025-02-25 19:44:24.223961: Epoch 204
2025-02-25 19:44:24.224092: Current learning rate: 0.00814
2025-02-25 19:45:29.322837: train_loss -0.7994
2025-02-25 19:45:29.323228: val_loss -0.7438
2025-02-25 19:45:29.323337: Pseudo dice [0.7935]
2025-02-25 19:45:29.323451: Epoch time: 65.1 s
2025-02-25 19:45:30.776570: 
2025-02-25 19:45:30.776788: Epoch 205
2025-02-25 19:45:30.776922: Current learning rate: 0.00813
2025-02-25 19:46:37.874801: train_loss -0.7909
2025-02-25 19:46:37.875194: val_loss -0.7548
2025-02-25 19:46:37.875283: Pseudo dice [0.8069]
2025-02-25 19:46:37.875401: Epoch time: 67.1 s
2025-02-25 19:46:37.875486: Yayy! New best EMA pseudo Dice: 0.7949
2025-02-25 19:46:40.136768: 
2025-02-25 19:46:40.137009: Epoch 206
2025-02-25 19:46:40.137138: Current learning rate: 0.00813
2025-02-25 19:47:46.006224: train_loss -0.8053
2025-02-25 19:47:46.006675: val_loss -0.7576
2025-02-25 19:47:46.006762: Pseudo dice [0.8065]
2025-02-25 19:47:46.006864: Epoch time: 65.87 s
2025-02-25 19:47:46.006949: Yayy! New best EMA pseudo Dice: 0.796
2025-02-25 19:47:47.938437: 
2025-02-25 19:47:47.938659: Epoch 207
2025-02-25 19:47:47.938784: Current learning rate: 0.00812
2025-02-25 19:48:54.650656: train_loss -0.8119
2025-02-25 19:48:54.651079: val_loss -0.7501
2025-02-25 19:48:54.651162: Pseudo dice [0.7971]
2025-02-25 19:48:54.651266: Epoch time: 66.71 s
2025-02-25 19:48:54.651364: Yayy! New best EMA pseudo Dice: 0.7961
2025-02-25 19:48:56.595334: 
2025-02-25 19:48:56.595586: Epoch 208
2025-02-25 19:48:56.595708: Current learning rate: 0.00811
2025-02-25 19:50:00.097604: train_loss -0.8093
2025-02-25 19:50:00.097997: val_loss -0.7191
2025-02-25 19:50:00.098083: Pseudo dice [0.7823]
2025-02-25 19:50:00.098184: Epoch time: 63.5 s
2025-02-25 19:50:01.481121: 
2025-02-25 19:50:01.481380: Epoch 209
2025-02-25 19:50:01.481503: Current learning rate: 0.0081
2025-02-25 19:51:05.548192: train_loss -0.8041
2025-02-25 19:51:05.548548: val_loss -0.7455
2025-02-25 19:51:05.548649: Pseudo dice [0.7973]
2025-02-25 19:51:05.548738: Epoch time: 64.07 s
2025-02-25 19:51:06.866491: 
2025-02-25 19:51:06.866720: Epoch 210
2025-02-25 19:51:06.866844: Current learning rate: 0.00809
2025-02-25 19:52:11.565233: train_loss -0.8015
2025-02-25 19:52:11.565645: val_loss -0.7428
2025-02-25 19:52:11.565728: Pseudo dice [0.7938]
2025-02-25 19:52:11.565829: Epoch time: 64.7 s
2025-02-25 19:52:12.889542: 
2025-02-25 19:52:12.889761: Epoch 211
2025-02-25 19:52:12.889883: Current learning rate: 0.00808
2025-02-25 19:53:17.770286: train_loss -0.8003
2025-02-25 19:53:17.771005: val_loss -0.7434
2025-02-25 19:53:17.771093: Pseudo dice [0.7997]
2025-02-25 19:53:17.771193: Epoch time: 64.88 s
2025-02-25 19:53:19.147364: 
2025-02-25 19:53:19.147618: Epoch 212
2025-02-25 19:53:19.147763: Current learning rate: 0.00807
2025-02-25 19:54:24.955123: train_loss -0.8079
2025-02-25 19:54:24.955540: val_loss -0.7537
2025-02-25 19:54:24.955633: Pseudo dice [0.7972]
2025-02-25 19:54:24.955741: Epoch time: 65.81 s
2025-02-25 19:54:26.292670: 
2025-02-25 19:54:26.292881: Epoch 213
2025-02-25 19:54:26.293008: Current learning rate: 0.00806
2025-02-25 19:55:32.552582: train_loss -0.8044
2025-02-25 19:55:32.552966: val_loss -0.7458
2025-02-25 19:55:32.553049: Pseudo dice [0.7965]
2025-02-25 19:55:32.553159: Epoch time: 66.26 s
2025-02-25 19:55:33.881533: 
2025-02-25 19:55:33.881741: Epoch 214
2025-02-25 19:55:33.881864: Current learning rate: 0.00805
2025-02-25 19:56:40.005896: train_loss -0.8118
2025-02-25 19:56:40.006328: val_loss -0.761
2025-02-25 19:56:40.006421: Pseudo dice [0.8106]
2025-02-25 19:56:40.006528: Epoch time: 66.13 s
2025-02-25 19:56:40.006604: Yayy! New best EMA pseudo Dice: 0.7971
2025-02-25 19:56:41.911401: 
2025-02-25 19:56:41.911607: Epoch 215
2025-02-25 19:56:41.911728: Current learning rate: 0.00804
2025-02-25 19:57:49.133597: train_loss -0.8143
2025-02-25 19:57:49.134158: val_loss -0.7408
2025-02-25 19:57:49.134464: Pseudo dice [0.7921]
2025-02-25 19:57:49.134578: Epoch time: 67.22 s
2025-02-25 19:57:50.518683: 
2025-02-25 19:57:50.518890: Epoch 216
2025-02-25 19:57:50.519029: Current learning rate: 0.00803
2025-02-25 19:58:56.302812: train_loss -0.753
2025-02-25 19:58:56.303202: val_loss -0.7455
2025-02-25 19:58:56.303285: Pseudo dice [0.7953]
2025-02-25 19:58:56.303404: Epoch time: 65.79 s
2025-02-25 19:58:57.649662: 
2025-02-25 19:58:57.649870: Epoch 217
2025-02-25 19:58:57.649999: Current learning rate: 0.00802
2025-02-25 20:00:03.561638: train_loss -0.7598
2025-02-25 20:00:03.562037: val_loss -0.7284
2025-02-25 20:00:03.562130: Pseudo dice [0.7801]
2025-02-25 20:00:03.562235: Epoch time: 65.91 s
2025-02-25 20:00:05.308266: 
2025-02-25 20:00:05.308541: Epoch 218
2025-02-25 20:00:05.308672: Current learning rate: 0.00801
2025-02-25 20:01:13.092138: train_loss -0.7153
2025-02-25 20:01:13.092536: val_loss -0.7242
2025-02-25 20:01:13.092749: Pseudo dice [0.7816]
2025-02-25 20:01:13.092860: Epoch time: 67.79 s
2025-02-25 20:01:14.490513: 
2025-02-25 20:01:14.490765: Epoch 219
2025-02-25 20:01:14.490891: Current learning rate: 0.00801
2025-02-25 20:02:20.569310: train_loss -0.7403
2025-02-25 20:02:20.569717: val_loss -0.7562
2025-02-25 20:02:20.569803: Pseudo dice [0.7996]
2025-02-25 20:02:20.569906: Epoch time: 66.08 s
2025-02-25 20:02:21.929067: 
2025-02-25 20:02:21.929310: Epoch 220
2025-02-25 20:02:21.929436: Current learning rate: 0.008
2025-02-25 20:03:28.195210: train_loss -0.7867
2025-02-25 20:03:28.195554: val_loss -0.7607
2025-02-25 20:03:28.195647: Pseudo dice [0.8075]
2025-02-25 20:03:28.195755: Epoch time: 66.27 s
2025-02-25 20:03:29.561313: 
2025-02-25 20:03:29.561550: Epoch 221
2025-02-25 20:03:29.561678: Current learning rate: 0.00799
2025-02-25 20:04:34.026336: train_loss -0.7984
2025-02-25 20:04:34.027767: val_loss -0.7186
2025-02-25 20:04:34.027884: Pseudo dice [0.7821]
2025-02-25 20:04:34.028012: Epoch time: 64.47 s
2025-02-25 20:04:35.362549: 
2025-02-25 20:04:35.362783: Epoch 222
2025-02-25 20:04:35.362917: Current learning rate: 0.00798
2025-02-25 20:05:41.241584: train_loss -0.759
2025-02-25 20:05:41.241997: val_loss -0.7209
2025-02-25 20:05:41.242080: Pseudo dice [0.7797]
2025-02-25 20:05:41.242177: Epoch time: 65.88 s
2025-02-25 20:05:42.557891: 
2025-02-25 20:05:42.558102: Epoch 223
2025-02-25 20:05:42.558224: Current learning rate: 0.00797
2025-02-25 20:06:47.660779: train_loss -0.7747
2025-02-25 20:06:47.661161: val_loss -0.7473
2025-02-25 20:06:47.661246: Pseudo dice [0.8053]
2025-02-25 20:06:47.661354: Epoch time: 65.1 s
2025-02-25 20:06:49.002562: 
2025-02-25 20:06:49.002786: Epoch 224
2025-02-25 20:06:49.002910: Current learning rate: 0.00796
2025-02-25 20:07:54.699583: train_loss -0.793
2025-02-25 20:07:54.700121: val_loss -0.7495
2025-02-25 20:07:54.700215: Pseudo dice [0.8035]
2025-02-25 20:07:54.700323: Epoch time: 65.7 s
2025-02-25 20:07:56.000599: 
2025-02-25 20:07:56.000819: Epoch 225
2025-02-25 20:07:56.000941: Current learning rate: 0.00795
2025-02-25 20:09:02.711026: train_loss -0.7865
2025-02-25 20:09:02.711471: val_loss -0.7437
2025-02-25 20:09:02.711575: Pseudo dice [0.7916]
2025-02-25 20:09:02.711686: Epoch time: 66.71 s
2025-02-25 20:09:04.022647: 
2025-02-25 20:09:04.022867: Epoch 226
2025-02-25 20:09:04.022995: Current learning rate: 0.00794
2025-02-25 20:10:11.302160: train_loss -0.7775
2025-02-25 20:10:11.302597: val_loss -0.7431
2025-02-25 20:10:11.302694: Pseudo dice [0.7955]
2025-02-25 20:10:11.302800: Epoch time: 67.28 s
2025-02-25 20:10:12.648017: 
2025-02-25 20:10:12.648235: Epoch 227
2025-02-25 20:10:12.648363: Current learning rate: 0.00793
2025-02-25 20:11:18.939287: train_loss -0.8087
2025-02-25 20:11:18.939695: val_loss -0.7435
2025-02-25 20:11:18.939787: Pseudo dice [0.7955]
2025-02-25 20:11:18.939896: Epoch time: 66.29 s
2025-02-25 20:11:20.320595: 
2025-02-25 20:11:20.320815: Epoch 228
2025-02-25 20:11:20.320944: Current learning rate: 0.00792
2025-02-25 20:12:26.392803: train_loss -0.8195
2025-02-25 20:12:26.393231: val_loss -0.7523
2025-02-25 20:12:26.393343: Pseudo dice [0.797]
2025-02-25 20:12:26.393457: Epoch time: 66.07 s
2025-02-25 20:12:28.127005: 
2025-02-25 20:12:28.127229: Epoch 229
2025-02-25 20:12:28.127366: Current learning rate: 0.00791
2025-02-25 20:13:35.211762: train_loss -0.8065
2025-02-25 20:13:35.212129: val_loss -0.7494
2025-02-25 20:13:35.212219: Pseudo dice [0.8053]
2025-02-25 20:13:35.212336: Epoch time: 67.09 s
2025-02-25 20:13:36.558566: 
2025-02-25 20:13:36.558794: Epoch 230
2025-02-25 20:13:36.558923: Current learning rate: 0.0079
2025-02-25 20:14:41.711360: train_loss -0.8019
2025-02-25 20:14:41.711720: val_loss -0.7495
2025-02-25 20:14:41.711823: Pseudo dice [0.8044]
2025-02-25 20:14:41.711923: Epoch time: 65.15 s
2025-02-25 20:14:43.007845: 
2025-02-25 20:14:43.008060: Epoch 231
2025-02-25 20:14:43.008181: Current learning rate: 0.00789
2025-02-25 20:15:51.048880: train_loss -0.8199
2025-02-25 20:15:51.049416: val_loss -0.7597
2025-02-25 20:15:51.049545: Pseudo dice [0.8108]
2025-02-25 20:15:51.049676: Epoch time: 68.04 s
2025-02-25 20:15:51.049761: Yayy! New best EMA pseudo Dice: 0.7982
2025-02-25 20:15:52.958474: 
2025-02-25 20:15:52.958696: Epoch 232
2025-02-25 20:15:52.958820: Current learning rate: 0.00789
2025-02-25 20:17:01.185364: train_loss -0.826
2025-02-25 20:17:01.185773: val_loss -0.7489
2025-02-25 20:17:01.185860: Pseudo dice [0.8048]
2025-02-25 20:17:01.185964: Epoch time: 68.23 s
2025-02-25 20:17:01.186049: Yayy! New best EMA pseudo Dice: 0.7989
2025-02-25 20:17:03.055514: 
2025-02-25 20:17:03.055790: Epoch 233
2025-02-25 20:17:03.055920: Current learning rate: 0.00788
2025-02-25 20:18:10.597664: train_loss -0.8283
2025-02-25 20:18:10.598473: val_loss -0.7614
2025-02-25 20:18:10.598564: Pseudo dice [0.8054]
2025-02-25 20:18:10.598650: Epoch time: 67.54 s
2025-02-25 20:18:10.598715: Yayy! New best EMA pseudo Dice: 0.7996
2025-02-25 20:18:12.490591: 
2025-02-25 20:18:12.490841: Epoch 234
2025-02-25 20:18:12.490968: Current learning rate: 0.00787
2025-02-25 20:19:19.353766: train_loss -0.8148
2025-02-25 20:19:19.354262: val_loss -0.7539
2025-02-25 20:19:19.354373: Pseudo dice [0.8045]
2025-02-25 20:19:19.354493: Epoch time: 66.86 s
2025-02-25 20:19:19.354596: Yayy! New best EMA pseudo Dice: 0.8
2025-02-25 20:19:21.213449: 
2025-02-25 20:19:21.213678: Epoch 235
2025-02-25 20:19:21.213804: Current learning rate: 0.00786
2025-02-25 20:20:27.818972: train_loss -0.8289
2025-02-25 20:20:27.819368: val_loss -0.7492
2025-02-25 20:20:27.819461: Pseudo dice [0.8017]
2025-02-25 20:20:27.819560: Epoch time: 66.61 s
2025-02-25 20:20:27.819636: Yayy! New best EMA pseudo Dice: 0.8002
2025-02-25 20:20:29.689407: 
2025-02-25 20:20:29.689626: Epoch 236
2025-02-25 20:20:29.689751: Current learning rate: 0.00785
2025-02-25 20:21:37.562585: train_loss -0.8292
2025-02-25 20:21:37.562982: val_loss -0.7515
2025-02-25 20:21:37.563495: Pseudo dice [0.8075]
2025-02-25 20:21:37.563960: Epoch time: 67.87 s
2025-02-25 20:21:37.564140: Yayy! New best EMA pseudo Dice: 0.8009
2025-02-25 20:21:39.513145: 
2025-02-25 20:21:39.513372: Epoch 237
2025-02-25 20:21:39.513499: Current learning rate: 0.00784
2025-02-25 20:22:44.185440: train_loss -0.8201
2025-02-25 20:22:44.185787: val_loss -0.7522
2025-02-25 20:22:44.185972: Pseudo dice [0.8058]
2025-02-25 20:22:44.186242: Epoch time: 64.67 s
2025-02-25 20:22:44.186399: Yayy! New best EMA pseudo Dice: 0.8014
2025-02-25 20:22:46.081276: 
2025-02-25 20:22:46.081502: Epoch 238
2025-02-25 20:22:46.081628: Current learning rate: 0.00783
2025-02-25 20:23:52.058559: train_loss -0.81
2025-02-25 20:23:52.058982: val_loss -0.7526
2025-02-25 20:23:52.059077: Pseudo dice [0.8075]
2025-02-25 20:23:52.059187: Epoch time: 65.98 s
2025-02-25 20:23:52.059268: Yayy! New best EMA pseudo Dice: 0.802
2025-02-25 20:23:53.948505: 
2025-02-25 20:23:53.948761: Epoch 239
2025-02-25 20:23:53.949203: Current learning rate: 0.00782
2025-02-25 20:25:00.295161: train_loss -0.8099
2025-02-25 20:25:00.295596: val_loss -0.7489
2025-02-25 20:25:00.295683: Pseudo dice [0.8035]
2025-02-25 20:25:00.295792: Epoch time: 66.35 s
2025-02-25 20:25:00.295872: Yayy! New best EMA pseudo Dice: 0.8022
2025-02-25 20:25:02.176524: 
2025-02-25 20:25:02.176756: Epoch 240
2025-02-25 20:25:02.176888: Current learning rate: 0.00781
2025-02-25 20:26:06.525941: train_loss -0.8207
2025-02-25 20:26:06.526410: val_loss -0.7438
2025-02-25 20:26:06.526503: Pseudo dice [0.7992]
2025-02-25 20:26:06.526614: Epoch time: 64.35 s
2025-02-25 20:26:08.312779: 
2025-02-25 20:26:08.312996: Epoch 241
2025-02-25 20:26:08.313124: Current learning rate: 0.0078
2025-02-25 20:27:15.224186: train_loss -0.8186
2025-02-25 20:27:15.224661: val_loss -0.7413
2025-02-25 20:27:15.224760: Pseudo dice [0.7987]
2025-02-25 20:27:15.224888: Epoch time: 66.91 s
2025-02-25 20:27:16.576264: 
2025-02-25 20:27:16.576508: Epoch 242
2025-02-25 20:27:16.576642: Current learning rate: 0.00779
2025-02-25 20:28:21.999015: train_loss -0.83
2025-02-25 20:28:21.999982: val_loss -0.7505
2025-02-25 20:28:22.000100: Pseudo dice [0.8021]
2025-02-25 20:28:22.000224: Epoch time: 65.42 s
2025-02-25 20:28:23.385147: 
2025-02-25 20:28:23.385389: Epoch 243
2025-02-25 20:28:23.385514: Current learning rate: 0.00778
2025-02-25 20:29:28.360384: train_loss -0.82
2025-02-25 20:29:28.360850: val_loss -0.7446
2025-02-25 20:29:28.360948: Pseudo dice [0.7997]
2025-02-25 20:29:28.361058: Epoch time: 64.98 s
2025-02-25 20:29:29.651809: 
2025-02-25 20:29:29.652035: Epoch 244
2025-02-25 20:29:29.652177: Current learning rate: 0.00777
2025-02-25 20:30:35.352229: train_loss -0.828
2025-02-25 20:30:35.352554: val_loss -0.7632
2025-02-25 20:30:35.352645: Pseudo dice [0.819]
2025-02-25 20:30:35.352756: Epoch time: 65.7 s
2025-02-25 20:30:35.352844: Yayy! New best EMA pseudo Dice: 0.8032
2025-02-25 20:30:37.208758: 
2025-02-25 20:30:37.209005: Epoch 245
2025-02-25 20:30:37.209126: Current learning rate: 0.00777
2025-02-25 20:31:43.211610: train_loss -0.8289
2025-02-25 20:31:43.212015: val_loss -0.7409
2025-02-25 20:31:43.212118: Pseudo dice [0.7917]
2025-02-25 20:31:43.212224: Epoch time: 66.0 s
2025-02-25 20:31:44.551824: 
2025-02-25 20:31:44.552052: Epoch 246
2025-02-25 20:31:44.552175: Current learning rate: 0.00776
2025-02-25 20:32:49.682866: train_loss -0.8175
2025-02-25 20:32:49.683323: val_loss -0.7477
2025-02-25 20:32:49.683417: Pseudo dice [0.7954]
2025-02-25 20:32:49.683522: Epoch time: 65.13 s
2025-02-25 20:32:50.986433: 
2025-02-25 20:32:50.986659: Epoch 247
2025-02-25 20:32:50.986787: Current learning rate: 0.00775
2025-02-25 20:33:55.328753: train_loss -0.8395
2025-02-25 20:33:55.329160: val_loss -0.7556
2025-02-25 20:33:55.329252: Pseudo dice [0.8039]
2025-02-25 20:33:55.329378: Epoch time: 64.34 s
2025-02-25 20:33:56.627486: 
2025-02-25 20:33:56.627700: Epoch 248
2025-02-25 20:33:56.627823: Current learning rate: 0.00774
2025-02-25 20:35:02.641720: train_loss -0.8054
2025-02-25 20:35:02.642086: val_loss -0.7633
2025-02-25 20:35:02.642193: Pseudo dice [0.8123]
2025-02-25 20:35:02.642330: Epoch time: 66.02 s
2025-02-25 20:35:03.976154: 
2025-02-25 20:35:03.976375: Epoch 249
2025-02-25 20:35:03.976496: Current learning rate: 0.00773
2025-02-25 20:36:09.871660: train_loss -0.804
2025-02-25 20:36:09.872099: val_loss -0.7514
2025-02-25 20:36:09.872185: Pseudo dice [0.8051]
2025-02-25 20:36:09.872294: Epoch time: 65.9 s
2025-02-25 20:36:11.777029: 
2025-02-25 20:36:11.777263: Epoch 250
2025-02-25 20:36:11.777407: Current learning rate: 0.00772
2025-02-25 20:37:16.881001: train_loss -0.8211
2025-02-25 20:37:16.881422: val_loss -0.756
2025-02-25 20:37:16.881519: Pseudo dice [0.8054]
2025-02-25 20:37:16.881634: Epoch time: 65.11 s
2025-02-25 20:37:18.255858: 
2025-02-25 20:37:18.256068: Epoch 251
2025-02-25 20:37:18.256194: Current learning rate: 0.00771
2025-02-25 20:38:24.589219: train_loss -0.837
2025-02-25 20:38:24.589652: val_loss -0.7506
2025-02-25 20:38:24.601621: Pseudo dice [0.8007]
2025-02-25 20:38:24.601838: Epoch time: 66.33 s
2025-02-25 20:38:25.912676: 
2025-02-25 20:38:25.912880: Epoch 252
2025-02-25 20:38:25.913000: Current learning rate: 0.0077
2025-02-25 20:39:32.012744: train_loss -0.8301
2025-02-25 20:39:32.013136: val_loss -0.7438
2025-02-25 20:39:32.013222: Pseudo dice [0.8034]
2025-02-25 20:39:32.013335: Epoch time: 66.1 s
2025-02-25 20:39:33.782778: 
2025-02-25 20:39:33.783014: Epoch 253
2025-02-25 20:39:33.783139: Current learning rate: 0.00769
2025-02-25 20:40:40.362922: train_loss -0.8205
2025-02-25 20:40:40.363418: val_loss -0.7456
2025-02-25 20:40:40.363534: Pseudo dice [0.7932]
2025-02-25 20:40:40.363648: Epoch time: 66.58 s
2025-02-25 20:40:41.752752: 
2025-02-25 20:40:41.752990: Epoch 254
2025-02-25 20:40:41.753115: Current learning rate: 0.00768
2025-02-25 20:41:47.056591: train_loss -0.8163
2025-02-25 20:41:47.056973: val_loss -0.7609
2025-02-25 20:41:47.057055: Pseudo dice [0.8063]
2025-02-25 20:41:47.057138: Epoch time: 65.31 s
2025-02-25 20:41:48.382480: 
2025-02-25 20:41:48.382706: Epoch 255
2025-02-25 20:41:48.382832: Current learning rate: 0.00767
2025-02-25 20:42:52.596319: train_loss -0.837
2025-02-25 20:42:52.596810: val_loss -0.7517
2025-02-25 20:42:52.596909: Pseudo dice [0.8058]
2025-02-25 20:42:52.597023: Epoch time: 64.22 s
2025-02-25 20:42:53.964426: 
2025-02-25 20:42:53.964642: Epoch 256
2025-02-25 20:42:53.964766: Current learning rate: 0.00766
2025-02-25 20:44:00.879445: train_loss -0.8338
2025-02-25 20:44:00.879854: val_loss -0.7701
2025-02-25 20:44:00.879942: Pseudo dice [0.8204]
2025-02-25 20:44:00.880048: Epoch time: 66.92 s
2025-02-25 20:44:00.880128: Yayy! New best EMA pseudo Dice: 0.8045
2025-02-25 20:44:02.793821: 
2025-02-25 20:44:02.794075: Epoch 257
2025-02-25 20:44:02.794202: Current learning rate: 0.00765
2025-02-25 20:45:07.961536: train_loss -0.839
2025-02-25 20:45:07.961890: val_loss -0.75
2025-02-25 20:45:07.961973: Pseudo dice [0.7957]
2025-02-25 20:45:07.962072: Epoch time: 65.17 s
2025-02-25 20:45:09.259095: 
2025-02-25 20:45:09.259369: Epoch 258
2025-02-25 20:45:09.259516: Current learning rate: 0.00764
2025-02-25 20:46:16.128582: train_loss -0.8363
2025-02-25 20:46:16.128987: val_loss -0.7424
2025-02-25 20:46:16.129077: Pseudo dice [0.792]
2025-02-25 20:46:16.129178: Epoch time: 66.87 s
2025-02-25 20:46:17.445576: 
2025-02-25 20:46:17.445804: Epoch 259
2025-02-25 20:46:17.445929: Current learning rate: 0.00764
2025-02-25 20:47:23.371495: train_loss -0.8308
2025-02-25 20:47:23.371885: val_loss -0.7568
2025-02-25 20:47:23.371974: Pseudo dice [0.8088]
2025-02-25 20:47:23.372078: Epoch time: 65.93 s
2025-02-25 20:47:24.670669: 
2025-02-25 20:47:24.670881: Epoch 260
2025-02-25 20:47:24.671000: Current learning rate: 0.00763
2025-02-25 20:48:28.938240: train_loss -0.8189
2025-02-25 20:48:28.938686: val_loss -0.7178
2025-02-25 20:48:28.938770: Pseudo dice [0.7697]
2025-02-25 20:48:28.938869: Epoch time: 64.27 s
2025-02-25 20:48:30.258193: 
2025-02-25 20:48:30.258423: Epoch 261
2025-02-25 20:48:30.258547: Current learning rate: 0.00762
2025-02-25 20:49:36.805839: train_loss -0.8075
2025-02-25 20:49:36.806243: val_loss -0.7328
2025-02-25 20:49:36.806449: Pseudo dice [0.7853]
2025-02-25 20:49:36.806563: Epoch time: 66.55 s
2025-02-25 20:49:38.095860: 
2025-02-25 20:49:38.096056: Epoch 262
2025-02-25 20:49:38.096182: Current learning rate: 0.00761
2025-02-25 20:50:42.389352: train_loss -0.7841
2025-02-25 20:50:42.389822: val_loss -0.7339
2025-02-25 20:50:42.389917: Pseudo dice [0.7867]
2025-02-25 20:50:42.390025: Epoch time: 64.29 s
2025-02-25 20:50:43.669114: 
2025-02-25 20:50:43.669337: Epoch 263
2025-02-25 20:50:43.669461: Current learning rate: 0.0076
2025-02-25 20:51:50.375190: train_loss -0.7428
2025-02-25 20:51:50.375494: val_loss -0.7005
2025-02-25 20:51:50.375735: Pseudo dice [0.7468]
2025-02-25 20:51:50.375859: Epoch time: 66.71 s
2025-02-25 20:51:51.704129: 
2025-02-25 20:51:51.704393: Epoch 264
2025-02-25 20:51:51.704533: Current learning rate: 0.00759
2025-02-25 20:52:59.532318: train_loss -0.7323
2025-02-25 20:52:59.546561: val_loss -0.6853
2025-02-25 20:52:59.546866: Pseudo dice [0.7573]
2025-02-25 20:52:59.546998: Epoch time: 67.83 s
2025-02-25 20:53:00.877746: 
2025-02-25 20:53:00.877963: Epoch 265
2025-02-25 20:53:00.878089: Current learning rate: 0.00758
2025-02-25 20:54:06.521948: train_loss -0.7778
2025-02-25 20:54:06.522390: val_loss -0.7523
2025-02-25 20:54:06.522503: Pseudo dice [0.7984]
2025-02-25 20:54:06.522611: Epoch time: 65.65 s
2025-02-25 20:54:08.263507: 
2025-02-25 20:54:08.263733: Epoch 266
2025-02-25 20:54:08.263856: Current learning rate: 0.00757
2025-02-25 20:55:15.897827: train_loss -0.8027
2025-02-25 20:55:15.898253: val_loss -0.7385
2025-02-25 20:55:15.898359: Pseudo dice [0.7859]
2025-02-25 20:55:15.898463: Epoch time: 67.64 s
2025-02-25 20:55:17.220979: 
2025-02-25 20:55:17.221241: Epoch 267
2025-02-25 20:55:17.221396: Current learning rate: 0.00756
2025-02-25 20:56:23.082835: train_loss -0.8023
2025-02-25 20:56:23.083252: val_loss -0.7531
2025-02-25 20:56:23.083373: Pseudo dice [0.8041]
2025-02-25 20:56:23.083498: Epoch time: 65.86 s
2025-02-25 20:56:24.428267: 
2025-02-25 20:56:24.428479: Epoch 268
2025-02-25 20:56:24.428608: Current learning rate: 0.00755
2025-02-25 20:57:30.251029: train_loss -0.7834
2025-02-25 20:57:30.251459: val_loss -0.7159
2025-02-25 20:57:30.251565: Pseudo dice [0.781]
2025-02-25 20:57:30.251690: Epoch time: 65.82 s
2025-02-25 20:57:31.586225: 
2025-02-25 20:57:31.586471: Epoch 269
2025-02-25 20:57:31.586596: Current learning rate: 0.00754
2025-02-25 20:58:38.981423: train_loss -0.8066
2025-02-25 20:58:38.981840: val_loss -0.7555
2025-02-25 20:58:38.981925: Pseudo dice [0.8042]
2025-02-25 20:58:38.982028: Epoch time: 67.4 s
2025-02-25 20:58:40.394693: 
2025-02-25 20:58:40.395010: Epoch 270
2025-02-25 20:58:40.395139: Current learning rate: 0.00753
2025-02-25 20:59:46.843313: train_loss -0.8071
2025-02-25 20:59:46.843730: val_loss -0.746
2025-02-25 20:59:46.843817: Pseudo dice [0.7968]
2025-02-25 20:59:46.843922: Epoch time: 66.45 s
2025-02-25 20:59:48.163717: 
2025-02-25 20:59:48.163942: Epoch 271
2025-02-25 20:59:48.164066: Current learning rate: 0.00752
2025-02-25 21:00:52.924294: train_loss -0.8073
2025-02-25 21:00:52.927923: val_loss -0.7237
2025-02-25 21:00:52.928033: Pseudo dice [0.7819]
2025-02-25 21:00:52.928144: Epoch time: 64.76 s
2025-02-25 21:00:54.256450: 
2025-02-25 21:00:54.256674: Epoch 272
2025-02-25 21:00:54.256797: Current learning rate: 0.00751
2025-02-25 21:02:00.852142: train_loss -0.8219
2025-02-25 21:02:00.852611: val_loss -0.7535
2025-02-25 21:02:00.852703: Pseudo dice [0.8036]
2025-02-25 21:02:00.852806: Epoch time: 66.6 s
2025-02-25 21:02:02.159545: 
2025-02-25 21:02:02.159746: Epoch 273
2025-02-25 21:02:02.159868: Current learning rate: 0.00751
2025-02-25 21:03:07.316278: train_loss -0.82
2025-02-25 21:03:07.316827: val_loss -0.7484
2025-02-25 21:03:07.316919: Pseudo dice [0.8044]
2025-02-25 21:03:07.317014: Epoch time: 65.16 s
2025-02-25 21:03:08.605511: 
2025-02-25 21:03:08.605735: Epoch 274
2025-02-25 21:03:08.605858: Current learning rate: 0.0075
2025-02-25 21:04:11.833837: train_loss -0.8157
2025-02-25 21:04:11.834244: val_loss -0.7427
2025-02-25 21:04:11.834346: Pseudo dice [0.8032]
2025-02-25 21:04:11.834464: Epoch time: 63.23 s
2025-02-25 21:04:13.143292: 
2025-02-25 21:04:13.143549: Epoch 275
2025-02-25 21:04:13.143730: Current learning rate: 0.00749
2025-02-25 21:05:17.448002: train_loss -0.8308
2025-02-25 21:05:17.448452: val_loss -0.7486
2025-02-25 21:05:17.448536: Pseudo dice [0.7998]
2025-02-25 21:05:17.448648: Epoch time: 64.31 s
2025-02-25 21:05:18.813216: 
2025-02-25 21:05:18.813442: Epoch 276
2025-02-25 21:05:18.813566: Current learning rate: 0.00748
2025-02-25 21:06:23.779553: train_loss -0.83
2025-02-25 21:06:23.779946: val_loss -0.7443
2025-02-25 21:06:23.780039: Pseudo dice [0.7933]
2025-02-25 21:06:23.780152: Epoch time: 64.97 s
2025-02-25 21:06:25.094719: 
2025-02-25 21:06:25.094966: Epoch 277
2025-02-25 21:06:25.095087: Current learning rate: 0.00747
2025-02-25 21:07:29.999541: train_loss -0.8387
2025-02-25 21:07:29.999949: val_loss -0.7531
2025-02-25 21:07:30.000044: Pseudo dice [0.8028]
2025-02-25 21:07:30.000153: Epoch time: 64.91 s
2025-02-25 21:07:31.750693: 
2025-02-25 21:07:31.750921: Epoch 278
2025-02-25 21:07:31.751046: Current learning rate: 0.00746
2025-02-25 21:08:37.363115: train_loss -0.8391
2025-02-25 21:08:37.363600: val_loss -0.7365
2025-02-25 21:08:37.365483: Pseudo dice [0.7965]
2025-02-25 21:08:37.365806: Epoch time: 65.61 s
2025-02-25 21:08:38.649236: 
2025-02-25 21:08:38.649489: Epoch 279
2025-02-25 21:08:38.649613: Current learning rate: 0.00745
2025-02-25 21:09:42.604098: train_loss -0.8276
2025-02-25 21:09:42.604529: val_loss -0.7298
2025-02-25 21:09:42.604612: Pseudo dice [0.7904]
2025-02-25 21:09:42.604715: Epoch time: 63.96 s
2025-02-25 21:09:43.953183: 
2025-02-25 21:09:43.953472: Epoch 280
2025-02-25 21:09:43.953658: Current learning rate: 0.00744
2025-02-25 21:10:48.864623: train_loss -0.8266
2025-02-25 21:10:48.864982: val_loss -0.7221
2025-02-25 21:10:48.865063: Pseudo dice [0.7724]
2025-02-25 21:10:48.865155: Epoch time: 64.91 s
2025-02-25 21:10:50.204179: 
2025-02-25 21:10:50.204424: Epoch 281
2025-02-25 21:10:50.204549: Current learning rate: 0.00743
2025-02-25 21:11:53.877803: train_loss -0.8239
2025-02-25 21:11:53.878280: val_loss -0.7422
2025-02-25 21:11:53.878411: Pseudo dice [0.7926]
2025-02-25 21:11:53.878529: Epoch time: 63.68 s
2025-02-25 21:11:55.148750: 
2025-02-25 21:11:55.148988: Epoch 282
2025-02-25 21:11:55.149105: Current learning rate: 0.00742
2025-02-25 21:12:58.870432: train_loss -0.8395
2025-02-25 21:12:58.870995: val_loss -0.7294
2025-02-25 21:12:58.871128: Pseudo dice [0.7806]
2025-02-25 21:12:58.871259: Epoch time: 63.72 s
2025-02-25 21:13:00.179102: 
2025-02-25 21:13:00.179373: Epoch 283
2025-02-25 21:13:00.179498: Current learning rate: 0.00741
2025-02-25 21:14:05.498181: train_loss -0.8491
2025-02-25 21:14:05.498565: val_loss -0.7487
2025-02-25 21:14:05.498659: Pseudo dice [0.8027]
2025-02-25 21:14:05.498740: Epoch time: 65.32 s
2025-02-25 21:14:06.802909: 
2025-02-25 21:14:06.803142: Epoch 284
2025-02-25 21:14:06.803266: Current learning rate: 0.0074
2025-02-25 21:15:12.881409: train_loss -0.8247
2025-02-25 21:15:12.881772: val_loss -0.741
2025-02-25 21:15:12.881845: Pseudo dice [0.7898]
2025-02-25 21:15:12.881942: Epoch time: 66.08 s
2025-02-25 21:15:14.188401: 
2025-02-25 21:15:14.188653: Epoch 285
2025-02-25 21:15:14.188776: Current learning rate: 0.00739
2025-02-25 21:16:19.761380: train_loss -0.7878
2025-02-25 21:16:19.761804: val_loss -0.7147
2025-02-25 21:16:19.761889: Pseudo dice [0.7785]
2025-02-25 21:16:19.761989: Epoch time: 65.57 s
2025-02-25 21:16:21.073249: 
2025-02-25 21:16:21.073483: Epoch 286
2025-02-25 21:16:21.073616: Current learning rate: 0.00738
2025-02-25 21:17:24.327121: train_loss -0.8131
2025-02-25 21:17:24.327542: val_loss -0.7527
2025-02-25 21:17:24.327629: Pseudo dice [0.7966]
2025-02-25 21:17:24.327732: Epoch time: 63.26 s
2025-02-25 21:17:25.668116: 
2025-02-25 21:17:25.668336: Epoch 287
2025-02-25 21:17:25.668464: Current learning rate: 0.00738
2025-02-25 21:18:30.657842: train_loss -0.8221
2025-02-25 21:18:30.658243: val_loss -0.752
2025-02-25 21:18:30.658342: Pseudo dice [0.8033]
2025-02-25 21:18:30.658458: Epoch time: 64.99 s
2025-02-25 21:18:31.994186: 
2025-02-25 21:18:31.994401: Epoch 288
2025-02-25 21:18:31.994524: Current learning rate: 0.00737
2025-02-25 21:19:37.092637: train_loss -0.8303
2025-02-25 21:19:37.093070: val_loss -0.7637
2025-02-25 21:19:37.093150: Pseudo dice [0.8119]
2025-02-25 21:19:37.093337: Epoch time: 65.1 s
2025-02-25 21:19:38.404334: 
2025-02-25 21:19:38.404561: Epoch 289
2025-02-25 21:19:38.404685: Current learning rate: 0.00736
2025-02-25 21:20:45.154931: train_loss -0.8187
2025-02-25 21:20:45.155343: val_loss -0.7455
2025-02-25 21:20:45.155446: Pseudo dice [0.8017]
2025-02-25 21:20:45.155560: Epoch time: 66.75 s
2025-02-25 21:20:46.901980: 
2025-02-25 21:20:46.902207: Epoch 290
2025-02-25 21:20:46.902344: Current learning rate: 0.00735
2025-02-25 21:21:53.415332: train_loss -0.8366
2025-02-25 21:21:53.415753: val_loss -0.7534
2025-02-25 21:21:53.416368: Pseudo dice [0.8044]
2025-02-25 21:21:53.416489: Epoch time: 66.51 s
2025-02-25 21:21:54.744513: 
2025-02-25 21:21:54.744750: Epoch 291
2025-02-25 21:21:54.744876: Current learning rate: 0.00734
2025-02-25 21:23:01.413776: train_loss -0.8376
2025-02-25 21:23:01.414170: val_loss -0.7558
2025-02-25 21:23:01.414252: Pseudo dice [0.8087]
2025-02-25 21:23:01.414365: Epoch time: 66.67 s
2025-02-25 21:23:02.680833: 
2025-02-25 21:23:02.681055: Epoch 292
2025-02-25 21:23:02.681177: Current learning rate: 0.00733
2025-02-25 21:24:08.794494: train_loss -0.8445
2025-02-25 21:24:08.794941: val_loss -0.748
2025-02-25 21:24:08.795028: Pseudo dice [0.7963]
2025-02-25 21:24:08.795138: Epoch time: 66.12 s
2025-02-25 21:24:10.069969: 
2025-02-25 21:24:10.070194: Epoch 293
2025-02-25 21:24:10.070326: Current learning rate: 0.00732
2025-02-25 21:25:17.096044: train_loss -0.8477
2025-02-25 21:25:17.096450: val_loss -0.7513
2025-02-25 21:25:17.096533: Pseudo dice [0.8041]
2025-02-25 21:25:17.096631: Epoch time: 67.03 s
2025-02-25 21:25:18.407179: 
2025-02-25 21:25:18.407459: Epoch 294
2025-02-25 21:25:18.407583: Current learning rate: 0.00731
2025-02-25 21:26:24.875663: train_loss -0.8546
2025-02-25 21:26:24.876090: val_loss -0.7483
2025-02-25 21:26:24.876172: Pseudo dice [0.8011]
2025-02-25 21:26:24.876273: Epoch time: 66.47 s
2025-02-25 21:26:26.261024: 
2025-02-25 21:26:26.261255: Epoch 295
2025-02-25 21:26:26.261388: Current learning rate: 0.0073
2025-02-25 21:27:34.341651: train_loss -0.8395
2025-02-25 21:27:34.342084: val_loss -0.7362
2025-02-25 21:27:34.342186: Pseudo dice [0.8015]
2025-02-25 21:27:34.342291: Epoch time: 68.08 s
2025-02-25 21:27:35.671173: 
2025-02-25 21:27:35.671398: Epoch 296
2025-02-25 21:27:35.671519: Current learning rate: 0.00729
2025-02-25 21:28:44.128963: train_loss -0.8575
2025-02-25 21:28:44.129268: val_loss -0.7411
2025-02-25 21:28:44.129369: Pseudo dice [0.7995]
2025-02-25 21:28:44.129472: Epoch time: 68.46 s
2025-02-25 21:28:45.525926: 
2025-02-25 21:28:45.526134: Epoch 297
2025-02-25 21:28:45.526252: Current learning rate: 0.00728
2025-02-25 21:29:54.749586: train_loss -0.8493
2025-02-25 21:29:54.749949: val_loss -0.7472
2025-02-25 21:29:54.750028: Pseudo dice [0.7949]
2025-02-25 21:29:54.750113: Epoch time: 69.23 s
2025-02-25 21:29:56.091957: 
2025-02-25 21:29:56.092192: Epoch 298
2025-02-25 21:29:56.092335: Current learning rate: 0.00727
2025-02-25 21:31:04.066795: train_loss -0.8336
2025-02-25 21:31:04.067150: val_loss -0.7598
2025-02-25 21:31:04.067234: Pseudo dice [0.8023]
2025-02-25 21:31:04.067343: Epoch time: 67.98 s
2025-02-25 21:31:05.439568: 
2025-02-25 21:31:05.439789: Epoch 299
2025-02-25 21:31:05.439923: Current learning rate: 0.00726
2025-02-25 21:32:12.819277: train_loss -0.8041
2025-02-25 21:32:12.819734: val_loss -0.7265
2025-02-25 21:32:12.819821: Pseudo dice [0.7923]
2025-02-25 21:32:12.819922: Epoch time: 67.38 s
2025-02-25 21:32:14.688507: 
2025-02-25 21:32:14.688708: Epoch 300
2025-02-25 21:32:14.688831: Current learning rate: 0.00725
2025-02-25 21:33:22.706772: train_loss -0.7529
2025-02-25 21:33:22.707205: val_loss -0.7242
2025-02-25 21:33:22.707291: Pseudo dice [0.7758]
2025-02-25 21:33:22.707408: Epoch time: 68.02 s
2025-02-25 21:33:24.396151: 
2025-02-25 21:33:24.396389: Epoch 301
2025-02-25 21:33:24.396530: Current learning rate: 0.00724
2025-02-25 21:34:30.009380: train_loss -0.7567
2025-02-25 21:34:30.009793: val_loss -0.7159
2025-02-25 21:34:30.009883: Pseudo dice [0.7712]
2025-02-25 21:34:30.009984: Epoch time: 65.61 s
2025-02-25 21:34:31.351799: 
2025-02-25 21:34:31.352031: Epoch 302
2025-02-25 21:34:31.352154: Current learning rate: 0.00724
2025-02-25 21:35:37.411770: train_loss -0.7703
2025-02-25 21:35:37.412151: val_loss -0.7308
2025-02-25 21:35:37.412247: Pseudo dice [0.7855]
2025-02-25 21:35:37.412374: Epoch time: 66.06 s
2025-02-25 21:35:38.800642: 
2025-02-25 21:35:38.800866: Epoch 303
2025-02-25 21:35:38.800997: Current learning rate: 0.00723
2025-02-25 21:36:44.631166: train_loss -0.8011
2025-02-25 21:36:44.631547: val_loss -0.7358
2025-02-25 21:36:44.631639: Pseudo dice [0.7873]
2025-02-25 21:36:44.631743: Epoch time: 65.83 s
2025-02-25 21:36:46.002540: 
2025-02-25 21:36:46.002767: Epoch 304
2025-02-25 21:36:46.002893: Current learning rate: 0.00722
2025-02-25 21:37:51.548527: train_loss -0.7722
2025-02-25 21:37:51.548982: val_loss -0.7261
2025-02-25 21:37:51.549078: Pseudo dice [0.783]
2025-02-25 21:37:51.549183: Epoch time: 65.55 s
2025-02-25 21:37:53.026431: 
2025-02-25 21:37:53.026649: Epoch 305
2025-02-25 21:37:53.026784: Current learning rate: 0.00721
2025-02-25 21:38:57.987104: train_loss -0.8043
2025-02-25 21:38:57.987561: val_loss -0.7287
2025-02-25 21:38:57.987645: Pseudo dice [0.7818]
2025-02-25 21:38:57.987750: Epoch time: 64.96 s
2025-02-25 21:38:59.315158: 
2025-02-25 21:38:59.315398: Epoch 306
2025-02-25 21:38:59.315524: Current learning rate: 0.0072
2025-02-25 21:40:03.786479: train_loss -0.768
2025-02-25 21:40:03.786933: val_loss -0.7206
2025-02-25 21:40:03.787060: Pseudo dice [0.7718]
2025-02-25 21:40:03.787179: Epoch time: 64.47 s
2025-02-25 21:40:05.090799: 
2025-02-25 21:40:05.090998: Epoch 307
2025-02-25 21:40:05.091115: Current learning rate: 0.00719
2025-02-25 21:41:09.538525: train_loss -0.7639
2025-02-25 21:41:09.538912: val_loss -0.7152
2025-02-25 21:41:09.539002: Pseudo dice [0.7648]
2025-02-25 21:41:09.539104: Epoch time: 64.45 s
2025-02-25 21:41:10.924549: 
2025-02-25 21:41:10.924751: Epoch 308
2025-02-25 21:41:10.924874: Current learning rate: 0.00718
2025-02-25 21:42:16.385161: train_loss -0.7853
2025-02-25 21:42:16.385532: val_loss -0.7214
2025-02-25 21:42:16.385621: Pseudo dice [0.7723]
2025-02-25 21:42:16.385732: Epoch time: 65.46 s
2025-02-25 21:42:17.705335: 
2025-02-25 21:42:17.705554: Epoch 309
2025-02-25 21:42:17.705678: Current learning rate: 0.00717
2025-02-25 21:43:22.568397: train_loss -0.8046
2025-02-25 21:43:22.568858: val_loss -0.723
2025-02-25 21:43:22.568958: Pseudo dice [0.779]
2025-02-25 21:43:22.569075: Epoch time: 64.86 s
2025-02-25 21:43:23.943345: 
2025-02-25 21:43:23.943559: Epoch 310
2025-02-25 21:43:23.943687: Current learning rate: 0.00716
2025-02-25 21:44:29.811705: train_loss -0.8076
2025-02-25 21:44:29.812108: val_loss -0.7332
2025-02-25 21:44:29.812201: Pseudo dice [0.784]
2025-02-25 21:44:29.812320: Epoch time: 65.87 s
2025-02-25 21:44:31.131858: 
2025-02-25 21:44:31.132090: Epoch 311
2025-02-25 21:44:31.132215: Current learning rate: 0.00715
2025-02-25 21:45:36.229617: train_loss -0.7943
2025-02-25 21:45:36.230014: val_loss -0.7438
2025-02-25 21:45:36.230104: Pseudo dice [0.7952]
2025-02-25 21:45:36.230210: Epoch time: 65.1 s
2025-02-25 21:45:37.550200: 
2025-02-25 21:45:37.550413: Epoch 312
2025-02-25 21:45:37.550538: Current learning rate: 0.00714
2025-02-25 21:46:43.785732: train_loss -0.8185
2025-02-25 21:46:43.786156: val_loss -0.7444
2025-02-25 21:46:43.786247: Pseudo dice [0.795]
2025-02-25 21:46:43.786583: Epoch time: 66.24 s
2025-02-25 21:46:45.509825: 
2025-02-25 21:46:45.510051: Epoch 313
2025-02-25 21:46:45.510178: Current learning rate: 0.00713
2025-02-25 21:47:48.959696: train_loss -0.8314
2025-02-25 21:47:48.960135: val_loss -0.7467
2025-02-25 21:47:48.960236: Pseudo dice [0.7989]
2025-02-25 21:47:48.960365: Epoch time: 63.45 s
2025-02-25 21:47:50.327705: 
2025-02-25 21:47:50.327937: Epoch 314
2025-02-25 21:47:50.328066: Current learning rate: 0.00712
2025-02-25 21:48:54.444924: train_loss -0.8203
2025-02-25 21:48:54.445409: val_loss -0.7525
2025-02-25 21:48:54.445516: Pseudo dice [0.7986]
2025-02-25 21:48:54.445636: Epoch time: 64.12 s
2025-02-25 21:48:55.775932: 
2025-02-25 21:48:55.776162: Epoch 315
2025-02-25 21:48:55.776289: Current learning rate: 0.00711
2025-02-25 21:50:01.995494: train_loss -0.8269
2025-02-25 21:50:01.996116: val_loss -0.7311
2025-02-25 21:50:01.996220: Pseudo dice [0.7858]
2025-02-25 21:50:01.996352: Epoch time: 66.22 s
2025-02-25 21:50:03.357316: 
2025-02-25 21:50:03.357543: Epoch 316
2025-02-25 21:50:03.357666: Current learning rate: 0.0071
2025-02-25 21:51:08.771518: train_loss -0.8181
2025-02-25 21:51:08.771971: val_loss -0.7247
2025-02-25 21:51:08.772660: Pseudo dice [0.7768]
2025-02-25 21:51:08.772794: Epoch time: 65.42 s
2025-02-25 21:51:10.080335: 
2025-02-25 21:51:10.080549: Epoch 317
2025-02-25 21:51:10.080671: Current learning rate: 0.0071
2025-02-25 21:52:16.314108: train_loss -0.8323
2025-02-25 21:52:16.314552: val_loss -0.7489
2025-02-25 21:52:16.320887: Pseudo dice [0.7965]
2025-02-25 21:52:16.321066: Epoch time: 66.24 s
2025-02-25 21:52:17.700403: 
2025-02-25 21:52:17.700629: Epoch 318
2025-02-25 21:52:17.700752: Current learning rate: 0.00709
2025-02-25 21:53:23.172523: train_loss -0.8437
2025-02-25 21:53:23.172921: val_loss -0.7499
2025-02-25 21:53:23.173015: Pseudo dice [0.8013]
2025-02-25 21:53:23.173123: Epoch time: 65.47 s
2025-02-25 21:53:24.474706: 
2025-02-25 21:53:24.474946: Epoch 319
2025-02-25 21:53:24.475074: Current learning rate: 0.00708
2025-02-25 21:54:29.174069: train_loss -0.8481
2025-02-25 21:54:29.174484: val_loss -0.7377
2025-02-25 21:54:29.174576: Pseudo dice [0.7901]
2025-02-25 21:54:29.174683: Epoch time: 64.7 s
2025-02-25 21:54:30.438105: 
2025-02-25 21:54:30.438321: Epoch 320
2025-02-25 21:54:30.438445: Current learning rate: 0.00707
2025-02-25 21:55:35.336147: train_loss -0.8387
2025-02-25 21:55:35.336681: val_loss -0.7567
2025-02-25 21:55:35.336919: Pseudo dice [0.8042]
2025-02-25 21:55:35.337034: Epoch time: 64.9 s
2025-02-25 21:55:36.601618: 
2025-02-25 21:55:36.601864: Epoch 321
2025-02-25 21:55:36.601991: Current learning rate: 0.00706
2025-02-25 21:56:41.170201: train_loss -0.8504
2025-02-25 21:56:41.170637: val_loss -0.7372
2025-02-25 21:56:41.170732: Pseudo dice [0.7948]
2025-02-25 21:56:41.170860: Epoch time: 64.57 s
2025-02-25 21:56:42.574275: 
2025-02-25 21:56:42.574527: Epoch 322
2025-02-25 21:56:42.574652: Current learning rate: 0.00705
2025-02-25 21:57:48.382033: train_loss -0.851
2025-02-25 21:57:48.382444: val_loss -0.742
2025-02-25 21:57:48.382534: Pseudo dice [0.7949]
2025-02-25 21:57:48.382635: Epoch time: 65.81 s
2025-02-25 21:57:49.752253: 
2025-02-25 21:57:49.752494: Epoch 323
2025-02-25 21:57:49.752620: Current learning rate: 0.00704
2025-02-25 21:58:56.526655: train_loss -0.8514
2025-02-25 21:58:56.527182: val_loss -0.7437
2025-02-25 21:58:56.527319: Pseudo dice [0.8007]
2025-02-25 21:58:56.527458: Epoch time: 66.78 s
2025-02-25 21:58:57.926344: 
2025-02-25 21:58:57.926582: Epoch 324
2025-02-25 21:58:57.926705: Current learning rate: 0.00703
2025-02-25 22:00:03.520958: train_loss -0.8516
2025-02-25 22:00:03.521360: val_loss -0.7404
2025-02-25 22:00:03.521448: Pseudo dice [0.7935]
2025-02-25 22:00:03.521545: Epoch time: 65.6 s
2025-02-25 22:00:05.213785: 
2025-02-25 22:00:05.214007: Epoch 325
2025-02-25 22:00:05.214125: Current learning rate: 0.00702
2025-02-25 22:01:11.329196: train_loss -0.8515
2025-02-25 22:01:11.329642: val_loss -0.7549
2025-02-25 22:01:11.329732: Pseudo dice [0.8048]
2025-02-25 22:01:11.329841: Epoch time: 66.12 s
2025-02-25 22:01:12.652119: 
2025-02-25 22:01:12.652352: Epoch 326
2025-02-25 22:01:12.652474: Current learning rate: 0.00701
2025-02-25 22:02:17.962036: train_loss -0.8608
2025-02-25 22:02:17.962449: val_loss -0.7442
2025-02-25 22:02:17.962526: Pseudo dice [0.7967]
2025-02-25 22:02:17.962619: Epoch time: 65.31 s
2025-02-25 22:02:19.312324: 
2025-02-25 22:02:19.312539: Epoch 327
2025-02-25 22:02:19.312665: Current learning rate: 0.007
2025-02-25 22:03:23.869344: train_loss -0.8536
2025-02-25 22:03:23.869763: val_loss -0.7392
2025-02-25 22:03:23.869848: Pseudo dice [0.7909]
2025-02-25 22:03:23.869949: Epoch time: 64.56 s
2025-02-25 22:03:25.266281: 
2025-02-25 22:03:25.266554: Epoch 328
2025-02-25 22:03:25.266682: Current learning rate: 0.00699
2025-02-25 22:04:30.032342: train_loss -0.8613
2025-02-25 22:04:30.032854: val_loss -0.7397
2025-02-25 22:04:30.032964: Pseudo dice [0.7966]
2025-02-25 22:04:30.033095: Epoch time: 64.77 s
2025-02-25 22:04:31.323025: 
2025-02-25 22:04:31.323253: Epoch 329
2025-02-25 22:04:31.323384: Current learning rate: 0.00698
2025-02-25 22:05:38.462582: train_loss -0.852
2025-02-25 22:05:38.463045: val_loss -0.7565
2025-02-25 22:05:38.463135: Pseudo dice [0.8064]
2025-02-25 22:05:38.463239: Epoch time: 67.14 s
2025-02-25 22:05:39.714571: 
2025-02-25 22:05:39.714809: Epoch 330
2025-02-25 22:05:39.714935: Current learning rate: 0.00697
2025-02-25 22:06:44.999808: train_loss -0.8654
2025-02-25 22:06:45.000226: val_loss -0.748
2025-02-25 22:06:45.000366: Pseudo dice [0.7972]
2025-02-25 22:06:45.000483: Epoch time: 65.29 s
2025-02-25 22:06:46.351565: 
2025-02-25 22:06:46.351803: Epoch 331
2025-02-25 22:06:46.351927: Current learning rate: 0.00696
2025-02-25 22:07:53.668520: train_loss -0.844
2025-02-25 22:07:53.668902: val_loss -0.7593
2025-02-25 22:07:53.668987: Pseudo dice [0.8014]
2025-02-25 22:07:53.669090: Epoch time: 67.32 s
2025-02-25 22:07:55.025483: 
2025-02-25 22:07:55.025708: Epoch 332
2025-02-25 22:07:55.025835: Current learning rate: 0.00696
2025-02-25 22:09:01.622966: train_loss -0.8483
2025-02-25 22:09:01.623437: val_loss -0.7462
2025-02-25 22:09:01.623580: Pseudo dice [0.8]
2025-02-25 22:09:01.623686: Epoch time: 66.6 s
2025-02-25 22:09:02.950072: 
2025-02-25 22:09:02.950284: Epoch 333
2025-02-25 22:09:02.950430: Current learning rate: 0.00695
2025-02-25 22:10:07.897768: train_loss -0.8415
2025-02-25 22:10:07.898183: val_loss -0.7386
2025-02-25 22:10:07.898270: Pseudo dice [0.7882]
2025-02-25 22:10:07.898599: Epoch time: 64.95 s
2025-02-25 22:10:09.177758: 
2025-02-25 22:10:09.177969: Epoch 334
2025-02-25 22:10:09.178096: Current learning rate: 0.00694
2025-02-25 22:11:15.649348: train_loss -0.8146
2025-02-25 22:11:15.649741: val_loss -0.7501
2025-02-25 22:11:15.649852: Pseudo dice [0.8029]
2025-02-25 22:11:15.649953: Epoch time: 66.47 s
2025-02-25 22:11:16.969899: 
2025-02-25 22:11:16.970122: Epoch 335
2025-02-25 22:11:16.970255: Current learning rate: 0.00693
2025-02-25 22:12:24.815132: train_loss -0.8314
2025-02-25 22:12:24.815553: val_loss -0.7453
2025-02-25 22:12:24.815638: Pseudo dice [0.7918]
2025-02-25 22:12:24.815737: Epoch time: 67.85 s
2025-02-25 22:12:26.242815: 
2025-02-25 22:12:26.243031: Epoch 336
2025-02-25 22:12:26.243167: Current learning rate: 0.00692
2025-02-25 22:13:31.074491: train_loss -0.8511
2025-02-25 22:13:31.074881: val_loss -0.7438
2025-02-25 22:13:31.074976: Pseudo dice [0.7976]
2025-02-25 22:13:31.075082: Epoch time: 64.83 s
2025-02-25 22:13:32.882842: 
2025-02-25 22:13:32.883075: Epoch 337
2025-02-25 22:13:32.883201: Current learning rate: 0.00691
2025-02-25 22:14:39.678761: train_loss -0.854
2025-02-25 22:14:39.679250: val_loss -0.7557
2025-02-25 22:14:39.679370: Pseudo dice [0.8067]
2025-02-25 22:14:39.679480: Epoch time: 66.8 s
2025-02-25 22:14:41.091313: 
2025-02-25 22:14:41.091540: Epoch 338
2025-02-25 22:14:41.091666: Current learning rate: 0.0069
2025-02-25 22:15:46.718681: train_loss -0.869
2025-02-25 22:15:46.719174: val_loss -0.7502
2025-02-25 22:15:46.719268: Pseudo dice [0.7973]
2025-02-25 22:15:46.719388: Epoch time: 65.63 s
2025-02-25 22:15:48.007745: 
2025-02-25 22:15:48.007977: Epoch 339
2025-02-25 22:15:48.008113: Current learning rate: 0.00689
2025-02-25 22:16:54.849583: train_loss -0.8573
2025-02-25 22:16:54.849972: val_loss -0.7559
2025-02-25 22:16:54.850059: Pseudo dice [0.8054]
2025-02-25 22:16:54.850162: Epoch time: 66.84 s
2025-02-25 22:16:56.144494: 
2025-02-25 22:16:56.144708: Epoch 340
2025-02-25 22:16:56.144838: Current learning rate: 0.00688
2025-02-25 22:18:04.090663: train_loss -0.8528
2025-02-25 22:18:04.090989: val_loss -0.7329
2025-02-25 22:18:04.091063: Pseudo dice [0.786]
2025-02-25 22:18:04.091152: Epoch time: 67.95 s
2025-02-25 22:18:05.447197: 
2025-02-25 22:18:05.447483: Epoch 341
2025-02-25 22:18:05.447667: Current learning rate: 0.00687
2025-02-25 22:19:11.587510: train_loss -0.8172
2025-02-25 22:19:11.587861: val_loss -0.7412
2025-02-25 22:19:11.587960: Pseudo dice [0.7895]
2025-02-25 22:19:11.588313: Epoch time: 66.14 s
2025-02-25 22:19:12.983902: 
2025-02-25 22:19:12.984144: Epoch 342
2025-02-25 22:19:12.984270: Current learning rate: 0.00686
2025-02-25 22:20:18.948586: train_loss -0.8427
2025-02-25 22:20:18.949003: val_loss -0.7505
2025-02-25 22:20:18.949558: Pseudo dice [0.8022]
2025-02-25 22:20:18.949677: Epoch time: 65.97 s
2025-02-25 22:20:20.270595: 
2025-02-25 22:20:20.270830: Epoch 343
2025-02-25 22:20:20.270952: Current learning rate: 0.00685
2025-02-25 22:21:27.317315: train_loss -0.8263
2025-02-25 22:21:27.317718: val_loss -0.7443
2025-02-25 22:21:27.317807: Pseudo dice [0.7985]
2025-02-25 22:21:27.317905: Epoch time: 67.05 s
2025-02-25 22:21:28.642764: 
2025-02-25 22:21:28.642993: Epoch 344
2025-02-25 22:21:28.643108: Current learning rate: 0.00684
2025-02-25 22:22:33.843209: train_loss -0.8291
2025-02-25 22:22:33.843636: val_loss -0.7302
2025-02-25 22:22:33.843720: Pseudo dice [0.7888]
2025-02-25 22:22:33.843821: Epoch time: 65.2 s
2025-02-25 22:22:35.187013: 
2025-02-25 22:22:35.187218: Epoch 345
2025-02-25 22:22:35.187348: Current learning rate: 0.00683
2025-02-25 22:23:40.084585: train_loss -0.8379
2025-02-25 22:23:40.084970: val_loss -0.7389
2025-02-25 22:23:40.085050: Pseudo dice [0.7922]
2025-02-25 22:23:40.085147: Epoch time: 64.9 s
2025-02-25 22:23:41.495161: 
2025-02-25 22:23:41.495423: Epoch 346
2025-02-25 22:23:41.495567: Current learning rate: 0.00682
2025-02-25 22:24:45.947889: train_loss -0.8404
2025-02-25 22:24:45.948326: val_loss -0.7335
2025-02-25 22:24:45.948425: Pseudo dice [0.7838]
2025-02-25 22:24:45.948534: Epoch time: 64.45 s
2025-02-25 22:24:47.309748: 
2025-02-25 22:24:47.309976: Epoch 347
2025-02-25 22:24:47.310101: Current learning rate: 0.00681
2025-02-25 22:25:51.763113: train_loss -0.8573
2025-02-25 22:25:51.763843: val_loss -0.751
2025-02-25 22:25:51.763992: Pseudo dice [0.7986]
2025-02-25 22:25:51.764182: Epoch time: 64.45 s
2025-02-25 22:25:53.472728: 
2025-02-25 22:25:53.472977: Epoch 348
2025-02-25 22:25:53.473101: Current learning rate: 0.0068
2025-02-25 22:26:58.723375: train_loss -0.8517
2025-02-25 22:26:58.723785: val_loss -0.7456
2025-02-25 22:26:58.723879: Pseudo dice [0.7987]
2025-02-25 22:26:58.723985: Epoch time: 65.25 s
2025-02-25 22:27:00.081908: 
2025-02-25 22:27:00.082164: Epoch 349
2025-02-25 22:27:00.082293: Current learning rate: 0.0068
2025-02-25 22:28:06.084928: train_loss -0.8454
2025-02-25 22:28:06.085438: val_loss -0.7265
2025-02-25 22:28:06.085567: Pseudo dice [0.7731]
2025-02-25 22:28:06.085669: Epoch time: 66.0 s
2025-02-25 22:28:07.953105: 
2025-02-25 22:28:07.953348: Epoch 350
2025-02-25 22:28:07.953472: Current learning rate: 0.00679
2025-02-25 22:29:13.171602: train_loss -0.8358
2025-02-25 22:29:13.171916: val_loss -0.757
2025-02-25 22:29:13.172012: Pseudo dice [0.8034]
2025-02-25 22:29:13.172118: Epoch time: 65.22 s
2025-02-25 22:29:14.541645: 
2025-02-25 22:29:14.541916: Epoch 351
2025-02-25 22:29:14.542111: Current learning rate: 0.00678
2025-02-25 22:30:18.319070: train_loss -0.8391
2025-02-25 22:30:18.319459: val_loss -0.7338
2025-02-25 22:30:18.319538: Pseudo dice [0.7811]
2025-02-25 22:30:18.319622: Epoch time: 63.78 s
2025-02-25 22:30:19.648333: 
2025-02-25 22:30:19.648553: Epoch 352
2025-02-25 22:30:19.648679: Current learning rate: 0.00677
2025-02-25 22:31:26.254054: train_loss -0.8504
2025-02-25 22:31:26.254512: val_loss -0.7554
2025-02-25 22:31:26.254606: Pseudo dice [0.8128]
2025-02-25 22:31:26.254719: Epoch time: 66.61 s
2025-02-25 22:31:27.590516: 
2025-02-25 22:31:27.590724: Epoch 353
2025-02-25 22:31:27.590839: Current learning rate: 0.00676
2025-02-25 22:32:31.126368: train_loss -0.8409
2025-02-25 22:32:31.126800: val_loss -0.7618
2025-02-25 22:32:31.126892: Pseudo dice [0.8099]
2025-02-25 22:32:31.127000: Epoch time: 63.54 s
2025-02-25 22:32:32.452801: 
2025-02-25 22:32:32.453042: Epoch 354
2025-02-25 22:32:32.453164: Current learning rate: 0.00675
2025-02-25 22:33:37.958248: train_loss -0.8552
2025-02-25 22:33:37.958698: val_loss -0.7539
2025-02-25 22:33:37.958789: Pseudo dice [0.8006]
2025-02-25 22:33:37.958897: Epoch time: 65.51 s
2025-02-25 22:33:39.304741: 
2025-02-25 22:33:39.304955: Epoch 355
2025-02-25 22:33:39.305081: Current learning rate: 0.00674
2025-02-25 22:34:42.118374: train_loss -0.8601
2025-02-25 22:34:42.118739: val_loss -0.746
2025-02-25 22:34:42.118821: Pseudo dice [0.7973]
2025-02-25 22:34:42.118916: Epoch time: 62.82 s
2025-02-25 22:34:43.600941: 
2025-02-25 22:34:43.601158: Epoch 356
2025-02-25 22:34:43.601281: Current learning rate: 0.00673
2025-02-25 22:35:49.131465: train_loss -0.8603
2025-02-25 22:35:49.131947: val_loss -0.7629
2025-02-25 22:35:49.132046: Pseudo dice [0.8109]
2025-02-25 22:35:49.132163: Epoch time: 65.53 s
2025-02-25 22:35:50.480965: 
2025-02-25 22:35:50.481205: Epoch 357
2025-02-25 22:35:50.481391: Current learning rate: 0.00672
2025-02-25 22:36:56.163150: train_loss -0.8466
2025-02-25 22:36:56.163563: val_loss -0.7125
2025-02-25 22:36:56.163651: Pseudo dice [0.7853]
2025-02-25 22:36:56.163756: Epoch time: 65.68 s
2025-02-25 22:36:57.557732: 
2025-02-25 22:36:57.557937: Epoch 358
2025-02-25 22:36:57.558069: Current learning rate: 0.00671
2025-02-25 22:38:05.504543: train_loss -0.8569
2025-02-25 22:38:05.504936: val_loss -0.7263
2025-02-25 22:38:05.505039: Pseudo dice [0.7807]
2025-02-25 22:38:05.505163: Epoch time: 67.95 s
2025-02-25 22:38:07.246959: 
2025-02-25 22:38:07.247199: Epoch 359
2025-02-25 22:38:07.247330: Current learning rate: 0.0067
2025-02-25 22:39:14.273849: train_loss -0.8599
2025-02-25 22:39:14.274271: val_loss -0.7427
2025-02-25 22:39:14.274384: Pseudo dice [0.7923]
2025-02-25 22:39:14.274489: Epoch time: 67.03 s
2025-02-25 22:39:15.688032: 
2025-02-25 22:39:15.688325: Epoch 360
2025-02-25 22:39:15.688465: Current learning rate: 0.00669
2025-02-25 22:40:20.684813: train_loss -0.8641
2025-02-25 22:40:20.685228: val_loss -0.7466
2025-02-25 22:40:20.685316: Pseudo dice [0.7953]
2025-02-25 22:40:20.685414: Epoch time: 65.0 s
2025-02-25 22:40:22.033881: 
2025-02-25 22:40:22.034119: Epoch 361
2025-02-25 22:40:22.034239: Current learning rate: 0.00668
2025-02-25 22:41:29.578969: train_loss -0.86
2025-02-25 22:41:29.579439: val_loss -0.7372
2025-02-25 22:41:29.579569: Pseudo dice [0.7843]
2025-02-25 22:41:29.579669: Epoch time: 67.55 s
2025-02-25 22:41:30.905600: 
2025-02-25 22:41:30.905815: Epoch 362
2025-02-25 22:41:30.905933: Current learning rate: 0.00667
2025-02-25 22:42:35.568995: train_loss -0.8728
2025-02-25 22:42:35.569442: val_loss -0.7432
2025-02-25 22:42:35.569530: Pseudo dice [0.793]
2025-02-25 22:42:35.569641: Epoch time: 64.66 s
2025-02-25 22:42:36.946133: 
2025-02-25 22:42:36.946421: Epoch 363
2025-02-25 22:42:36.946551: Current learning rate: 0.00666
2025-02-25 22:43:41.746036: train_loss -0.8716
2025-02-25 22:43:41.746487: val_loss -0.7337
2025-02-25 22:43:41.746580: Pseudo dice [0.7864]
2025-02-25 22:43:41.746682: Epoch time: 64.8 s
2025-02-25 22:43:43.095172: 
2025-02-25 22:43:43.095403: Epoch 364
2025-02-25 22:43:43.095537: Current learning rate: 0.00665
2025-02-25 22:44:48.842621: train_loss -0.8772
2025-02-25 22:44:48.843030: val_loss -0.7534
2025-02-25 22:44:48.843128: Pseudo dice [0.8034]
2025-02-25 22:44:48.843236: Epoch time: 65.75 s
2025-02-25 22:44:50.190693: 
2025-02-25 22:44:50.190916: Epoch 365
2025-02-25 22:44:50.191034: Current learning rate: 0.00665
2025-02-25 22:45:56.098555: train_loss -0.878
2025-02-25 22:45:56.098886: val_loss -0.7303
2025-02-25 22:45:56.098969: Pseudo dice [0.7812]
2025-02-25 22:45:56.099069: Epoch time: 65.91 s
2025-02-25 22:45:57.480859: 
2025-02-25 22:45:57.481075: Epoch 366
2025-02-25 22:45:57.481199: Current learning rate: 0.00664
2025-02-25 22:47:03.064570: train_loss -0.8631
2025-02-25 22:47:03.064964: val_loss -0.7343
2025-02-25 22:47:03.065048: Pseudo dice [0.7958]
2025-02-25 22:47:03.065148: Epoch time: 65.59 s
2025-02-25 22:47:04.444926: 
2025-02-25 22:47:04.445142: Epoch 367
2025-02-25 22:47:04.445271: Current learning rate: 0.00663
2025-02-25 22:48:07.394639: train_loss -0.8677
2025-02-25 22:48:07.394968: val_loss -0.7543
2025-02-25 22:48:07.395061: Pseudo dice [0.8019]
2025-02-25 22:48:07.395176: Epoch time: 62.95 s
2025-02-25 22:48:08.785804: 
2025-02-25 22:48:08.786027: Epoch 368
2025-02-25 22:48:08.786150: Current learning rate: 0.00662
2025-02-25 22:49:12.798960: train_loss -0.8732
2025-02-25 22:49:12.799365: val_loss -0.746
2025-02-25 22:49:12.799854: Pseudo dice [0.8029]
2025-02-25 22:49:12.799965: Epoch time: 64.01 s
2025-02-25 22:49:14.147224: 
2025-02-25 22:49:14.147432: Epoch 369
2025-02-25 22:49:14.147557: Current learning rate: 0.00661
2025-02-25 22:50:20.357128: train_loss -0.8707
2025-02-25 22:50:20.357649: val_loss -0.7428
2025-02-25 22:50:20.357747: Pseudo dice [0.7921]
2025-02-25 22:50:20.357864: Epoch time: 66.21 s
2025-02-25 22:50:21.811881: 
2025-02-25 22:50:21.812102: Epoch 370
2025-02-25 22:50:21.812237: Current learning rate: 0.0066
2025-02-25 22:51:25.587792: train_loss -0.8731
2025-02-25 22:51:25.588149: val_loss -0.7546
2025-02-25 22:51:25.588255: Pseudo dice [0.7992]
2025-02-25 22:51:25.588383: Epoch time: 63.78 s
2025-02-25 22:51:27.410763: 
2025-02-25 22:51:27.411009: Epoch 371
2025-02-25 22:51:27.411133: Current learning rate: 0.00659
2025-02-25 22:52:32.340526: train_loss -0.8662
2025-02-25 22:52:32.340881: val_loss -0.7288
2025-02-25 22:52:32.340954: Pseudo dice [0.7833]
2025-02-25 22:52:32.341037: Epoch time: 64.93 s
2025-02-25 22:52:33.715635: 
2025-02-25 22:52:33.715860: Epoch 372
2025-02-25 22:52:33.715983: Current learning rate: 0.00658
2025-02-25 22:53:38.777432: train_loss -0.87
2025-02-25 22:53:38.777739: val_loss -0.7449
2025-02-25 22:53:38.777830: Pseudo dice [0.8012]
2025-02-25 22:53:38.777955: Epoch time: 65.06 s
2025-02-25 22:53:40.158220: 
2025-02-25 22:53:40.158491: Epoch 373
2025-02-25 22:53:40.158618: Current learning rate: 0.00657
2025-02-25 22:54:44.848736: train_loss -0.8754
2025-02-25 22:54:44.849137: val_loss -0.744
2025-02-25 22:54:44.849232: Pseudo dice [0.7974]
2025-02-25 22:54:44.849353: Epoch time: 64.69 s
2025-02-25 22:54:46.303957: 
2025-02-25 22:54:46.304202: Epoch 374
2025-02-25 22:54:46.304341: Current learning rate: 0.00656
2025-02-25 22:55:54.061540: train_loss -0.8655
2025-02-25 22:55:54.061968: val_loss -0.7486
2025-02-25 22:55:54.062060: Pseudo dice [0.8043]
2025-02-25 22:55:54.062170: Epoch time: 67.76 s
2025-02-25 22:55:55.430196: 
2025-02-25 22:55:55.430442: Epoch 375
2025-02-25 22:55:55.430574: Current learning rate: 0.00655
2025-02-25 22:57:00.340996: train_loss -0.8574
2025-02-25 22:57:00.341519: val_loss -0.7424
2025-02-25 22:57:00.341610: Pseudo dice [0.7973]
2025-02-25 22:57:00.341726: Epoch time: 64.91 s
2025-02-25 22:57:01.680768: 
2025-02-25 22:57:01.681037: Epoch 376
2025-02-25 22:57:01.681160: Current learning rate: 0.00654
2025-02-25 22:58:06.957091: train_loss -0.848
2025-02-25 22:58:06.957541: val_loss -0.7262
2025-02-25 22:58:06.957631: Pseudo dice [0.7853]
2025-02-25 22:58:06.957737: Epoch time: 65.28 s
2025-02-25 22:58:08.365606: 
2025-02-25 22:58:08.365833: Epoch 377
2025-02-25 22:58:08.365960: Current learning rate: 0.00653
2025-02-25 22:59:14.394244: train_loss -0.8474
2025-02-25 22:59:14.394800: val_loss -0.7437
2025-02-25 22:59:14.394909: Pseudo dice [0.7993]
2025-02-25 22:59:14.395027: Epoch time: 66.03 s
2025-02-25 22:59:15.743590: 
2025-02-25 22:59:15.743802: Epoch 378
2025-02-25 22:59:15.743920: Current learning rate: 0.00652
2025-02-25 23:00:23.061110: train_loss -0.8698
2025-02-25 23:00:23.061550: val_loss -0.7329
2025-02-25 23:00:23.061631: Pseudo dice [0.7927]
2025-02-25 23:00:23.061723: Epoch time: 67.32 s
2025-02-25 23:00:24.428216: 
2025-02-25 23:00:24.428453: Epoch 379
2025-02-25 23:00:24.428576: Current learning rate: 0.00651
2025-02-25 23:01:28.987818: train_loss -0.8601
2025-02-25 23:01:28.988257: val_loss -0.7524
2025-02-25 23:01:28.988368: Pseudo dice [0.8014]
2025-02-25 23:01:28.988482: Epoch time: 64.56 s
2025-02-25 23:01:30.331212: 
2025-02-25 23:01:30.331439: Epoch 380
2025-02-25 23:01:30.331566: Current learning rate: 0.0065
2025-02-25 23:02:33.626283: train_loss -0.8682
2025-02-25 23:02:33.626746: val_loss -0.731
2025-02-25 23:02:33.626944: Pseudo dice [0.7864]
2025-02-25 23:02:33.627076: Epoch time: 63.3 s
2025-02-25 23:02:34.988255: 
2025-02-25 23:02:34.988470: Epoch 381
2025-02-25 23:02:34.988597: Current learning rate: 0.00649
2025-02-25 23:03:41.270692: train_loss -0.8336
2025-02-25 23:03:41.271164: val_loss -0.7386
2025-02-25 23:03:41.271255: Pseudo dice [0.7909]
2025-02-25 23:03:41.271400: Epoch time: 66.28 s
2025-02-25 23:03:43.025987: 
2025-02-25 23:03:43.026214: Epoch 382
2025-02-25 23:03:43.026352: Current learning rate: 0.00648
2025-02-25 23:04:47.386237: train_loss -0.8459
2025-02-25 23:04:47.386777: val_loss -0.7315
2025-02-25 23:04:47.386880: Pseudo dice [0.7849]
2025-02-25 23:04:47.386987: Epoch time: 64.36 s
2025-02-25 23:04:48.770464: 
2025-02-25 23:04:48.770727: Epoch 383
2025-02-25 23:04:48.770864: Current learning rate: 0.00648
2025-02-25 23:05:54.595531: train_loss -0.8566
2025-02-25 23:05:54.595902: val_loss -0.7387
2025-02-25 23:05:54.595988: Pseudo dice [0.786]
2025-02-25 23:05:54.596089: Epoch time: 65.83 s
2025-02-25 23:05:55.977437: 
2025-02-25 23:05:55.977660: Epoch 384
2025-02-25 23:05:55.977790: Current learning rate: 0.00647
2025-02-25 23:07:01.915310: train_loss -0.8739
2025-02-25 23:07:01.915673: val_loss -0.735
2025-02-25 23:07:01.915763: Pseudo dice [0.7854]
2025-02-25 23:07:01.915868: Epoch time: 65.94 s
2025-02-25 23:07:03.303667: 
2025-02-25 23:07:03.303887: Epoch 385
2025-02-25 23:07:03.304013: Current learning rate: 0.00646
2025-02-25 23:08:09.006571: train_loss -0.8716
2025-02-25 23:08:09.006977: val_loss -0.7041
2025-02-25 23:08:09.007064: Pseudo dice [0.7938]
2025-02-25 23:08:09.007168: Epoch time: 65.7 s
2025-02-25 23:08:10.446835: 
2025-02-25 23:08:10.447071: Epoch 386
2025-02-25 23:08:10.447196: Current learning rate: 0.00645
2025-02-25 23:09:12.456729: train_loss -0.7848
2025-02-25 23:09:12.457233: val_loss -0.7454
2025-02-25 23:09:12.457339: Pseudo dice [0.801]
2025-02-25 23:09:12.462616: Epoch time: 62.01 s
2025-02-25 23:09:13.711994: 
2025-02-25 23:09:13.712190: Epoch 387
2025-02-25 23:09:13.712311: Current learning rate: 0.00644
2025-02-25 23:10:17.885886: train_loss -0.7643
2025-02-25 23:10:17.886244: val_loss -0.7425
2025-02-25 23:10:17.886357: Pseudo dice [0.7977]
2025-02-25 23:10:17.886446: Epoch time: 64.18 s
2025-02-25 23:10:19.172745: 
2025-02-25 23:10:19.172976: Epoch 388
2025-02-25 23:10:19.173093: Current learning rate: 0.00643
2025-02-25 23:11:21.982731: train_loss -0.8085
2025-02-25 23:11:21.983110: val_loss -0.7501
2025-02-25 23:11:21.983182: Pseudo dice [0.8003]
2025-02-25 23:11:21.983257: Epoch time: 62.81 s
2025-02-25 23:11:23.214637: 
2025-02-25 23:11:23.214839: Epoch 389
2025-02-25 23:11:23.214958: Current learning rate: 0.00642
2025-02-25 23:12:24.699540: train_loss -0.8031
2025-02-25 23:12:24.699955: val_loss -0.7195
2025-02-25 23:12:24.700049: Pseudo dice [0.7711]
2025-02-25 23:12:24.700142: Epoch time: 61.49 s
2025-02-25 23:12:25.936423: 
2025-02-25 23:12:25.936630: Epoch 390
2025-02-25 23:12:25.936743: Current learning rate: 0.00641
2025-02-25 23:13:28.781052: train_loss -0.8012
2025-02-25 23:13:28.781488: val_loss -0.7489
2025-02-25 23:13:28.781585: Pseudo dice [0.7963]
2025-02-25 23:13:28.781680: Epoch time: 62.85 s
2025-02-25 23:13:30.010695: 
2025-02-25 23:13:30.010905: Epoch 391
2025-02-25 23:13:30.011022: Current learning rate: 0.0064
2025-02-25 23:14:33.404108: train_loss -0.8423
2025-02-25 23:14:33.404586: val_loss -0.7449
2025-02-25 23:14:33.404666: Pseudo dice [0.7973]
2025-02-25 23:14:33.404762: Epoch time: 63.39 s
2025-02-25 23:14:34.654308: 
2025-02-25 23:14:34.654521: Epoch 392
2025-02-25 23:14:34.654633: Current learning rate: 0.00639
2025-02-25 23:15:39.162956: train_loss -0.8429
2025-02-25 23:15:39.163466: val_loss -0.7057
2025-02-25 23:15:39.163565: Pseudo dice [0.7683]
2025-02-25 23:15:39.163683: Epoch time: 64.51 s
2025-02-25 23:15:40.953274: 
2025-02-25 23:15:40.953563: Epoch 393
2025-02-25 23:15:40.953700: Current learning rate: 0.00638
2025-02-25 23:16:46.833844: train_loss -0.7582
2025-02-25 23:16:46.834344: val_loss -0.6963
2025-02-25 23:16:46.834444: Pseudo dice [0.7624]
2025-02-25 23:16:46.834552: Epoch time: 65.88 s
2025-02-25 23:16:48.216398: 
2025-02-25 23:16:48.216626: Epoch 394
2025-02-25 23:16:48.216754: Current learning rate: 0.00637
2025-02-25 23:17:54.079507: train_loss -0.7599
2025-02-25 23:17:54.079962: val_loss -0.7143
2025-02-25 23:17:54.080604: Pseudo dice [0.7795]
2025-02-25 23:17:54.080756: Epoch time: 65.86 s
2025-02-25 23:17:55.497975: 
2025-02-25 23:17:55.498217: Epoch 395
2025-02-25 23:17:55.498359: Current learning rate: 0.00636
2025-02-25 23:18:59.072894: train_loss -0.8113
2025-02-25 23:18:59.073367: val_loss -0.7271
2025-02-25 23:18:59.073519: Pseudo dice [0.7822]
2025-02-25 23:18:59.073669: Epoch time: 63.58 s
2025-02-25 23:19:00.470678: 
2025-02-25 23:19:00.470909: Epoch 396
2025-02-25 23:19:00.471034: Current learning rate: 0.00635
2025-02-25 23:20:07.033784: train_loss -0.8256
2025-02-25 23:20:07.034245: val_loss -0.749
2025-02-25 23:20:07.034363: Pseudo dice [0.7996]
2025-02-25 23:20:07.034481: Epoch time: 66.56 s
2025-02-25 23:20:08.437497: 
2025-02-25 23:20:08.437765: Epoch 397
2025-02-25 23:20:08.437888: Current learning rate: 0.00634
2025-02-25 23:21:15.691193: train_loss -0.8235
2025-02-25 23:21:15.691649: val_loss -0.761
2025-02-25 23:21:15.691740: Pseudo dice [0.8041]
2025-02-25 23:21:15.691843: Epoch time: 67.26 s
2025-02-25 23:21:17.136453: 
2025-02-25 23:21:17.136678: Epoch 398
2025-02-25 23:21:17.136808: Current learning rate: 0.00633
2025-02-25 23:22:23.137290: train_loss -0.8274
2025-02-25 23:22:23.137779: val_loss -0.7304
2025-02-25 23:22:23.137878: Pseudo dice [0.7867]
2025-02-25 23:22:23.137982: Epoch time: 66.0 s
2025-02-25 23:22:24.513159: 
2025-02-25 23:22:24.513391: Epoch 399
2025-02-25 23:22:24.513516: Current learning rate: 0.00632
2025-02-25 23:23:30.258142: train_loss -0.8285
2025-02-25 23:23:30.258599: val_loss -0.7402
2025-02-25 23:23:30.258694: Pseudo dice [0.7965]
2025-02-25 23:23:30.258804: Epoch time: 65.75 s
2025-02-25 23:23:32.184646: 
2025-02-25 23:23:32.184861: Epoch 400
2025-02-25 23:23:32.184990: Current learning rate: 0.00631
2025-02-25 23:24:39.000174: train_loss -0.8463
2025-02-25 23:24:39.000575: val_loss -0.7484
2025-02-25 23:24:39.000666: Pseudo dice [0.8047]
2025-02-25 23:24:39.000774: Epoch time: 66.82 s
2025-02-25 23:24:40.364491: 
2025-02-25 23:24:40.364699: Epoch 401
2025-02-25 23:24:40.364825: Current learning rate: 0.0063
2025-02-25 23:25:46.354426: train_loss -0.8662
2025-02-25 23:25:46.354867: val_loss -0.7582
2025-02-25 23:25:46.354958: Pseudo dice [0.8078]
2025-02-25 23:25:46.355063: Epoch time: 65.99 s
2025-02-25 23:25:47.702787: 
2025-02-25 23:25:47.702995: Epoch 402
2025-02-25 23:25:47.703124: Current learning rate: 0.0063
2025-02-25 23:26:54.265801: train_loss -0.8638
2025-02-25 23:26:54.266204: val_loss -0.7286
2025-02-25 23:26:54.266294: Pseudo dice [0.7894]
2025-02-25 23:26:54.266418: Epoch time: 66.56 s
2025-02-25 23:26:55.610541: 
2025-02-25 23:26:55.610740: Epoch 403
2025-02-25 23:26:55.610860: Current learning rate: 0.00629
2025-02-25 23:28:00.166589: train_loss -0.8411
2025-02-25 23:28:00.166884: val_loss -0.7219
2025-02-25 23:28:00.166969: Pseudo dice [0.7742]
2025-02-25 23:28:00.167066: Epoch time: 64.56 s
2025-02-25 23:28:01.920661: 
2025-02-25 23:28:01.920895: Epoch 404
2025-02-25 23:28:01.921031: Current learning rate: 0.00628
2025-02-25 23:29:06.159306: train_loss -0.8486
2025-02-25 23:29:06.159697: val_loss -0.7397
2025-02-25 23:29:06.159787: Pseudo dice [0.7875]
2025-02-25 23:29:06.159916: Epoch time: 64.24 s
2025-02-25 23:29:07.590097: 
2025-02-25 23:29:07.590353: Epoch 405
2025-02-25 23:29:07.590477: Current learning rate: 0.00627
2025-02-25 23:30:14.184199: train_loss -0.8596
2025-02-25 23:30:14.184626: val_loss -0.7458
2025-02-25 23:30:14.184720: Pseudo dice [0.798]
2025-02-25 23:30:14.184833: Epoch time: 66.6 s
2025-02-25 23:30:15.593692: 
2025-02-25 23:30:15.593915: Epoch 406
2025-02-25 23:30:15.594038: Current learning rate: 0.00626
2025-02-25 23:31:22.986026: train_loss -0.8519
2025-02-25 23:31:22.986434: val_loss -0.7437
2025-02-25 23:31:22.986597: Pseudo dice [0.796]
2025-02-25 23:31:22.986693: Epoch time: 67.39 s
2025-02-25 23:31:24.435868: 
2025-02-25 23:31:24.436116: Epoch 407
2025-02-25 23:31:24.436240: Current learning rate: 0.00625
2025-02-25 23:32:29.971064: train_loss -0.8748
2025-02-25 23:32:29.971496: val_loss -0.7506
2025-02-25 23:32:29.971588: Pseudo dice [0.7986]
2025-02-25 23:32:29.971693: Epoch time: 65.54 s
2025-02-25 23:32:31.342116: 
2025-02-25 23:32:31.342335: Epoch 408
2025-02-25 23:32:31.342461: Current learning rate: 0.00624
2025-02-25 23:33:38.187093: train_loss -0.8735
2025-02-25 23:33:38.187544: val_loss -0.7365
2025-02-25 23:33:38.187638: Pseudo dice [0.7915]
2025-02-25 23:33:38.187738: Epoch time: 66.85 s
2025-02-25 23:33:39.587369: 
2025-02-25 23:33:39.587616: Epoch 409
2025-02-25 23:33:39.587767: Current learning rate: 0.00623
2025-02-25 23:34:46.008917: train_loss -0.8713
2025-02-25 23:34:46.009572: val_loss -0.7478
2025-02-25 23:34:46.009672: Pseudo dice [0.791]
2025-02-25 23:34:46.009787: Epoch time: 66.42 s
2025-02-25 23:34:47.411645: 
2025-02-25 23:34:47.411863: Epoch 410
2025-02-25 23:34:47.411988: Current learning rate: 0.00622
2025-02-25 23:35:55.565999: train_loss -0.8716
2025-02-25 23:35:55.566399: val_loss -0.7447
2025-02-25 23:35:55.566571: Pseudo dice [0.7932]
2025-02-25 23:35:55.566677: Epoch time: 68.16 s
2025-02-25 23:35:56.905209: 
2025-02-25 23:35:56.905437: Epoch 411
2025-02-25 23:35:56.905560: Current learning rate: 0.00621
2025-02-25 23:37:03.182876: train_loss -0.871
2025-02-25 23:37:03.183258: val_loss -0.7401
2025-02-25 23:37:03.183371: Pseudo dice [0.794]
2025-02-25 23:37:03.183475: Epoch time: 66.28 s
2025-02-25 23:37:04.536229: 
2025-02-25 23:37:04.536451: Epoch 412
2025-02-25 23:37:04.536573: Current learning rate: 0.0062
2025-02-25 23:38:12.896982: train_loss -0.8638
2025-02-25 23:38:12.897653: val_loss -0.7454
2025-02-25 23:38:12.897756: Pseudo dice [0.7971]
2025-02-25 23:38:12.897869: Epoch time: 68.36 s
2025-02-25 23:38:14.284321: 
2025-02-25 23:38:14.284533: Epoch 413
2025-02-25 23:38:14.284668: Current learning rate: 0.00619
2025-02-25 23:39:21.324797: train_loss -0.8859
2025-02-25 23:39:21.325695: val_loss -0.7456
2025-02-25 23:39:21.325971: Pseudo dice [0.7913]
2025-02-25 23:39:21.326078: Epoch time: 67.04 s
2025-02-25 23:39:22.699735: 
2025-02-25 23:39:22.699951: Epoch 414
2025-02-25 23:39:22.700078: Current learning rate: 0.00618
2025-02-25 23:40:28.723427: train_loss -0.8695
2025-02-25 23:40:28.723819: val_loss -0.7491
2025-02-25 23:40:28.723903: Pseudo dice [0.7885]
2025-02-25 23:40:28.724001: Epoch time: 66.03 s
2025-02-25 23:40:30.052583: 
2025-02-25 23:40:30.052804: Epoch 415
2025-02-25 23:40:30.052938: Current learning rate: 0.00617
2025-02-25 23:41:36.744271: train_loss -0.8792
2025-02-25 23:41:36.744654: val_loss -0.7303
2025-02-25 23:41:36.744744: Pseudo dice [0.7892]
2025-02-25 23:41:36.744843: Epoch time: 66.69 s
2025-02-25 23:41:38.443136: 
2025-02-25 23:41:38.443392: Epoch 416
2025-02-25 23:41:38.443529: Current learning rate: 0.00616
2025-02-25 23:42:44.652549: train_loss -0.8778
2025-02-25 23:42:44.652960: val_loss -0.7436
2025-02-25 23:42:44.653047: Pseudo dice [0.8009]
2025-02-25 23:42:44.653142: Epoch time: 66.21 s
2025-02-25 23:42:46.002319: 
2025-02-25 23:42:46.002566: Epoch 417
2025-02-25 23:42:46.002716: Current learning rate: 0.00615
2025-02-25 23:43:52.179837: train_loss -0.8638
2025-02-25 23:43:52.180292: val_loss -0.7478
2025-02-25 23:43:52.180401: Pseudo dice [0.7996]
2025-02-25 23:43:52.180515: Epoch time: 66.18 s
2025-02-25 23:43:53.517552: 
2025-02-25 23:43:53.517795: Epoch 418
2025-02-25 23:43:53.517922: Current learning rate: 0.00614
2025-02-25 23:44:59.419919: train_loss -0.8449
2025-02-25 23:44:59.420386: val_loss -0.7338
2025-02-25 23:44:59.420491: Pseudo dice [0.7878]
2025-02-25 23:44:59.420604: Epoch time: 65.9 s
2025-02-25 23:45:00.745898: 
2025-02-25 23:45:00.746150: Epoch 419
2025-02-25 23:45:00.746275: Current learning rate: 0.00613
2025-02-25 23:46:06.761001: train_loss -0.8374
2025-02-25 23:46:06.761409: val_loss -0.7405
2025-02-25 23:46:06.761497: Pseudo dice [0.7948]
2025-02-25 23:46:06.761589: Epoch time: 66.02 s
2025-02-25 23:46:08.066572: 
2025-02-25 23:46:08.066800: Epoch 420
2025-02-25 23:46:08.066926: Current learning rate: 0.00612
2025-02-25 23:47:12.871577: train_loss -0.8511
2025-02-25 23:47:12.871997: val_loss -0.7442
2025-02-25 23:47:12.872587: Pseudo dice [0.7986]
2025-02-25 23:47:12.872703: Epoch time: 64.81 s
2025-02-25 23:47:14.195730: 
2025-02-25 23:47:14.195966: Epoch 421
2025-02-25 23:47:14.196089: Current learning rate: 0.00612
2025-02-25 23:48:19.127149: train_loss -0.8573
2025-02-25 23:48:19.127559: val_loss -0.7495
2025-02-25 23:48:19.127644: Pseudo dice [0.7961]
2025-02-25 23:48:19.127746: Epoch time: 64.93 s
2025-02-25 23:48:20.565433: 
2025-02-25 23:48:20.565671: Epoch 422
2025-02-25 23:48:20.565794: Current learning rate: 0.00611
2025-02-25 23:49:26.315099: train_loss -0.8672
2025-02-25 23:49:26.315543: val_loss -0.7366
2025-02-25 23:49:26.315633: Pseudo dice [0.7904]
2025-02-25 23:49:26.315745: Epoch time: 65.75 s
2025-02-25 23:49:27.681195: 
2025-02-25 23:49:27.681430: Epoch 423
2025-02-25 23:49:27.681551: Current learning rate: 0.0061
2025-02-25 23:50:32.690756: train_loss -0.8556
2025-02-25 23:50:32.691168: val_loss -0.7284
2025-02-25 23:50:32.691259: Pseudo dice [0.7812]
2025-02-25 23:50:32.691409: Epoch time: 65.01 s
2025-02-25 23:50:34.025351: 
2025-02-25 23:50:34.025559: Epoch 424
2025-02-25 23:50:34.025681: Current learning rate: 0.00609
2025-02-25 23:51:38.789287: train_loss -0.8521
2025-02-25 23:51:38.789742: val_loss -0.7235
2025-02-25 23:51:38.789835: Pseudo dice [0.778]
2025-02-25 23:51:38.789933: Epoch time: 64.77 s
2025-02-25 23:51:40.114679: 
2025-02-25 23:51:40.114898: Epoch 425
2025-02-25 23:51:40.115021: Current learning rate: 0.00608
2025-02-25 23:52:45.093607: train_loss -0.8537
2025-02-25 23:52:45.093958: val_loss -0.738
2025-02-25 23:52:45.094046: Pseudo dice [0.7876]
2025-02-25 23:52:45.094150: Epoch time: 64.98 s
2025-02-25 23:52:46.467013: 
2025-02-25 23:52:46.467199: Epoch 426
2025-02-25 23:52:46.467329: Current learning rate: 0.00607
2025-02-25 23:53:53.451953: train_loss -0.8528
2025-02-25 23:53:53.452358: val_loss -0.7201
2025-02-25 23:53:53.452446: Pseudo dice [0.7704]
2025-02-25 23:53:53.452543: Epoch time: 66.99 s
2025-02-25 23:53:54.750534: 
2025-02-25 23:53:54.750792: Epoch 427
2025-02-25 23:53:54.750933: Current learning rate: 0.00606
2025-02-25 23:54:58.935794: train_loss -0.8693
2025-02-25 23:54:58.936329: val_loss -0.7504
2025-02-25 23:54:58.936463: Pseudo dice [0.7965]
2025-02-25 23:54:58.936606: Epoch time: 64.19 s
2025-02-25 23:55:00.323239: 
2025-02-25 23:55:00.323449: Epoch 428
2025-02-25 23:55:00.323570: Current learning rate: 0.00605
2025-02-25 23:56:05.094000: train_loss -0.8755
2025-02-25 23:56:05.094439: val_loss -0.7382
2025-02-25 23:56:05.094558: Pseudo dice [0.7876]
2025-02-25 23:56:05.094678: Epoch time: 64.77 s
2025-02-25 23:56:06.815853: 
2025-02-25 23:56:06.816090: Epoch 429
2025-02-25 23:56:06.816208: Current learning rate: 0.00604
2025-02-25 23:57:12.315068: train_loss -0.8779
2025-02-25 23:57:12.315490: val_loss -0.7453
2025-02-25 23:57:12.315574: Pseudo dice [0.7937]
2025-02-25 23:57:12.315674: Epoch time: 65.5 s
2025-02-25 23:57:13.628763: 
2025-02-25 23:57:13.628990: Epoch 430
2025-02-25 23:57:13.629112: Current learning rate: 0.00603
2025-02-25 23:58:18.248928: train_loss -0.8865
2025-02-25 23:58:18.249351: val_loss -0.7563
2025-02-25 23:58:18.249441: Pseudo dice [0.8038]
2025-02-25 23:58:18.249540: Epoch time: 64.62 s
2025-02-25 23:58:19.571062: 
2025-02-25 23:58:19.571282: Epoch 431
2025-02-25 23:58:19.571425: Current learning rate: 0.00602
2025-02-25 23:59:25.211688: train_loss -0.8851
2025-02-25 23:59:25.212089: val_loss -0.7369
2025-02-25 23:59:25.212170: Pseudo dice [0.7872]
2025-02-25 23:59:25.212269: Epoch time: 65.64 s
2025-02-25 23:59:26.579787: 
2025-02-25 23:59:26.580010: Epoch 432
2025-02-25 23:59:26.580133: Current learning rate: 0.00601
2025-02-26 00:00:32.353824: train_loss -0.8727
2025-02-26 00:00:32.354228: val_loss -0.74
2025-02-26 00:00:32.354323: Pseudo dice [0.7931]
2025-02-26 00:00:32.354434: Epoch time: 65.78 s
2025-02-26 00:00:33.675856: 
2025-02-26 00:00:33.676089: Epoch 433
2025-02-26 00:00:33.676211: Current learning rate: 0.006
2025-02-26 00:01:38.741284: train_loss -0.879
2025-02-26 00:01:38.741761: val_loss -0.7452
2025-02-26 00:01:38.741874: Pseudo dice [0.7983]
2025-02-26 00:01:38.741992: Epoch time: 65.07 s
2025-02-26 00:01:40.044227: 
2025-02-26 00:01:40.044493: Epoch 434
2025-02-26 00:01:40.044623: Current learning rate: 0.00599
2025-02-26 00:02:43.823981: train_loss -0.8797
2025-02-26 00:02:43.824432: val_loss -0.7199
2025-02-26 00:02:43.824538: Pseudo dice [0.7699]
2025-02-26 00:02:43.824649: Epoch time: 63.78 s
2025-02-26 00:02:45.148933: 
2025-02-26 00:02:45.149153: Epoch 435
2025-02-26 00:02:45.149276: Current learning rate: 0.00598
2025-02-26 00:03:48.960195: train_loss -0.8828
2025-02-26 00:03:48.960629: val_loss -0.739
2025-02-26 00:03:48.960724: Pseudo dice [0.7975]
2025-02-26 00:03:48.960839: Epoch time: 63.81 s
2025-02-26 00:03:50.359618: 
2025-02-26 00:03:50.359838: Epoch 436
2025-02-26 00:03:50.359964: Current learning rate: 0.00597
2025-02-26 00:04:55.142143: train_loss -0.8845
2025-02-26 00:04:55.142593: val_loss -0.7544
2025-02-26 00:04:55.142677: Pseudo dice [0.8047]
2025-02-26 00:04:55.142774: Epoch time: 64.78 s
2025-02-26 00:04:56.502187: 
2025-02-26 00:04:56.502424: Epoch 437
2025-02-26 00:04:56.502549: Current learning rate: 0.00596
2025-02-26 00:06:00.997314: train_loss -0.8859
2025-02-26 00:06:00.997736: val_loss -0.7391
2025-02-26 00:06:00.997829: Pseudo dice [0.8]
2025-02-26 00:06:00.997946: Epoch time: 64.5 s
2025-02-26 00:06:02.379253: 
2025-02-26 00:06:02.379476: Epoch 438
2025-02-26 00:06:02.379607: Current learning rate: 0.00595
2025-02-26 00:07:07.975560: train_loss -0.8884
2025-02-26 00:07:07.976125: val_loss -0.7612
2025-02-26 00:07:07.976213: Pseudo dice [0.8097]
2025-02-26 00:07:07.976328: Epoch time: 65.6 s
2025-02-26 00:07:09.403525: 
2025-02-26 00:07:09.403745: Epoch 439
2025-02-26 00:07:09.403869: Current learning rate: 0.00594
2025-02-26 00:08:14.040247: train_loss -0.8847
2025-02-26 00:08:14.040731: val_loss -0.7332
2025-02-26 00:08:14.040838: Pseudo dice [0.7898]
2025-02-26 00:08:14.040958: Epoch time: 64.64 s
2025-02-26 00:08:15.373490: 
2025-02-26 00:08:15.373694: Epoch 440
2025-02-26 00:08:15.373815: Current learning rate: 0.00593
2025-02-26 00:09:20.252699: train_loss -0.8811
2025-02-26 00:09:20.253080: val_loss -0.7335
2025-02-26 00:09:20.253173: Pseudo dice [0.7874]
2025-02-26 00:09:20.253281: Epoch time: 64.88 s
2025-02-26 00:09:22.026591: 
2025-02-26 00:09:22.026821: Epoch 441
2025-02-26 00:09:22.026951: Current learning rate: 0.00592
2025-02-26 00:10:27.603594: train_loss -0.8819
2025-02-26 00:10:27.603983: val_loss -0.7567
2025-02-26 00:10:27.604071: Pseudo dice [0.8016]
2025-02-26 00:10:27.604177: Epoch time: 65.58 s
2025-02-26 00:10:28.926563: 
2025-02-26 00:10:28.926812: Epoch 442
2025-02-26 00:10:28.926937: Current learning rate: 0.00592
2025-02-26 00:11:33.961253: train_loss -0.8753
2025-02-26 00:11:33.961778: val_loss -0.7501
2025-02-26 00:11:33.961882: Pseudo dice [0.8013]
2025-02-26 00:11:33.962006: Epoch time: 65.04 s
2025-02-26 00:11:35.302583: 
2025-02-26 00:11:35.302808: Epoch 443
2025-02-26 00:11:35.302935: Current learning rate: 0.00591
2025-02-26 00:12:40.130103: train_loss -0.885
2025-02-26 00:12:40.130513: val_loss -0.74
2025-02-26 00:12:40.130597: Pseudo dice [0.7945]
2025-02-26 00:12:40.130695: Epoch time: 64.83 s
2025-02-26 00:12:41.435547: 
2025-02-26 00:12:41.435769: Epoch 444
2025-02-26 00:12:41.435893: Current learning rate: 0.0059
2025-02-26 00:13:46.991719: train_loss -0.8641
2025-02-26 00:13:46.992100: val_loss -0.7448
2025-02-26 00:13:46.992176: Pseudo dice [0.7919]
2025-02-26 00:13:46.992262: Epoch time: 65.56 s
2025-02-26 00:13:48.298720: 
2025-02-26 00:13:48.298971: Epoch 445
2025-02-26 00:13:48.299100: Current learning rate: 0.00589
2025-02-26 00:14:52.083116: train_loss -0.857
2025-02-26 00:14:52.083788: val_loss -0.7481
2025-02-26 00:14:52.083885: Pseudo dice [0.8007]
2025-02-26 00:14:52.083992: Epoch time: 63.79 s
2025-02-26 00:14:53.445952: 
2025-02-26 00:14:53.446186: Epoch 446
2025-02-26 00:14:53.446318: Current learning rate: 0.00588
2025-02-26 00:15:59.000768: train_loss -0.8737
2025-02-26 00:15:59.001169: val_loss -0.7394
2025-02-26 00:15:59.001711: Pseudo dice [0.7921]
2025-02-26 00:15:59.001831: Epoch time: 65.56 s
2025-02-26 00:16:00.352436: 
2025-02-26 00:16:00.352657: Epoch 447
2025-02-26 00:16:00.352782: Current learning rate: 0.00587
2025-02-26 00:17:05.887487: train_loss -0.872
2025-02-26 00:17:05.888126: val_loss -0.7486
2025-02-26 00:17:05.888253: Pseudo dice [0.8044]
2025-02-26 00:17:05.888383: Epoch time: 65.54 s
2025-02-26 00:17:07.214742: 
2025-02-26 00:17:07.214954: Epoch 448
2025-02-26 00:17:07.215076: Current learning rate: 0.00586
2025-02-26 00:18:13.429694: train_loss -0.8717
2025-02-26 00:18:13.430060: val_loss -0.7365
2025-02-26 00:18:13.430148: Pseudo dice [0.7913]
2025-02-26 00:18:13.430261: Epoch time: 66.22 s
2025-02-26 00:18:14.824502: 
2025-02-26 00:18:14.824733: Epoch 449
2025-02-26 00:18:14.824857: Current learning rate: 0.00585
2025-02-26 00:19:19.691003: train_loss -0.8684
2025-02-26 00:19:19.691417: val_loss -0.7408
2025-02-26 00:19:19.691507: Pseudo dice [0.7982]
2025-02-26 00:19:19.691609: Epoch time: 64.87 s
2025-02-26 00:19:21.628899: 
2025-02-26 00:19:21.629114: Epoch 450
2025-02-26 00:19:21.629240: Current learning rate: 0.00584
2025-02-26 00:20:26.934595: train_loss -0.8755
2025-02-26 00:20:26.935089: val_loss -0.7473
2025-02-26 00:20:26.935198: Pseudo dice [0.8001]
2025-02-26 00:20:26.935310: Epoch time: 65.31 s
2025-02-26 00:20:28.198831: 
2025-02-26 00:20:28.199065: Epoch 451
2025-02-26 00:20:28.199190: Current learning rate: 0.00583
2025-02-26 00:21:33.490448: train_loss -0.8866
2025-02-26 00:21:33.490906: val_loss -0.7339
2025-02-26 00:21:33.490998: Pseudo dice [0.7828]
2025-02-26 00:21:33.491103: Epoch time: 65.29 s
2025-02-26 00:21:34.767778: 
2025-02-26 00:21:34.767988: Epoch 452
2025-02-26 00:21:34.768111: Current learning rate: 0.00582
2025-02-26 00:22:42.986195: train_loss -0.8733
2025-02-26 00:22:42.986665: val_loss -0.7378
2025-02-26 00:22:42.986764: Pseudo dice [0.7909]
2025-02-26 00:22:42.986872: Epoch time: 68.22 s
2025-02-26 00:22:44.693018: 
2025-02-26 00:22:44.693242: Epoch 453
2025-02-26 00:22:44.693384: Current learning rate: 0.00581
2025-02-26 00:23:50.262143: train_loss -0.876
2025-02-26 00:23:50.262591: val_loss -0.7392
2025-02-26 00:23:50.262684: Pseudo dice [0.7923]
2025-02-26 00:23:50.262791: Epoch time: 65.57 s
2025-02-26 00:23:51.650027: 
2025-02-26 00:23:51.650250: Epoch 454
2025-02-26 00:23:51.650388: Current learning rate: 0.0058
2025-02-26 00:24:57.934012: train_loss -0.8835
2025-02-26 00:24:57.934441: val_loss -0.7344
2025-02-26 00:24:57.934527: Pseudo dice [0.7906]
2025-02-26 00:24:57.934623: Epoch time: 66.29 s
2025-02-26 00:24:59.203936: 
2025-02-26 00:24:59.204162: Epoch 455
2025-02-26 00:24:59.204289: Current learning rate: 0.00579
2025-02-26 00:26:04.010714: train_loss -0.8787
2025-02-26 00:26:04.011176: val_loss -0.7454
2025-02-26 00:26:04.013386: Pseudo dice [0.803]
2025-02-26 00:26:04.013571: Epoch time: 64.81 s
2025-02-26 00:26:05.262531: 
2025-02-26 00:26:05.262739: Epoch 456
2025-02-26 00:26:05.262868: Current learning rate: 0.00578
2025-02-26 00:27:11.449013: train_loss -0.8874
2025-02-26 00:27:11.449496: val_loss -0.7504
2025-02-26 00:27:11.449607: Pseudo dice [0.8019]
2025-02-26 00:27:11.449725: Epoch time: 66.19 s
2025-02-26 00:27:12.764768: 
2025-02-26 00:27:12.765111: Epoch 457
2025-02-26 00:27:12.765241: Current learning rate: 0.00577
2025-02-26 00:28:19.398925: train_loss -0.8824
2025-02-26 00:28:19.399343: val_loss -0.7512
2025-02-26 00:28:19.399445: Pseudo dice [0.8042]
2025-02-26 00:28:19.399556: Epoch time: 66.64 s
2025-02-26 00:28:20.716563: 
2025-02-26 00:28:20.716776: Epoch 458
2025-02-26 00:28:20.716895: Current learning rate: 0.00576
2025-02-26 00:29:27.040575: train_loss -0.8747
2025-02-26 00:29:27.040976: val_loss -0.7349
2025-02-26 00:29:27.041066: Pseudo dice [0.7875]
2025-02-26 00:29:27.041172: Epoch time: 66.33 s
2025-02-26 00:29:28.337078: 
2025-02-26 00:29:28.337294: Epoch 459
2025-02-26 00:29:28.337440: Current learning rate: 0.00575
2025-02-26 00:30:33.913176: train_loss -0.8721
2025-02-26 00:30:33.913616: val_loss -0.725
2025-02-26 00:30:33.913702: Pseudo dice [0.7827]
2025-02-26 00:30:33.913801: Epoch time: 65.58 s
2025-02-26 00:30:35.295279: 
2025-02-26 00:30:35.295537: Epoch 460
2025-02-26 00:30:35.295660: Current learning rate: 0.00574
2025-02-26 00:31:40.667120: train_loss -0.8869
2025-02-26 00:31:40.667638: val_loss -0.7365
2025-02-26 00:31:40.667737: Pseudo dice [0.7875]
2025-02-26 00:31:40.667862: Epoch time: 65.37 s
2025-02-26 00:31:41.993461: 
2025-02-26 00:31:41.993676: Epoch 461
2025-02-26 00:31:41.993804: Current learning rate: 0.00573
2025-02-26 00:32:47.999288: train_loss -0.891
2025-02-26 00:32:47.999714: val_loss -0.7386
2025-02-26 00:32:47.999803: Pseudo dice [0.7929]
2025-02-26 00:32:47.999905: Epoch time: 66.01 s
2025-02-26 00:32:49.297385: 
2025-02-26 00:32:49.297619: Epoch 462
2025-02-26 00:32:49.297745: Current learning rate: 0.00572
2025-02-26 00:33:53.901092: train_loss -0.8933
2025-02-26 00:33:53.901558: val_loss -0.7387
2025-02-26 00:33:53.901657: Pseudo dice [0.7937]
2025-02-26 00:33:53.901767: Epoch time: 64.61 s
2025-02-26 00:33:55.233482: 
2025-02-26 00:33:55.233740: Epoch 463
2025-02-26 00:33:55.233929: Current learning rate: 0.00571
2025-02-26 00:35:01.354366: train_loss -0.8985
2025-02-26 00:35:01.354673: val_loss -0.7515
2025-02-26 00:35:01.354768: Pseudo dice [0.8015]
2025-02-26 00:35:01.354875: Epoch time: 66.12 s
2025-02-26 00:35:02.663064: 
2025-02-26 00:35:02.663399: Epoch 464
2025-02-26 00:35:02.663532: Current learning rate: 0.0057
2025-02-26 00:36:07.207620: train_loss -0.8934
2025-02-26 00:36:07.207971: val_loss -0.7459
2025-02-26 00:36:07.208045: Pseudo dice [0.7976]
2025-02-26 00:36:07.208129: Epoch time: 64.55 s
2025-02-26 00:36:08.996135: 
2025-02-26 00:36:08.996375: Epoch 465
2025-02-26 00:36:08.996500: Current learning rate: 0.0057
2025-02-26 00:37:13.923902: train_loss -0.8974
2025-02-26 00:37:13.924347: val_loss -0.7479
2025-02-26 00:37:13.924447: Pseudo dice [0.7985]
2025-02-26 00:37:13.924549: Epoch time: 64.93 s
2025-02-26 00:37:15.320060: 
2025-02-26 00:37:15.320287: Epoch 466
2025-02-26 00:37:15.320426: Current learning rate: 0.00569
2025-02-26 00:38:20.588074: train_loss -0.8928
2025-02-26 00:38:20.588522: val_loss -0.7573
2025-02-26 00:38:20.588612: Pseudo dice [0.8049]
2025-02-26 00:38:20.588712: Epoch time: 65.27 s
2025-02-26 00:38:21.883038: 
2025-02-26 00:38:21.883251: Epoch 467
2025-02-26 00:38:21.883389: Current learning rate: 0.00568
2025-02-26 00:39:26.650553: train_loss -0.9021
2025-02-26 00:39:26.650975: val_loss -0.7384
2025-02-26 00:39:26.651152: Pseudo dice [0.7911]
2025-02-26 00:39:26.651269: Epoch time: 64.77 s
2025-02-26 00:39:27.953841: 
2025-02-26 00:39:27.954064: Epoch 468
2025-02-26 00:39:27.954188: Current learning rate: 0.00567
2025-02-26 00:40:35.266533: train_loss -0.8887
2025-02-26 00:40:35.266958: val_loss -0.7498
2025-02-26 00:40:35.267050: Pseudo dice [0.8004]
2025-02-26 00:40:35.267156: Epoch time: 67.31 s
2025-02-26 00:40:36.624060: 
2025-02-26 00:40:36.624285: Epoch 469
2025-02-26 00:40:36.624423: Current learning rate: 0.00566
2025-02-26 00:41:40.433053: train_loss -0.8993
2025-02-26 00:41:40.456273: val_loss -0.7345
2025-02-26 00:41:40.456500: Pseudo dice [0.788]
2025-02-26 00:41:40.456635: Epoch time: 63.81 s
2025-02-26 00:41:41.845518: 
2025-02-26 00:41:41.845844: Epoch 470
2025-02-26 00:41:41.845976: Current learning rate: 0.00565
2025-02-26 00:42:46.564618: train_loss -0.8966
2025-02-26 00:42:46.565037: val_loss -0.732
2025-02-26 00:42:46.565126: Pseudo dice [0.7903]
2025-02-26 00:42:46.565234: Epoch time: 64.72 s
2025-02-26 00:42:47.899780: 
2025-02-26 00:42:47.900006: Epoch 471
2025-02-26 00:42:47.900131: Current learning rate: 0.00564
2025-02-26 00:43:53.868827: train_loss -0.9017
2025-02-26 00:43:53.869100: val_loss -0.7353
2025-02-26 00:43:53.869174: Pseudo dice [0.7895]
2025-02-26 00:43:53.869255: Epoch time: 65.97 s
2025-02-26 00:43:55.168698: 
2025-02-26 00:43:55.168916: Epoch 472
2025-02-26 00:43:55.169040: Current learning rate: 0.00563
2025-02-26 00:44:59.818088: train_loss -0.8758
2025-02-26 00:44:59.818476: val_loss -0.7524
2025-02-26 00:44:59.818939: Pseudo dice [0.801]
2025-02-26 00:44:59.819046: Epoch time: 64.65 s
2025-02-26 00:45:01.123501: 
2025-02-26 00:45:01.123723: Epoch 473
2025-02-26 00:45:01.123848: Current learning rate: 0.00562
2025-02-26 00:46:06.293827: train_loss -0.8641
2025-02-26 00:46:06.294231: val_loss -0.7025
2025-02-26 00:46:06.294364: Pseudo dice [0.7604]
2025-02-26 00:46:06.294471: Epoch time: 65.17 s
2025-02-26 00:46:07.594542: 
2025-02-26 00:46:07.594768: Epoch 474
2025-02-26 00:46:07.594899: Current learning rate: 0.00561
2025-02-26 00:47:10.446534: train_loss -0.8547
2025-02-26 00:47:10.446861: val_loss -0.7341
2025-02-26 00:47:10.446952: Pseudo dice [0.7816]
2025-02-26 00:47:10.447094: Epoch time: 62.85 s
2025-02-26 00:47:11.761398: 
2025-02-26 00:47:11.761618: Epoch 475
2025-02-26 00:47:11.761745: Current learning rate: 0.0056
2025-02-26 00:48:16.400562: train_loss -0.8647
2025-02-26 00:48:16.400902: val_loss -0.7449
2025-02-26 00:48:16.400985: Pseudo dice [0.7918]
2025-02-26 00:48:16.401087: Epoch time: 64.64 s
2025-02-26 00:48:17.683736: 
2025-02-26 00:48:17.683963: Epoch 476
2025-02-26 00:48:17.684086: Current learning rate: 0.00559
2025-02-26 00:49:22.350638: train_loss -0.8624
2025-02-26 00:49:22.351054: val_loss -0.72
2025-02-26 00:49:22.351146: Pseudo dice [0.7745]
2025-02-26 00:49:22.351255: Epoch time: 64.67 s
2025-02-26 00:49:23.777020: 
2025-02-26 00:49:23.777235: Epoch 477
2025-02-26 00:49:23.777375: Current learning rate: 0.00558
2025-02-26 00:50:29.930417: train_loss -0.863
2025-02-26 00:50:29.930794: val_loss -0.7454
2025-02-26 00:50:29.930894: Pseudo dice [0.8043]
2025-02-26 00:50:29.931004: Epoch time: 66.15 s
2025-02-26 00:50:31.733122: 
2025-02-26 00:50:31.733387: Epoch 478
2025-02-26 00:50:31.733533: Current learning rate: 0.00557
2025-02-26 00:51:37.750117: train_loss -0.8632
2025-02-26 00:51:37.750527: val_loss -0.7332
2025-02-26 00:51:37.750610: Pseudo dice [0.7881]
2025-02-26 00:51:37.750705: Epoch time: 66.02 s
2025-02-26 00:51:39.108583: 
2025-02-26 00:51:39.108803: Epoch 479
2025-02-26 00:51:39.108924: Current learning rate: 0.00556
2025-02-26 00:52:42.824874: train_loss -0.8801
2025-02-26 00:52:42.825348: val_loss -0.752
2025-02-26 00:52:42.825451: Pseudo dice [0.8002]
2025-02-26 00:52:42.825559: Epoch time: 63.72 s
2025-02-26 00:52:44.100454: 
2025-02-26 00:52:44.100687: Epoch 480
2025-02-26 00:52:44.100815: Current learning rate: 0.00555
2025-02-26 00:53:49.661751: train_loss -0.8698
2025-02-26 00:53:49.662157: val_loss -0.7249
2025-02-26 00:53:49.662247: Pseudo dice [0.7883]
2025-02-26 00:53:49.662372: Epoch time: 65.56 s
2025-02-26 00:53:50.991282: 
2025-02-26 00:53:50.991539: Epoch 481
2025-02-26 00:53:50.991665: Current learning rate: 0.00554
2025-02-26 00:54:57.507140: train_loss -0.8774
2025-02-26 00:54:57.507561: val_loss -0.7399
2025-02-26 00:54:57.507657: Pseudo dice [0.7951]
2025-02-26 00:54:57.507763: Epoch time: 66.52 s
2025-02-26 00:54:58.865941: 
2025-02-26 00:54:58.866196: Epoch 482
2025-02-26 00:54:58.866334: Current learning rate: 0.00553
2025-02-26 00:56:04.360978: train_loss -0.8788
2025-02-26 00:56:04.361526: val_loss -0.7305
2025-02-26 00:56:04.361798: Pseudo dice [0.7854]
2025-02-26 00:56:04.361937: Epoch time: 65.5 s
2025-02-26 00:56:05.700669: 
2025-02-26 00:56:05.700914: Epoch 483
2025-02-26 00:56:05.701039: Current learning rate: 0.00552
2025-02-26 00:57:10.879090: train_loss -0.8819
2025-02-26 00:57:10.879455: val_loss -0.7448
2025-02-26 00:57:10.879547: Pseudo dice [0.8014]
2025-02-26 00:57:10.879650: Epoch time: 65.18 s
2025-02-26 00:57:12.249708: 
2025-02-26 00:57:12.249945: Epoch 484
2025-02-26 00:57:12.250074: Current learning rate: 0.00551
2025-02-26 00:58:15.094474: train_loss -0.8941
2025-02-26 00:58:15.094881: val_loss -0.7352
2025-02-26 00:58:15.094979: Pseudo dice [0.7891]
2025-02-26 00:58:15.095084: Epoch time: 62.85 s
2025-02-26 00:58:16.427816: 
2025-02-26 00:58:16.428060: Epoch 485
2025-02-26 00:58:16.428189: Current learning rate: 0.0055
2025-02-26 00:59:22.745703: train_loss -0.8862
2025-02-26 00:59:22.746124: val_loss -0.7291
2025-02-26 00:59:22.746235: Pseudo dice [0.7889]
2025-02-26 00:59:22.746356: Epoch time: 66.32 s
2025-02-26 00:59:24.118947: 
2025-02-26 00:59:24.119166: Epoch 486
2025-02-26 00:59:24.119287: Current learning rate: 0.00549
2025-02-26 01:00:30.176703: train_loss -0.856
2025-02-26 01:00:30.177111: val_loss -0.7329
2025-02-26 01:00:30.177203: Pseudo dice [0.7918]
2025-02-26 01:00:30.177342: Epoch time: 66.06 s
2025-02-26 01:00:31.478483: 
2025-02-26 01:00:31.478730: Epoch 487
2025-02-26 01:00:31.478868: Current learning rate: 0.00548
2025-02-26 01:01:36.969063: train_loss -0.8262
2025-02-26 01:01:36.969488: val_loss -0.6898
2025-02-26 01:01:36.969586: Pseudo dice [0.7435]
2025-02-26 01:01:36.969687: Epoch time: 65.49 s
2025-02-26 01:01:38.326074: 
2025-02-26 01:01:38.326316: Epoch 488
2025-02-26 01:01:38.326447: Current learning rate: 0.00547
2025-02-26 01:02:44.332599: train_loss -0.7703
2025-02-26 01:02:44.332999: val_loss -0.715
2025-02-26 01:02:44.333088: Pseudo dice [0.7626]
2025-02-26 01:02:44.333192: Epoch time: 66.01 s
2025-02-26 01:02:45.652889: 
2025-02-26 01:02:45.653100: Epoch 489
2025-02-26 01:02:45.653225: Current learning rate: 0.00546
2025-02-26 01:03:51.169458: train_loss -0.7692
2025-02-26 01:03:51.169756: val_loss -0.7311
2025-02-26 01:03:51.169859: Pseudo dice [0.7923]
2025-02-26 01:03:51.170056: Epoch time: 65.52 s
2025-02-26 01:03:52.477857: 
2025-02-26 01:03:52.478070: Epoch 490
2025-02-26 01:03:52.478193: Current learning rate: 0.00546
2025-02-26 01:04:59.990675: train_loss -0.8014
2025-02-26 01:04:59.990992: val_loss -0.7212
2025-02-26 01:04:59.991089: Pseudo dice [0.7804]
2025-02-26 01:04:59.991208: Epoch time: 67.51 s
2025-02-26 01:05:01.716912: 
2025-02-26 01:05:01.717148: Epoch 491
2025-02-26 01:05:01.717278: Current learning rate: 0.00545
2025-02-26 01:06:05.996342: train_loss -0.8134
2025-02-26 01:06:05.996751: val_loss -0.7149
2025-02-26 01:06:05.996840: Pseudo dice [0.7738]
2025-02-26 01:06:05.996944: Epoch time: 64.28 s
2025-02-26 01:06:07.361178: 
2025-02-26 01:06:07.361426: Epoch 492
2025-02-26 01:06:07.361554: Current learning rate: 0.00544
2025-02-26 01:07:12.955259: train_loss -0.833
2025-02-26 01:07:12.955712: val_loss -0.7217
2025-02-26 01:07:12.955810: Pseudo dice [0.7691]
2025-02-26 01:07:12.955932: Epoch time: 65.6 s
2025-02-26 01:07:14.288348: 
2025-02-26 01:07:14.288596: Epoch 493
2025-02-26 01:07:14.288725: Current learning rate: 0.00543
2025-02-26 01:08:19.649258: train_loss -0.8529
2025-02-26 01:08:19.649651: val_loss -0.7464
2025-02-26 01:08:19.649735: Pseudo dice [0.8017]
2025-02-26 01:08:19.649903: Epoch time: 65.36 s
2025-02-26 01:08:20.973799: 
2025-02-26 01:08:20.974047: Epoch 494
2025-02-26 01:08:20.974172: Current learning rate: 0.00542
2025-02-26 01:09:27.188128: train_loss -0.8731
2025-02-26 01:09:27.188546: val_loss -0.7215
2025-02-26 01:09:27.188631: Pseudo dice [0.7752]
2025-02-26 01:09:27.188729: Epoch time: 66.22 s
2025-02-26 01:09:28.535674: 
2025-02-26 01:09:28.535898: Epoch 495
2025-02-26 01:09:28.536017: Current learning rate: 0.00541
2025-02-26 01:10:33.851567: train_loss -0.8462
2025-02-26 01:10:33.852117: val_loss -0.727
2025-02-26 01:10:33.852214: Pseudo dice [0.7807]
2025-02-26 01:10:33.852346: Epoch time: 65.32 s
2025-02-26 01:10:35.191714: 
2025-02-26 01:10:35.191934: Epoch 496
2025-02-26 01:10:35.192066: Current learning rate: 0.0054
2025-02-26 01:11:39.503751: train_loss -0.8416
2025-02-26 01:11:39.504258: val_loss -0.7395
2025-02-26 01:11:39.504398: Pseudo dice [0.793]
2025-02-26 01:11:39.504522: Epoch time: 64.31 s
2025-02-26 01:11:40.853428: 
2025-02-26 01:11:40.853652: Epoch 497
2025-02-26 01:11:40.853779: Current learning rate: 0.00539
2025-02-26 01:12:45.341995: train_loss -0.854
2025-02-26 01:12:45.342446: val_loss -0.7379
2025-02-26 01:12:45.342576: Pseudo dice [0.7866]
2025-02-26 01:12:45.342848: Epoch time: 64.49 s
2025-02-26 01:12:46.693716: 
2025-02-26 01:12:46.693943: Epoch 498
2025-02-26 01:12:46.694070: Current learning rate: 0.00538
2025-02-26 01:13:52.494544: train_loss -0.841
2025-02-26 01:13:52.494953: val_loss -0.7329
2025-02-26 01:13:52.495515: Pseudo dice [0.7887]
2025-02-26 01:13:52.495637: Epoch time: 65.8 s
2025-02-26 01:13:53.851916: 
2025-02-26 01:13:53.852153: Epoch 499
2025-02-26 01:13:53.852280: Current learning rate: 0.00537
2025-02-26 01:15:01.627898: train_loss -0.8618
2025-02-26 01:15:01.628292: val_loss -0.7365
2025-02-26 01:15:01.628405: Pseudo dice [0.7935]
2025-02-26 01:15:01.628513: Epoch time: 67.78 s
2025-02-26 01:15:03.510798: 
2025-02-26 01:15:03.511027: Epoch 500
2025-02-26 01:15:03.511161: Current learning rate: 0.00536
2025-02-26 01:16:08.553782: train_loss -0.8683
2025-02-26 01:16:08.554223: val_loss -0.703
2025-02-26 01:16:08.554326: Pseudo dice [0.7605]
2025-02-26 01:16:08.554440: Epoch time: 65.04 s
2025-02-26 01:16:09.875200: 
2025-02-26 01:16:09.875421: Epoch 501
2025-02-26 01:16:09.875545: Current learning rate: 0.00535
2025-02-26 01:17:15.386714: train_loss -0.8551
2025-02-26 01:17:15.387232: val_loss -0.7419
2025-02-26 01:17:15.387361: Pseudo dice [0.798]
2025-02-26 01:17:15.387489: Epoch time: 65.51 s
2025-02-26 01:17:17.162726: 
2025-02-26 01:17:17.162968: Epoch 502
2025-02-26 01:17:17.163094: Current learning rate: 0.00534
2025-02-26 01:18:23.164264: train_loss -0.8468
2025-02-26 01:18:23.164645: val_loss -0.6791
2025-02-26 01:18:23.164798: Pseudo dice [0.7697]
2025-02-26 01:18:23.164895: Epoch time: 66.0 s
2025-02-26 01:18:24.504360: 
2025-02-26 01:18:24.504593: Epoch 503
2025-02-26 01:18:24.504718: Current learning rate: 0.00533
2025-02-26 01:19:30.849083: train_loss -0.8165
2025-02-26 01:19:30.849533: val_loss -0.7196
2025-02-26 01:19:30.849637: Pseudo dice [0.7862]
2025-02-26 01:19:30.849747: Epoch time: 66.35 s
2025-02-26 01:19:32.180875: 
2025-02-26 01:19:32.181116: Epoch 504
2025-02-26 01:19:32.181246: Current learning rate: 0.00532
2025-02-26 01:20:38.083983: train_loss -0.8228
2025-02-26 01:20:38.084385: val_loss -0.7341
2025-02-26 01:20:38.084482: Pseudo dice [0.7831]
2025-02-26 01:20:38.084587: Epoch time: 65.9 s
2025-02-26 01:20:39.402255: 
2025-02-26 01:20:39.402525: Epoch 505
2025-02-26 01:20:39.402652: Current learning rate: 0.00531
2025-02-26 01:21:44.071788: train_loss -0.8372
2025-02-26 01:21:44.072232: val_loss -0.7329
2025-02-26 01:21:44.072340: Pseudo dice [0.7913]
2025-02-26 01:21:44.072460: Epoch time: 64.67 s
2025-02-26 01:21:45.385696: 
2025-02-26 01:21:45.385942: Epoch 506
2025-02-26 01:21:45.386063: Current learning rate: 0.0053
2025-02-26 01:22:52.196520: train_loss -0.8708
2025-02-26 01:22:52.197152: val_loss -0.7358
2025-02-26 01:22:52.197285: Pseudo dice [0.7939]
2025-02-26 01:22:52.197424: Epoch time: 66.81 s
2025-02-26 01:22:53.481139: 
2025-02-26 01:22:53.481390: Epoch 507
2025-02-26 01:22:53.481514: Current learning rate: 0.00529
2025-02-26 01:23:58.476437: train_loss -0.8686
2025-02-26 01:23:58.476800: val_loss -0.7258
2025-02-26 01:23:58.476891: Pseudo dice [0.7816]
2025-02-26 01:23:58.476991: Epoch time: 65.0 s
2025-02-26 01:23:59.850471: 
2025-02-26 01:23:59.850742: Epoch 508
2025-02-26 01:23:59.850867: Current learning rate: 0.00528
2025-02-26 01:25:04.047598: train_loss -0.8682
2025-02-26 01:25:04.048034: val_loss -0.7322
2025-02-26 01:25:04.048129: Pseudo dice [0.785]
2025-02-26 01:25:04.048239: Epoch time: 64.2 s
2025-02-26 01:25:05.372512: 
2025-02-26 01:25:05.372809: Epoch 509
2025-02-26 01:25:05.372935: Current learning rate: 0.00527
2025-02-26 01:26:12.167067: train_loss -0.8674
2025-02-26 01:26:12.167550: val_loss -0.7279
2025-02-26 01:26:12.167657: Pseudo dice [0.79]
2025-02-26 01:26:12.167784: Epoch time: 66.8 s
2025-02-26 01:26:13.498667: 
2025-02-26 01:26:13.498885: Epoch 510
2025-02-26 01:26:13.499007: Current learning rate: 0.00526
2025-02-26 01:27:18.523701: train_loss -0.8847
2025-02-26 01:27:18.524123: val_loss -0.7339
2025-02-26 01:27:18.524208: Pseudo dice [0.7925]
2025-02-26 01:27:18.524324: Epoch time: 65.03 s
2025-02-26 01:27:19.875020: 
2025-02-26 01:27:19.875229: Epoch 511
2025-02-26 01:27:19.875359: Current learning rate: 0.00525
2025-02-26 01:28:25.513777: train_loss -0.8883
2025-02-26 01:28:25.514161: val_loss -0.7383
2025-02-26 01:28:25.514243: Pseudo dice [0.7969]
2025-02-26 01:28:25.514349: Epoch time: 65.64 s
2025-02-26 01:28:26.835237: 
2025-02-26 01:28:26.835464: Epoch 512
2025-02-26 01:28:26.835587: Current learning rate: 0.00524
2025-02-26 01:29:34.212750: train_loss -0.89
2025-02-26 01:29:34.213158: val_loss -0.7483
2025-02-26 01:29:34.213240: Pseudo dice [0.7959]
2025-02-26 01:29:34.213355: Epoch time: 67.38 s
2025-02-26 01:29:35.534813: 
2025-02-26 01:29:35.535015: Epoch 513
2025-02-26 01:29:35.535136: Current learning rate: 0.00523
2025-02-26 01:30:40.138809: train_loss -0.8954
2025-02-26 01:30:40.139258: val_loss -0.7354
2025-02-26 01:30:40.139373: Pseudo dice [0.7874]
2025-02-26 01:30:40.139492: Epoch time: 64.61 s
2025-02-26 01:30:41.461689: 
2025-02-26 01:30:41.461905: Epoch 514
2025-02-26 01:30:41.462034: Current learning rate: 0.00522
2025-02-26 01:31:48.743576: train_loss -0.8922
2025-02-26 01:31:48.743976: val_loss -0.732
2025-02-26 01:31:48.744059: Pseudo dice [0.7862]
2025-02-26 01:31:48.744159: Epoch time: 67.28 s
2025-02-26 01:31:50.547825: 
2025-02-26 01:31:50.548092: Epoch 515
2025-02-26 01:31:50.548213: Current learning rate: 0.00521
2025-02-26 01:32:56.981204: train_loss -0.8966
2025-02-26 01:32:56.981632: val_loss -0.7423
2025-02-26 01:32:56.981718: Pseudo dice [0.7917]
2025-02-26 01:32:56.981822: Epoch time: 66.43 s
2025-02-26 01:32:58.317914: 
2025-02-26 01:32:58.318145: Epoch 516
2025-02-26 01:32:58.318274: Current learning rate: 0.0052
2025-02-26 01:34:06.082260: train_loss -0.8948
2025-02-26 01:34:06.082675: val_loss -0.7356
2025-02-26 01:34:06.082761: Pseudo dice [0.7936]
2025-02-26 01:34:06.082859: Epoch time: 67.77 s
2025-02-26 01:34:07.397150: 
2025-02-26 01:34:07.397415: Epoch 517
2025-02-26 01:34:07.397542: Current learning rate: 0.00519
2025-02-26 01:35:12.006988: train_loss -0.868
2025-02-26 01:35:12.007395: val_loss -0.7102
2025-02-26 01:35:12.007500: Pseudo dice [0.78]
2025-02-26 01:35:12.007612: Epoch time: 64.61 s
2025-02-26 01:35:13.306568: 
2025-02-26 01:35:13.306862: Epoch 518
2025-02-26 01:35:13.306989: Current learning rate: 0.00518
2025-02-26 01:36:20.409631: train_loss -0.8665
2025-02-26 01:36:20.410149: val_loss -0.7402
2025-02-26 01:36:20.410253: Pseudo dice [0.7932]
2025-02-26 01:36:20.410384: Epoch time: 67.1 s
2025-02-26 01:36:21.809257: 
2025-02-26 01:36:21.809498: Epoch 519
2025-02-26 01:36:21.809623: Current learning rate: 0.00518
2025-02-26 01:37:28.496940: train_loss -0.881
2025-02-26 01:37:28.497654: val_loss -0.7407
2025-02-26 01:37:28.497774: Pseudo dice [0.7992]
2025-02-26 01:37:28.497892: Epoch time: 66.69 s
2025-02-26 01:37:29.821826: 
2025-02-26 01:37:29.822066: Epoch 520
2025-02-26 01:37:29.822188: Current learning rate: 0.00517
2025-02-26 01:38:36.934889: train_loss -0.8905
2025-02-26 01:38:36.935276: val_loss -0.7411
2025-02-26 01:38:36.935388: Pseudo dice [0.7889]
2025-02-26 01:38:36.935493: Epoch time: 67.11 s
2025-02-26 01:38:38.276198: 
2025-02-26 01:38:38.276429: Epoch 521
2025-02-26 01:38:38.276552: Current learning rate: 0.00516
2025-02-26 01:39:45.393791: train_loss -0.8705
2025-02-26 01:39:45.394197: val_loss -0.7208
2025-02-26 01:39:45.394281: Pseudo dice [0.7738]
2025-02-26 01:39:45.394409: Epoch time: 67.12 s
2025-02-26 01:39:46.746090: 
2025-02-26 01:39:46.746323: Epoch 522
2025-02-26 01:39:46.746456: Current learning rate: 0.00515
2025-02-26 01:40:54.699764: train_loss -0.8638
2025-02-26 01:40:54.700149: val_loss -0.7317
2025-02-26 01:40:54.700222: Pseudo dice [0.7792]
2025-02-26 01:40:54.700351: Epoch time: 67.96 s
2025-02-26 01:40:56.033376: 
2025-02-26 01:40:56.033619: Epoch 523
2025-02-26 01:40:56.033743: Current learning rate: 0.00514
2025-02-26 01:42:03.869838: train_loss -0.8853
2025-02-26 01:42:03.870267: val_loss -0.7528
2025-02-26 01:42:03.870378: Pseudo dice [0.8008]
2025-02-26 01:42:03.870493: Epoch time: 67.84 s
2025-02-26 01:42:05.232900: 
2025-02-26 01:42:05.233268: Epoch 524
2025-02-26 01:42:05.233405: Current learning rate: 0.00513
2025-02-26 01:43:11.582479: train_loss -0.8832
2025-02-26 01:43:11.582956: val_loss -0.7324
2025-02-26 01:43:11.583619: Pseudo dice [0.7918]
2025-02-26 01:43:11.583764: Epoch time: 66.35 s
2025-02-26 01:43:12.937454: 
2025-02-26 01:43:12.937659: Epoch 525
2025-02-26 01:43:12.937779: Current learning rate: 0.00512
2025-02-26 01:44:17.992678: train_loss -0.8853
2025-02-26 01:44:17.993071: val_loss -0.7379
2025-02-26 01:44:17.993162: Pseudo dice [0.7908]
2025-02-26 01:44:17.993342: Epoch time: 65.06 s
2025-02-26 01:44:19.361648: 
2025-02-26 01:44:19.361866: Epoch 526
2025-02-26 01:44:19.361992: Current learning rate: 0.00511
2025-02-26 01:45:26.472471: train_loss -0.8833
2025-02-26 01:45:26.472923: val_loss -0.7376
2025-02-26 01:45:26.473015: Pseudo dice [0.7942]
2025-02-26 01:45:26.473126: Epoch time: 67.11 s
2025-02-26 01:45:28.268660: 
2025-02-26 01:45:28.269005: Epoch 527
2025-02-26 01:45:28.269135: Current learning rate: 0.0051
2025-02-26 01:46:34.129996: train_loss -0.8454
2025-02-26 01:46:34.130404: val_loss -0.7101
2025-02-26 01:46:34.130494: Pseudo dice [0.7745]
2025-02-26 01:46:34.130599: Epoch time: 65.86 s
2025-02-26 01:46:35.573350: 
2025-02-26 01:46:35.573579: Epoch 528
2025-02-26 01:46:35.573713: Current learning rate: 0.00509
2025-02-26 01:47:41.593831: train_loss -0.8576
2025-02-26 01:47:41.594283: val_loss -0.7501
2025-02-26 01:47:41.594396: Pseudo dice [0.7974]
2025-02-26 01:47:41.594508: Epoch time: 66.02 s
2025-02-26 01:47:43.019309: 
2025-02-26 01:47:43.019537: Epoch 529
2025-02-26 01:47:43.019658: Current learning rate: 0.00508
2025-02-26 01:48:50.227740: train_loss -0.8585
2025-02-26 01:48:50.228221: val_loss -0.7153
2025-02-26 01:48:50.228337: Pseudo dice [0.7608]
2025-02-26 01:48:50.228464: Epoch time: 67.21 s
2025-02-26 01:48:51.624986: 
2025-02-26 01:48:51.625212: Epoch 530
2025-02-26 01:48:51.625345: Current learning rate: 0.00507
2025-02-26 01:49:57.327037: train_loss -0.873
2025-02-26 01:49:57.327437: val_loss -0.7424
2025-02-26 01:49:57.327533: Pseudo dice [0.7992]
2025-02-26 01:49:57.327640: Epoch time: 65.7 s
2025-02-26 01:49:58.652688: 
2025-02-26 01:49:58.652942: Epoch 531
2025-02-26 01:49:58.653070: Current learning rate: 0.00506
2025-02-26 01:51:04.252723: train_loss -0.8903
2025-02-26 01:51:04.253019: val_loss -0.7466
2025-02-26 01:51:04.253103: Pseudo dice [0.7968]
2025-02-26 01:51:04.253200: Epoch time: 65.6 s
2025-02-26 01:51:05.641739: 
2025-02-26 01:51:05.641954: Epoch 532
2025-02-26 01:51:05.642076: Current learning rate: 0.00505
2025-02-26 01:52:13.155381: train_loss -0.8912
2025-02-26 01:52:13.155864: val_loss -0.7528
2025-02-26 01:52:13.155966: Pseudo dice [0.8078]
2025-02-26 01:52:13.156086: Epoch time: 67.52 s
2025-02-26 01:52:14.499978: 
2025-02-26 01:52:14.500226: Epoch 533
2025-02-26 01:52:14.500371: Current learning rate: 0.00504
2025-02-26 01:53:20.608531: train_loss -0.8854
2025-02-26 01:53:20.608901: val_loss -0.7261
2025-02-26 01:53:20.608975: Pseudo dice [0.7909]
2025-02-26 01:53:20.609059: Epoch time: 66.11 s
2025-02-26 01:53:21.907604: 
2025-02-26 01:53:21.907830: Epoch 534
2025-02-26 01:53:21.907952: Current learning rate: 0.00503
2025-02-26 01:54:28.665318: train_loss -0.8937
2025-02-26 01:54:28.665710: val_loss -0.7421
2025-02-26 01:54:28.665793: Pseudo dice [0.7916]
2025-02-26 01:54:28.665893: Epoch time: 66.76 s
2025-02-26 01:54:30.003912: 
2025-02-26 01:54:30.004124: Epoch 535
2025-02-26 01:54:30.004251: Current learning rate: 0.00502
2025-02-26 01:55:35.984483: train_loss -0.895
2025-02-26 01:55:35.984890: val_loss -0.7296
2025-02-26 01:55:35.984979: Pseudo dice [0.7871]
2025-02-26 01:55:35.985094: Epoch time: 65.98 s
2025-02-26 01:55:37.336481: 
2025-02-26 01:55:37.336689: Epoch 536
2025-02-26 01:55:37.336811: Current learning rate: 0.00501
2025-02-26 01:56:40.842459: train_loss -0.8842
2025-02-26 01:56:40.842934: val_loss -0.7301
2025-02-26 01:56:40.843022: Pseudo dice [0.7855]
2025-02-26 01:56:40.843128: Epoch time: 63.51 s
2025-02-26 01:56:42.177228: 
2025-02-26 01:56:42.177441: Epoch 537
2025-02-26 01:56:42.177567: Current learning rate: 0.005
2025-02-26 01:57:47.727432: train_loss -0.8809
2025-02-26 01:57:47.727828: val_loss -0.7383
2025-02-26 01:57:47.727911: Pseudo dice [0.7931]
2025-02-26 01:57:47.728014: Epoch time: 65.55 s
2025-02-26 01:57:49.081074: 
2025-02-26 01:57:49.081328: Epoch 538
2025-02-26 01:57:49.081508: Current learning rate: 0.00499
2025-02-26 01:58:55.708554: train_loss -0.8902
2025-02-26 01:58:55.708965: val_loss -0.7286
2025-02-26 01:58:55.709054: Pseudo dice [0.7884]
2025-02-26 01:58:55.709161: Epoch time: 66.63 s
2025-02-26 01:58:57.520933: 
2025-02-26 01:58:57.521171: Epoch 539
2025-02-26 01:58:57.521305: Current learning rate: 0.00498
2025-02-26 02:00:05.703311: train_loss -0.8968
2025-02-26 02:00:05.703803: val_loss -0.7348
2025-02-26 02:00:05.703897: Pseudo dice [0.788]
2025-02-26 02:00:05.704012: Epoch time: 68.18 s
2025-02-26 02:00:07.039858: 
2025-02-26 02:00:07.040090: Epoch 540
2025-02-26 02:00:07.040215: Current learning rate: 0.00497
2025-02-26 02:01:13.814220: train_loss -0.8999
2025-02-26 02:01:13.814672: val_loss -0.7402
2025-02-26 02:01:13.814764: Pseudo dice [0.7936]
2025-02-26 02:01:13.814876: Epoch time: 66.78 s
2025-02-26 02:01:15.146614: 
2025-02-26 02:01:15.146868: Epoch 541
2025-02-26 02:01:15.146998: Current learning rate: 0.00496
2025-02-26 02:02:20.843401: train_loss -0.8999
2025-02-26 02:02:20.843825: val_loss -0.7279
2025-02-26 02:02:20.843915: Pseudo dice [0.7823]
2025-02-26 02:02:20.844014: Epoch time: 65.7 s
2025-02-26 02:02:22.181761: 
2025-02-26 02:02:22.181973: Epoch 542
2025-02-26 02:02:22.182096: Current learning rate: 0.00495
2025-02-26 02:03:28.029259: train_loss -0.8843
2025-02-26 02:03:28.029664: val_loss -0.745
2025-02-26 02:03:28.029747: Pseudo dice [0.7935]
2025-02-26 02:03:28.029854: Epoch time: 65.85 s
2025-02-26 02:03:29.354076: 
2025-02-26 02:03:29.354285: Epoch 543
2025-02-26 02:03:29.354424: Current learning rate: 0.00494
2025-02-26 02:04:35.232040: train_loss -0.8988
2025-02-26 02:04:35.232444: val_loss -0.7379
2025-02-26 02:04:35.232528: Pseudo dice [0.7871]
2025-02-26 02:04:35.232625: Epoch time: 65.88 s
2025-02-26 02:04:36.629965: 
2025-02-26 02:04:36.630180: Epoch 544
2025-02-26 02:04:36.630312: Current learning rate: 0.00493
2025-02-26 02:05:42.738505: train_loss -0.8875
2025-02-26 02:05:42.738893: val_loss -0.7461
2025-02-26 02:05:42.738976: Pseudo dice [0.7966]
2025-02-26 02:05:42.739074: Epoch time: 66.11 s
2025-02-26 02:05:44.058542: 
2025-02-26 02:05:44.058838: Epoch 545
2025-02-26 02:05:44.058965: Current learning rate: 0.00492
2025-02-26 02:06:49.496695: train_loss -0.8865
2025-02-26 02:06:49.497117: val_loss -0.7269
2025-02-26 02:06:49.497208: Pseudo dice [0.7844]
2025-02-26 02:06:49.497323: Epoch time: 65.44 s
2025-02-26 02:06:50.840798: 
2025-02-26 02:06:50.841017: Epoch 546
2025-02-26 02:06:50.841141: Current learning rate: 0.00491
2025-02-26 02:07:56.656974: train_loss -0.89
2025-02-26 02:07:56.657434: val_loss -0.7361
2025-02-26 02:07:56.657529: Pseudo dice [0.7953]
2025-02-26 02:07:56.657640: Epoch time: 65.82 s
2025-02-26 02:07:57.994417: 
2025-02-26 02:07:57.994637: Epoch 547
2025-02-26 02:07:57.994757: Current learning rate: 0.0049
2025-02-26 02:09:04.164396: train_loss -0.8891
2025-02-26 02:09:04.164692: val_loss -0.7379
2025-02-26 02:09:04.164780: Pseudo dice [0.793]
2025-02-26 02:09:04.164880: Epoch time: 66.17 s
2025-02-26 02:09:05.567624: 
2025-02-26 02:09:05.567839: Epoch 548
2025-02-26 02:09:05.567972: Current learning rate: 0.00489
2025-02-26 02:10:09.339412: train_loss -0.8979
2025-02-26 02:10:09.339883: val_loss -0.7307
2025-02-26 02:10:09.339982: Pseudo dice [0.7946]
2025-02-26 02:10:09.340095: Epoch time: 63.77 s
2025-02-26 02:10:10.717257: 
2025-02-26 02:10:10.717522: Epoch 549
2025-02-26 02:10:10.717664: Current learning rate: 0.00488
2025-02-26 02:11:18.583460: train_loss -0.8984
2025-02-26 02:11:18.583804: val_loss -0.7296
2025-02-26 02:11:18.583893: Pseudo dice [0.7934]
2025-02-26 02:11:18.584002: Epoch time: 67.87 s
2025-02-26 02:11:20.487666: 
2025-02-26 02:11:20.487884: Epoch 550
2025-02-26 02:11:20.488017: Current learning rate: 0.00487
2025-02-26 02:12:27.160453: train_loss -0.8893
2025-02-26 02:12:27.160907: val_loss -0.7279
2025-02-26 02:12:27.161494: Pseudo dice [0.7968]
2025-02-26 02:12:27.161619: Epoch time: 66.67 s
2025-02-26 02:12:28.883813: 
2025-02-26 02:12:28.884070: Epoch 551
2025-02-26 02:12:28.884194: Current learning rate: 0.00486
2025-02-26 02:13:31.966045: train_loss -0.8997
2025-02-26 02:13:31.966479: val_loss -0.6981
2025-02-26 02:13:31.966566: Pseudo dice [0.7606]
2025-02-26 02:13:31.966667: Epoch time: 63.08 s
2025-02-26 02:13:33.273957: 
2025-02-26 02:13:33.274202: Epoch 552
2025-02-26 02:13:33.274330: Current learning rate: 0.00485
2025-02-26 02:14:40.299037: train_loss -0.8948
2025-02-26 02:14:40.299515: val_loss -0.733
2025-02-26 02:14:40.299610: Pseudo dice [0.7914]
2025-02-26 02:14:40.299719: Epoch time: 67.03 s
2025-02-26 02:14:41.578540: 
2025-02-26 02:14:41.578766: Epoch 553
2025-02-26 02:14:41.578892: Current learning rate: 0.00484
2025-02-26 02:15:45.856557: train_loss -0.8608
2025-02-26 02:15:45.856977: val_loss -0.7109
2025-02-26 02:15:45.857071: Pseudo dice [0.7731]
2025-02-26 02:15:45.857181: Epoch time: 64.28 s
2025-02-26 02:15:47.200794: 
2025-02-26 02:15:47.201022: Epoch 554
2025-02-26 02:15:47.201149: Current learning rate: 0.00484
2025-02-26 02:16:52.975402: train_loss -0.8469
2025-02-26 02:16:52.975708: val_loss -0.7005
2025-02-26 02:16:52.975799: Pseudo dice [0.7619]
2025-02-26 02:16:52.975904: Epoch time: 65.78 s
2025-02-26 02:16:54.377799: 
2025-02-26 02:16:54.378020: Epoch 555
2025-02-26 02:16:54.378142: Current learning rate: 0.00483
2025-02-26 02:17:59.827068: train_loss -0.8156
2025-02-26 02:17:59.827485: val_loss -0.7216
2025-02-26 02:17:59.827570: Pseudo dice [0.7764]
2025-02-26 02:17:59.827675: Epoch time: 65.45 s
2025-02-26 02:18:01.186184: 
2025-02-26 02:18:01.186435: Epoch 556
2025-02-26 02:18:01.186561: Current learning rate: 0.00482
2025-02-26 02:19:07.899875: train_loss -0.8569
2025-02-26 02:19:07.900273: val_loss -0.7426
2025-02-26 02:19:07.900385: Pseudo dice [0.7973]
2025-02-26 02:19:07.900491: Epoch time: 66.72 s
2025-02-26 02:19:09.233334: 
2025-02-26 02:19:09.233558: Epoch 557
2025-02-26 02:19:09.233685: Current learning rate: 0.00481
2025-02-26 02:20:14.995879: train_loss -0.869
2025-02-26 02:20:14.996289: val_loss -0.7401
2025-02-26 02:20:14.996400: Pseudo dice [0.7916]
2025-02-26 02:20:14.996511: Epoch time: 65.76 s
2025-02-26 02:20:16.340709: 
2025-02-26 02:20:16.340942: Epoch 558
2025-02-26 02:20:16.341061: Current learning rate: 0.0048
2025-02-26 02:21:20.979996: train_loss -0.8763
2025-02-26 02:21:20.980450: val_loss -0.7408
2025-02-26 02:21:20.980538: Pseudo dice [0.791]
2025-02-26 02:21:20.980642: Epoch time: 64.64 s
2025-02-26 02:21:22.383523: 
2025-02-26 02:21:22.383735: Epoch 559
2025-02-26 02:21:22.383865: Current learning rate: 0.00479
2025-02-26 02:22:29.668164: train_loss -0.8722
2025-02-26 02:22:29.668509: val_loss -0.7253
2025-02-26 02:22:29.668594: Pseudo dice [0.7819]
2025-02-26 02:22:29.668689: Epoch time: 67.29 s
2025-02-26 02:22:31.074508: 
2025-02-26 02:22:31.074722: Epoch 560
2025-02-26 02:22:31.074843: Current learning rate: 0.00478
2025-02-26 02:23:36.519154: train_loss -0.8725
2025-02-26 02:23:36.519615: val_loss -0.7346
2025-02-26 02:23:36.519708: Pseudo dice [0.7897]
2025-02-26 02:23:36.519823: Epoch time: 65.45 s
2025-02-26 02:23:37.923477: 
2025-02-26 02:23:37.923699: Epoch 561
2025-02-26 02:23:37.923824: Current learning rate: 0.00477
2025-02-26 02:24:43.131889: train_loss -0.8585
2025-02-26 02:24:43.132452: val_loss -0.7064
2025-02-26 02:24:43.132568: Pseudo dice [0.7667]
2025-02-26 02:24:43.132680: Epoch time: 65.21 s
2025-02-26 02:24:44.490198: 
2025-02-26 02:24:44.490432: Epoch 562
2025-02-26 02:24:44.490557: Current learning rate: 0.00476
2025-02-26 02:25:51.488324: train_loss -0.827
2025-02-26 02:25:51.506578: val_loss -0.7175
2025-02-26 02:25:51.506915: Pseudo dice [0.7694]
2025-02-26 02:25:51.507028: Epoch time: 67.0 s
2025-02-26 02:25:53.254541: 
2025-02-26 02:25:53.254775: Epoch 563
2025-02-26 02:25:53.254908: Current learning rate: 0.00475
2025-02-26 02:26:59.523556: train_loss -0.8568
2025-02-26 02:26:59.523940: val_loss -0.7263
2025-02-26 02:26:59.524030: Pseudo dice [0.7758]
2025-02-26 02:26:59.524134: Epoch time: 66.27 s
2025-02-26 02:27:00.864099: 
2025-02-26 02:27:00.864346: Epoch 564
2025-02-26 02:27:00.864469: Current learning rate: 0.00474
2025-02-26 02:28:06.292479: train_loss -0.8814
2025-02-26 02:28:06.292957: val_loss -0.7381
2025-02-26 02:28:06.293046: Pseudo dice [0.7963]
2025-02-26 02:28:06.293157: Epoch time: 65.43 s
2025-02-26 02:28:07.651682: 
2025-02-26 02:28:07.651920: Epoch 565
2025-02-26 02:28:07.652045: Current learning rate: 0.00473
2025-02-26 02:29:14.667547: train_loss -0.8825
2025-02-26 02:29:14.668019: val_loss -0.7205
2025-02-26 02:29:14.668108: Pseudo dice [0.7725]
2025-02-26 02:29:14.668216: Epoch time: 67.02 s
2025-02-26 02:29:16.041595: 
2025-02-26 02:29:16.041851: Epoch 566
2025-02-26 02:29:16.041984: Current learning rate: 0.00472
2025-02-26 02:30:21.927673: train_loss -0.8855
2025-02-26 02:30:21.928125: val_loss -0.7288
2025-02-26 02:30:21.928213: Pseudo dice [0.7871]
2025-02-26 02:30:21.928331: Epoch time: 65.89 s
2025-02-26 02:30:23.274209: 
2025-02-26 02:30:23.274467: Epoch 567
2025-02-26 02:30:23.274600: Current learning rate: 0.00471
2025-02-26 02:31:28.518588: train_loss -0.8919
2025-02-26 02:31:28.519022: val_loss -0.7391
2025-02-26 02:31:28.519121: Pseudo dice [0.7933]
2025-02-26 02:31:28.519237: Epoch time: 65.25 s
2025-02-26 02:31:29.888376: 
2025-02-26 02:31:29.888642: Epoch 568
2025-02-26 02:31:29.888774: Current learning rate: 0.0047
2025-02-26 02:32:35.304836: train_loss -0.8853
2025-02-26 02:32:35.305246: val_loss -0.7083
2025-02-26 02:32:35.305357: Pseudo dice [0.7715]
2025-02-26 02:32:35.305465: Epoch time: 65.42 s
2025-02-26 02:32:36.687232: 
2025-02-26 02:32:36.687545: Epoch 569
2025-02-26 02:32:36.687673: Current learning rate: 0.00469
2025-02-26 02:33:41.665843: train_loss -0.8642
2025-02-26 02:33:41.666229: val_loss -0.7423
2025-02-26 02:33:41.666330: Pseudo dice [0.7965]
2025-02-26 02:33:41.666442: Epoch time: 64.98 s
2025-02-26 02:33:43.085525: 
2025-02-26 02:33:43.085766: Epoch 570
2025-02-26 02:33:43.085890: Current learning rate: 0.00468
2025-02-26 02:34:48.439868: train_loss -0.8922
2025-02-26 02:34:48.440272: val_loss -0.7374
2025-02-26 02:34:48.440474: Pseudo dice [0.7872]
2025-02-26 02:34:48.440587: Epoch time: 65.36 s
2025-02-26 02:34:49.746890: 
2025-02-26 02:34:49.747100: Epoch 571
2025-02-26 02:34:49.747221: Current learning rate: 0.00467
2025-02-26 02:35:54.594182: train_loss -0.8815
2025-02-26 02:35:54.594538: val_loss -0.7289
2025-02-26 02:35:54.594652: Pseudo dice [0.7789]
2025-02-26 02:35:54.594769: Epoch time: 64.85 s
2025-02-26 02:35:56.002795: 
2025-02-26 02:35:56.003013: Epoch 572
2025-02-26 02:35:56.003137: Current learning rate: 0.00466
2025-02-26 02:37:01.824991: train_loss -0.9004
2025-02-26 02:37:01.825391: val_loss -0.7378
2025-02-26 02:37:01.825587: Pseudo dice [0.7892]
2025-02-26 02:37:01.825802: Epoch time: 65.82 s
2025-02-26 02:37:03.161475: 
2025-02-26 02:37:03.161709: Epoch 573
2025-02-26 02:37:03.161830: Current learning rate: 0.00465
2025-02-26 02:38:07.912742: train_loss -0.8907
2025-02-26 02:38:07.913165: val_loss -0.7533
2025-02-26 02:38:07.913250: Pseudo dice [0.8031]
2025-02-26 02:38:07.913373: Epoch time: 64.75 s
2025-02-26 02:38:09.278932: 
2025-02-26 02:38:09.279200: Epoch 574
2025-02-26 02:38:09.279364: Current learning rate: 0.00464
2025-02-26 02:39:15.659351: train_loss -0.8877
2025-02-26 02:39:15.659781: val_loss -0.7464
2025-02-26 02:39:15.659873: Pseudo dice [0.7938]
2025-02-26 02:39:15.659988: Epoch time: 66.38 s
2025-02-26 02:39:17.376797: 
2025-02-26 02:39:17.377041: Epoch 575
2025-02-26 02:39:17.377165: Current learning rate: 0.00463
2025-02-26 02:40:22.575988: train_loss -0.8951
2025-02-26 02:40:22.576434: val_loss -0.7392
2025-02-26 02:40:22.576539: Pseudo dice [0.791]
2025-02-26 02:40:22.576657: Epoch time: 65.2 s
2025-02-26 02:40:23.911245: 
2025-02-26 02:40:23.911478: Epoch 576
2025-02-26 02:40:23.911604: Current learning rate: 0.00462
2025-02-26 02:41:30.501598: train_loss -0.8864
2025-02-26 02:41:30.502024: val_loss -0.7442
2025-02-26 02:41:30.502681: Pseudo dice [0.8006]
2025-02-26 02:41:30.502825: Epoch time: 66.59 s
2025-02-26 02:41:31.878508: 
2025-02-26 02:41:31.878746: Epoch 577
2025-02-26 02:41:31.878874: Current learning rate: 0.00461
2025-02-26 02:42:38.776239: train_loss -0.8901
2025-02-26 02:42:38.776656: val_loss -0.7384
2025-02-26 02:42:38.776742: Pseudo dice [0.7888]
2025-02-26 02:42:38.776845: Epoch time: 66.9 s
2025-02-26 02:42:40.120759: 
2025-02-26 02:42:40.120967: Epoch 578
2025-02-26 02:42:40.121097: Current learning rate: 0.0046
2025-02-26 02:43:46.729892: train_loss -0.8995
2025-02-26 02:43:46.730321: val_loss -0.7399
2025-02-26 02:43:46.730447: Pseudo dice [0.7901]
2025-02-26 02:43:46.730568: Epoch time: 66.61 s
2025-02-26 02:43:48.108480: 
2025-02-26 02:43:48.108701: Epoch 579
2025-02-26 02:43:48.108828: Current learning rate: 0.00459
2025-02-26 02:44:54.958113: train_loss -0.8945
2025-02-26 02:44:54.958602: val_loss -0.7461
2025-02-26 02:44:54.958693: Pseudo dice [0.8058]
2025-02-26 02:44:54.958785: Epoch time: 66.85 s
2025-02-26 02:44:56.296533: 
2025-02-26 02:44:56.296746: Epoch 580
2025-02-26 02:44:56.296871: Current learning rate: 0.00458
2025-02-26 02:46:01.048743: train_loss -0.9045
2025-02-26 02:46:01.049111: val_loss -0.7405
2025-02-26 02:46:01.049198: Pseudo dice [0.7982]
2025-02-26 02:46:01.049404: Epoch time: 64.75 s
2025-02-26 02:46:02.477240: 
2025-02-26 02:46:02.477462: Epoch 581
2025-02-26 02:46:02.477583: Current learning rate: 0.00457
2025-02-26 02:47:09.238916: train_loss -0.9009
2025-02-26 02:47:09.239357: val_loss -0.741
2025-02-26 02:47:09.239456: Pseudo dice [0.7946]
2025-02-26 02:47:09.239572: Epoch time: 66.76 s
2025-02-26 02:47:10.576398: 
2025-02-26 02:47:10.576617: Epoch 582
2025-02-26 02:47:10.576744: Current learning rate: 0.00456
2025-02-26 02:48:15.086569: train_loss -0.8989
2025-02-26 02:48:15.086994: val_loss -0.736
2025-02-26 02:48:15.087082: Pseudo dice [0.7974]
2025-02-26 02:48:15.087186: Epoch time: 64.51 s
2025-02-26 02:48:16.429013: 
2025-02-26 02:48:16.429232: Epoch 583
2025-02-26 02:48:16.429374: Current learning rate: 0.00455
2025-02-26 02:49:22.436407: train_loss -0.9069
2025-02-26 02:49:22.436806: val_loss -0.732
2025-02-26 02:49:22.436893: Pseudo dice [0.7884]
2025-02-26 02:49:22.436982: Epoch time: 66.01 s
2025-02-26 02:49:23.764207: 
2025-02-26 02:49:23.764458: Epoch 584
2025-02-26 02:49:23.764588: Current learning rate: 0.00454
2025-02-26 02:50:29.655177: train_loss -0.9118
2025-02-26 02:50:29.655581: val_loss -0.7422
2025-02-26 02:50:29.655666: Pseudo dice [0.7968]
2025-02-26 02:50:29.655767: Epoch time: 65.89 s
2025-02-26 02:50:30.994417: 
2025-02-26 02:50:30.994626: Epoch 585
2025-02-26 02:50:30.994760: Current learning rate: 0.00453
2025-02-26 02:51:38.038077: train_loss -0.9076
2025-02-26 02:51:38.038524: val_loss -0.734
2025-02-26 02:51:38.038721: Pseudo dice [0.7877]
2025-02-26 02:51:38.038848: Epoch time: 67.05 s
2025-02-26 02:51:39.822820: 
2025-02-26 02:51:39.823104: Epoch 586
2025-02-26 02:51:39.823283: Current learning rate: 0.00452
2025-02-26 02:52:46.066477: train_loss -0.8939
2025-02-26 02:52:46.066874: val_loss -0.7491
2025-02-26 02:52:46.066960: Pseudo dice [0.8006]
2025-02-26 02:52:46.067058: Epoch time: 66.25 s
2025-02-26 02:52:47.431087: 
2025-02-26 02:52:47.431313: Epoch 587
2025-02-26 02:52:47.431437: Current learning rate: 0.00451
2025-02-26 02:53:54.151461: train_loss -0.886
2025-02-26 02:53:54.151902: val_loss -0.7255
2025-02-26 02:53:54.151994: Pseudo dice [0.7938]
2025-02-26 02:53:54.152103: Epoch time: 66.72 s
2025-02-26 02:53:55.507842: 
2025-02-26 02:53:55.508057: Epoch 588
2025-02-26 02:53:55.508177: Current learning rate: 0.0045
2025-02-26 02:55:01.578183: train_loss -0.8711
2025-02-26 02:55:01.578655: val_loss -0.7306
2025-02-26 02:55:01.578926: Pseudo dice [0.7887]
2025-02-26 02:55:01.579139: Epoch time: 66.07 s
2025-02-26 02:55:03.013936: 
2025-02-26 02:55:03.014166: Epoch 589
2025-02-26 02:55:03.014310: Current learning rate: 0.00449
2025-02-26 02:56:08.434120: train_loss -0.8828
2025-02-26 02:56:08.434584: val_loss -0.7155
2025-02-26 02:56:08.434680: Pseudo dice [0.7714]
2025-02-26 02:56:08.434797: Epoch time: 65.42 s
2025-02-26 02:56:09.813044: 
2025-02-26 02:56:09.813246: Epoch 590
2025-02-26 02:56:09.813375: Current learning rate: 0.00448
2025-02-26 02:57:15.489051: train_loss -0.8865
2025-02-26 02:57:15.489429: val_loss -0.7344
2025-02-26 02:57:15.489511: Pseudo dice [0.7826]
2025-02-26 02:57:15.489607: Epoch time: 65.68 s
2025-02-26 02:57:16.863405: 
2025-02-26 02:57:16.863627: Epoch 591
2025-02-26 02:57:16.863748: Current learning rate: 0.00447
2025-02-26 02:58:21.838593: train_loss -0.892
2025-02-26 02:58:21.839087: val_loss -0.7325
2025-02-26 02:58:21.839191: Pseudo dice [0.7873]
2025-02-26 02:58:21.839318: Epoch time: 64.98 s
2025-02-26 02:58:23.147039: 
2025-02-26 02:58:23.147251: Epoch 592
2025-02-26 02:58:23.147381: Current learning rate: 0.00446
2025-02-26 02:59:27.570191: train_loss -0.8927
2025-02-26 02:59:27.570569: val_loss -0.7256
2025-02-26 02:59:27.570657: Pseudo dice [0.7828]
2025-02-26 02:59:27.570751: Epoch time: 64.42 s
2025-02-26 02:59:28.895279: 
2025-02-26 02:59:28.895501: Epoch 593
2025-02-26 02:59:28.895628: Current learning rate: 0.00445
2025-02-26 03:00:34.653575: train_loss -0.8916
2025-02-26 03:00:34.653934: val_loss -0.7488
2025-02-26 03:00:34.654014: Pseudo dice [0.7961]
2025-02-26 03:00:34.654112: Epoch time: 65.76 s
2025-02-26 03:00:36.038931: 
2025-02-26 03:00:36.039143: Epoch 594
2025-02-26 03:00:36.039266: Current learning rate: 0.00444
2025-02-26 03:01:39.621657: train_loss -0.8465
2025-02-26 03:01:39.622188: val_loss -0.7292
2025-02-26 03:01:39.622287: Pseudo dice [0.7712]
2025-02-26 03:01:39.622431: Epoch time: 63.58 s
2025-02-26 03:01:41.026974: 
2025-02-26 03:01:41.027195: Epoch 595
2025-02-26 03:01:41.027331: Current learning rate: 0.00443
2025-02-26 03:02:45.314824: train_loss -0.8625
2025-02-26 03:02:45.315231: val_loss -0.7272
2025-02-26 03:02:45.315334: Pseudo dice [0.7879]
2025-02-26 03:02:45.315448: Epoch time: 64.29 s
2025-02-26 03:02:46.658434: 
2025-02-26 03:02:46.658654: Epoch 596
2025-02-26 03:02:46.658780: Current learning rate: 0.00442
2025-02-26 03:03:50.888543: train_loss -0.868
2025-02-26 03:03:50.888952: val_loss -0.7361
2025-02-26 03:03:50.889038: Pseudo dice [0.7896]
2025-02-26 03:03:50.889147: Epoch time: 64.23 s
2025-02-26 03:03:52.273542: 
2025-02-26 03:03:52.273755: Epoch 597
2025-02-26 03:03:52.273882: Current learning rate: 0.00441
2025-02-26 03:04:58.077510: train_loss -0.8781
2025-02-26 03:04:58.077894: val_loss -0.7283
2025-02-26 03:04:58.077977: Pseudo dice [0.7818]
2025-02-26 03:04:58.078163: Epoch time: 65.81 s
2025-02-26 03:04:59.879757: 
2025-02-26 03:04:59.880010: Epoch 598
2025-02-26 03:04:59.880140: Current learning rate: 0.0044
2025-02-26 03:06:02.016639: train_loss -0.8492
2025-02-26 03:06:02.017004: val_loss -0.7278
2025-02-26 03:06:02.017095: Pseudo dice [0.7783]
2025-02-26 03:06:02.017194: Epoch time: 62.14 s
2025-02-26 03:06:03.395569: 
2025-02-26 03:06:03.395820: Epoch 599
2025-02-26 03:06:03.395951: Current learning rate: 0.00439
2025-02-26 03:07:08.713599: train_loss -0.8793
2025-02-26 03:07:08.713994: val_loss -0.7598
2025-02-26 03:07:08.714082: Pseudo dice [0.8073]
2025-02-26 03:07:08.714189: Epoch time: 65.32 s
2025-02-26 03:07:10.612020: 
2025-02-26 03:07:10.612247: Epoch 600
2025-02-26 03:07:10.612377: Current learning rate: 0.00438
2025-02-26 03:08:15.371476: train_loss -0.8942
2025-02-26 03:08:15.371867: val_loss -0.7296
2025-02-26 03:08:15.371968: Pseudo dice [0.7937]
2025-02-26 03:08:15.372072: Epoch time: 64.76 s
2025-02-26 03:08:16.735534: 
2025-02-26 03:08:16.735747: Epoch 601
2025-02-26 03:08:16.735866: Current learning rate: 0.00437
2025-02-26 03:09:21.115903: train_loss -0.894
2025-02-26 03:09:21.116357: val_loss -0.743
2025-02-26 03:09:21.116453: Pseudo dice [0.8033]
2025-02-26 03:09:21.116570: Epoch time: 64.38 s
2025-02-26 03:09:22.436745: 
2025-02-26 03:09:22.436972: Epoch 602
2025-02-26 03:09:22.437112: Current learning rate: 0.00436
2025-02-26 03:10:28.208751: train_loss -0.9038
2025-02-26 03:10:28.209177: val_loss -0.7427
2025-02-26 03:10:28.209849: Pseudo dice [0.8057]
2025-02-26 03:10:28.209979: Epoch time: 65.77 s
2025-02-26 03:10:29.522836: 
2025-02-26 03:10:29.523073: Epoch 603
2025-02-26 03:10:29.523198: Current learning rate: 0.00435
2025-02-26 03:11:34.780642: train_loss -0.9104
2025-02-26 03:11:34.780967: val_loss -0.7382
2025-02-26 03:11:34.781045: Pseudo dice [0.7957]
2025-02-26 03:11:34.781137: Epoch time: 65.26 s
2025-02-26 03:11:36.107275: 
2025-02-26 03:11:36.107487: Epoch 604
2025-02-26 03:11:36.107606: Current learning rate: 0.00434
2025-02-26 03:12:43.023862: train_loss -0.9087
2025-02-26 03:12:43.024247: val_loss -0.7476
2025-02-26 03:12:43.024350: Pseudo dice [0.8012]
2025-02-26 03:12:43.024455: Epoch time: 66.92 s
2025-02-26 03:12:44.350687: 
2025-02-26 03:12:44.350911: Epoch 605
2025-02-26 03:12:44.351032: Current learning rate: 0.00433
2025-02-26 03:13:50.037707: train_loss -0.9023
2025-02-26 03:13:50.038015: val_loss -0.7471
2025-02-26 03:13:50.038085: Pseudo dice [0.8042]
2025-02-26 03:13:50.038169: Epoch time: 65.69 s
2025-02-26 03:13:51.324426: 
2025-02-26 03:13:51.324645: Epoch 606
2025-02-26 03:13:51.324766: Current learning rate: 0.00432
2025-02-26 03:14:56.015779: train_loss -0.906
2025-02-26 03:14:56.016240: val_loss -0.7378
2025-02-26 03:14:56.016349: Pseudo dice [0.7933]
2025-02-26 03:14:56.016469: Epoch time: 64.69 s
2025-02-26 03:14:57.425777: 
2025-02-26 03:14:57.425980: Epoch 607
2025-02-26 03:14:57.426104: Current learning rate: 0.00431
2025-02-26 03:16:03.107939: train_loss -0.9076
2025-02-26 03:16:03.108371: val_loss -0.7487
2025-02-26 03:16:03.108476: Pseudo dice [0.8014]
2025-02-26 03:16:03.108581: Epoch time: 65.68 s
2025-02-26 03:16:04.461421: 
2025-02-26 03:16:04.461682: Epoch 608
2025-02-26 03:16:04.461808: Current learning rate: 0.0043
2025-02-26 03:17:11.335398: train_loss -0.9107
2025-02-26 03:17:11.335790: val_loss -0.7333
2025-02-26 03:17:11.335877: Pseudo dice [0.7884]
2025-02-26 03:17:11.335983: Epoch time: 66.88 s
2025-02-26 03:17:12.720980: 
2025-02-26 03:17:12.721187: Epoch 609
2025-02-26 03:17:12.721317: Current learning rate: 0.00429
2025-02-26 03:18:19.848958: train_loss -0.9
2025-02-26 03:18:19.849369: val_loss -0.7346
2025-02-26 03:18:19.849461: Pseudo dice [0.7881]
2025-02-26 03:18:19.849567: Epoch time: 67.13 s
2025-02-26 03:18:21.638016: 
2025-02-26 03:18:21.638265: Epoch 610
2025-02-26 03:18:21.638405: Current learning rate: 0.00429
2025-02-26 03:19:26.124855: train_loss -0.9027
2025-02-26 03:19:26.125129: val_loss -0.7394
2025-02-26 03:19:26.125200: Pseudo dice [0.7976]
2025-02-26 03:19:26.125275: Epoch time: 64.49 s
2025-02-26 03:19:27.512038: 
2025-02-26 03:19:27.512263: Epoch 611
2025-02-26 03:19:27.512392: Current learning rate: 0.00428
2025-02-26 03:20:32.143002: train_loss -0.9097
2025-02-26 03:20:32.143435: val_loss -0.7458
2025-02-26 03:20:32.143525: Pseudo dice [0.8008]
2025-02-26 03:20:32.143634: Epoch time: 64.63 s
2025-02-26 03:20:33.475388: 
2025-02-26 03:20:33.475614: Epoch 612
2025-02-26 03:20:33.475739: Current learning rate: 0.00427
2025-02-26 03:21:41.201981: train_loss -0.8995
2025-02-26 03:21:41.202379: val_loss -0.7471
2025-02-26 03:21:41.202470: Pseudo dice [0.803]
2025-02-26 03:21:41.202568: Epoch time: 67.73 s
2025-02-26 03:21:42.517612: 
2025-02-26 03:21:42.517823: Epoch 613
2025-02-26 03:21:42.517947: Current learning rate: 0.00426
2025-02-26 03:22:48.337235: train_loss -0.9089
2025-02-26 03:22:48.337700: val_loss -0.7474
2025-02-26 03:22:48.337788: Pseudo dice [0.8045]
2025-02-26 03:22:48.337889: Epoch time: 65.82 s
2025-02-26 03:22:49.675354: 
2025-02-26 03:22:49.675573: Epoch 614
2025-02-26 03:22:49.675692: Current learning rate: 0.00425
2025-02-26 03:23:55.861870: train_loss -0.9059
2025-02-26 03:23:55.862331: val_loss -0.748
2025-02-26 03:23:55.873614: Pseudo dice [0.8063]
2025-02-26 03:23:55.873872: Epoch time: 66.19 s
2025-02-26 03:23:57.218181: 
2025-02-26 03:23:57.218494: Epoch 615
2025-02-26 03:23:57.218632: Current learning rate: 0.00424
2025-02-26 03:25:02.439507: train_loss -0.9103
2025-02-26 03:25:02.439904: val_loss -0.7417
2025-02-26 03:25:02.439977: Pseudo dice [0.7906]
2025-02-26 03:25:02.440061: Epoch time: 65.22 s
2025-02-26 03:25:03.798388: 
2025-02-26 03:25:03.798664: Epoch 616
2025-02-26 03:25:03.798807: Current learning rate: 0.00423
2025-02-26 03:26:08.401998: train_loss -0.9068
2025-02-26 03:26:08.402403: val_loss -0.7446
2025-02-26 03:26:08.402485: Pseudo dice [0.7972]
2025-02-26 03:26:08.402581: Epoch time: 64.61 s
2025-02-26 03:26:09.697119: 
2025-02-26 03:26:09.697338: Epoch 617
2025-02-26 03:26:09.697463: Current learning rate: 0.00422
2025-02-26 03:27:12.878295: train_loss -0.9142
2025-02-26 03:27:12.878723: val_loss -0.7364
2025-02-26 03:27:12.878812: Pseudo dice [0.7908]
2025-02-26 03:27:12.878913: Epoch time: 63.18 s
2025-02-26 03:27:14.239620: 
2025-02-26 03:27:14.239830: Epoch 618
2025-02-26 03:27:14.239954: Current learning rate: 0.00421
2025-02-26 03:28:20.465496: train_loss -0.9127
2025-02-26 03:28:20.466012: val_loss -0.7395
2025-02-26 03:28:20.466155: Pseudo dice [0.7966]
2025-02-26 03:28:20.466258: Epoch time: 66.23 s
2025-02-26 03:28:21.867204: 
2025-02-26 03:28:21.867452: Epoch 619
2025-02-26 03:28:21.867576: Current learning rate: 0.0042
2025-02-26 03:29:27.241931: train_loss -0.9153
2025-02-26 03:29:27.242367: val_loss -0.7347
2025-02-26 03:29:27.242465: Pseudo dice [0.7956]
2025-02-26 03:29:27.242581: Epoch time: 65.38 s
2025-02-26 03:29:28.593263: 
2025-02-26 03:29:28.593503: Epoch 620
2025-02-26 03:29:28.593647: Current learning rate: 0.00419
2025-02-26 03:30:32.104484: train_loss -0.9092
2025-02-26 03:30:32.104895: val_loss -0.7402
2025-02-26 03:30:32.104983: Pseudo dice [0.7929]
2025-02-26 03:30:32.105103: Epoch time: 63.51 s
2025-02-26 03:30:33.935140: 
2025-02-26 03:30:33.935374: Epoch 621
2025-02-26 03:30:33.935504: Current learning rate: 0.00418
2025-02-26 03:31:39.242701: train_loss -0.9068
2025-02-26 03:31:39.250093: val_loss -0.7323
2025-02-26 03:31:39.250266: Pseudo dice [0.7896]
2025-02-26 03:31:39.250382: Epoch time: 65.31 s
2025-02-26 03:31:40.602156: 
2025-02-26 03:31:40.602393: Epoch 622
2025-02-26 03:31:40.602517: Current learning rate: 0.00417
2025-02-26 03:32:44.540350: train_loss -0.9075
2025-02-26 03:32:44.540742: val_loss -0.7526
2025-02-26 03:32:44.540828: Pseudo dice [0.8055]
2025-02-26 03:32:44.540926: Epoch time: 63.94 s
2025-02-26 03:32:45.909775: 
2025-02-26 03:32:45.909995: Epoch 623
2025-02-26 03:32:45.910118: Current learning rate: 0.00416
2025-02-26 03:33:50.411670: train_loss -0.918
2025-02-26 03:33:50.412045: val_loss -0.73
2025-02-26 03:33:50.412131: Pseudo dice [0.7957]
2025-02-26 03:33:50.412231: Epoch time: 64.5 s
2025-02-26 03:33:51.777864: 
2025-02-26 03:33:51.778090: Epoch 624
2025-02-26 03:33:51.778208: Current learning rate: 0.00415
2025-02-26 03:34:57.259325: train_loss -0.9151
2025-02-26 03:34:57.259731: val_loss -0.7258
2025-02-26 03:34:57.259830: Pseudo dice [0.7832]
2025-02-26 03:34:57.259942: Epoch time: 65.48 s
2025-02-26 03:34:58.647972: 
2025-02-26 03:34:58.648207: Epoch 625
2025-02-26 03:34:58.648343: Current learning rate: 0.00414
2025-02-26 03:36:03.337835: train_loss -0.9164
2025-02-26 03:36:03.338107: val_loss -0.746
2025-02-26 03:36:03.338180: Pseudo dice [0.7951]
2025-02-26 03:36:03.338265: Epoch time: 64.69 s
2025-02-26 03:36:04.702749: 
2025-02-26 03:36:04.703001: Epoch 626
2025-02-26 03:36:04.703131: Current learning rate: 0.00413
2025-02-26 03:37:09.079504: train_loss -0.8583
2025-02-26 03:37:09.079893: val_loss -0.737
2025-02-26 03:37:09.079974: Pseudo dice [0.7905]
2025-02-26 03:37:09.080070: Epoch time: 64.38 s
2025-02-26 03:37:10.445625: 
2025-02-26 03:37:10.445844: Epoch 627
2025-02-26 03:37:10.445966: Current learning rate: 0.00412
2025-02-26 03:38:15.971955: train_loss -0.8771
2025-02-26 03:38:15.972338: val_loss -0.7454
2025-02-26 03:38:15.972446: Pseudo dice [0.7952]
2025-02-26 03:38:15.972554: Epoch time: 65.53 s
2025-02-26 03:38:17.307405: 
2025-02-26 03:38:17.307617: Epoch 628
2025-02-26 03:38:17.307738: Current learning rate: 0.00411
2025-02-26 03:39:22.266853: train_loss -0.8972
2025-02-26 03:39:22.267244: val_loss -0.7271
2025-02-26 03:39:22.268012: Pseudo dice [0.7845]
2025-02-26 03:39:22.268141: Epoch time: 64.96 s
2025-02-26 03:39:23.838043: 
2025-02-26 03:39:23.838278: Epoch 629
2025-02-26 03:39:23.838419: Current learning rate: 0.0041
2025-02-26 03:40:27.560869: train_loss -0.8822
2025-02-26 03:40:27.561278: val_loss -0.7238
2025-02-26 03:40:27.561386: Pseudo dice [0.7898]
2025-02-26 03:40:27.561489: Epoch time: 63.72 s
2025-02-26 03:40:28.989586: 
2025-02-26 03:40:28.989815: Epoch 630
2025-02-26 03:40:28.989948: Current learning rate: 0.00409
2025-02-26 03:41:34.387544: train_loss -0.8813
2025-02-26 03:41:34.387926: val_loss -0.7397
2025-02-26 03:41:34.388016: Pseudo dice [0.7982]
2025-02-26 03:41:34.388128: Epoch time: 65.4 s
2025-02-26 03:41:35.737090: 
2025-02-26 03:41:35.737316: Epoch 631
2025-02-26 03:41:35.737441: Current learning rate: 0.00408
2025-02-26 03:42:41.150763: train_loss -0.8968
2025-02-26 03:42:41.151170: val_loss -0.7464
2025-02-26 03:42:41.151252: Pseudo dice [0.7972]
2025-02-26 03:42:41.151381: Epoch time: 65.42 s
2025-02-26 03:42:42.520012: 
2025-02-26 03:42:42.520220: Epoch 632
2025-02-26 03:42:42.520357: Current learning rate: 0.00407
2025-02-26 03:43:48.226279: train_loss -0.9015
2025-02-26 03:43:48.226677: val_loss -0.7434
2025-02-26 03:43:48.226768: Pseudo dice [0.7997]
2025-02-26 03:43:48.226870: Epoch time: 65.71 s
2025-02-26 03:43:49.980283: 
2025-02-26 03:43:49.980606: Epoch 633
2025-02-26 03:43:49.980759: Current learning rate: 0.00406
2025-02-26 03:44:56.302623: train_loss -0.9089
2025-02-26 03:44:56.303028: val_loss -0.7498
2025-02-26 03:44:56.303123: Pseudo dice [0.7951]
2025-02-26 03:44:56.303224: Epoch time: 66.32 s
2025-02-26 03:44:57.629170: 
2025-02-26 03:44:57.629415: Epoch 634
2025-02-26 03:44:57.629534: Current learning rate: 0.00405
2025-02-26 03:46:06.850600: train_loss -0.9048
2025-02-26 03:46:06.850931: val_loss -0.7192
2025-02-26 03:46:06.851013: Pseudo dice [0.7808]
2025-02-26 03:46:06.851108: Epoch time: 69.22 s
2025-02-26 03:46:08.214526: 
2025-02-26 03:46:08.214739: Epoch 635
2025-02-26 03:46:08.214859: Current learning rate: 0.00404
2025-02-26 03:47:16.148479: train_loss -0.9077
2025-02-26 03:47:16.149053: val_loss -0.7505
2025-02-26 03:47:16.149158: Pseudo dice [0.7956]
2025-02-26 03:47:16.149264: Epoch time: 67.94 s
2025-02-26 03:47:17.507086: 
2025-02-26 03:47:17.507333: Epoch 636
2025-02-26 03:47:17.507460: Current learning rate: 0.00403
2025-02-26 03:48:21.937215: train_loss -0.9106
2025-02-26 03:48:21.937645: val_loss -0.7454
2025-02-26 03:48:21.937739: Pseudo dice [0.7936]
2025-02-26 03:48:21.937850: Epoch time: 64.43 s
2025-02-26 03:48:23.276478: 
2025-02-26 03:48:23.276702: Epoch 637
2025-02-26 03:48:23.276832: Current learning rate: 0.00402
2025-02-26 03:49:28.273549: train_loss -0.906
2025-02-26 03:49:28.273886: val_loss -0.7419
2025-02-26 03:49:28.273963: Pseudo dice [0.7981]
2025-02-26 03:49:28.274054: Epoch time: 65.0 s
2025-02-26 03:49:29.628247: 
2025-02-26 03:49:29.628485: Epoch 638
2025-02-26 03:49:29.628611: Current learning rate: 0.00401
2025-02-26 03:50:37.197310: train_loss -0.9104
2025-02-26 03:50:37.197761: val_loss -0.7619
2025-02-26 03:50:37.197845: Pseudo dice [0.8076]
2025-02-26 03:50:37.197954: Epoch time: 67.57 s
2025-02-26 03:50:38.533788: 
2025-02-26 03:50:38.533999: Epoch 639
2025-02-26 03:50:38.534119: Current learning rate: 0.004
2025-02-26 03:51:43.633643: train_loss -0.8986
2025-02-26 03:51:43.634037: val_loss -0.7548
2025-02-26 03:51:43.634129: Pseudo dice [0.8029]
2025-02-26 03:51:43.634231: Epoch time: 65.1 s
2025-02-26 03:51:45.028920: 
2025-02-26 03:51:45.029147: Epoch 640
2025-02-26 03:51:45.029271: Current learning rate: 0.00399
2025-02-26 03:52:50.882671: train_loss -0.9107
2025-02-26 03:52:50.883114: val_loss -0.7269
2025-02-26 03:52:50.883204: Pseudo dice [0.7848]
2025-02-26 03:52:50.883324: Epoch time: 65.86 s
2025-02-26 03:52:52.261063: 
2025-02-26 03:52:52.261279: Epoch 641
2025-02-26 03:52:52.261417: Current learning rate: 0.00398
2025-02-26 03:53:58.233288: train_loss -0.9122
2025-02-26 03:53:58.233660: val_loss -0.7404
2025-02-26 03:53:58.233747: Pseudo dice [0.797]
2025-02-26 03:53:58.233948: Epoch time: 65.97 s
2025-02-26 03:53:59.629237: 
2025-02-26 03:53:59.629473: Epoch 642
2025-02-26 03:53:59.629604: Current learning rate: 0.00397
2025-02-26 03:55:05.654516: train_loss -0.906
2025-02-26 03:55:05.654863: val_loss -0.7319
2025-02-26 03:55:05.654984: Pseudo dice [0.7824]
2025-02-26 03:55:05.655113: Epoch time: 66.03 s
2025-02-26 03:55:07.035694: 
2025-02-26 03:55:07.035920: Epoch 643
2025-02-26 03:55:07.036043: Current learning rate: 0.00396
2025-02-26 03:56:13.558205: train_loss -0.9021
2025-02-26 03:56:13.558621: val_loss -0.7479
2025-02-26 03:56:13.558707: Pseudo dice [0.7974]
2025-02-26 03:56:13.558810: Epoch time: 66.52 s
2025-02-26 03:56:14.951505: 
2025-02-26 03:56:14.951717: Epoch 644
2025-02-26 03:56:14.951842: Current learning rate: 0.00395
2025-02-26 03:57:20.320916: train_loss -0.9144
2025-02-26 03:57:20.321517: val_loss -0.7314
2025-02-26 03:57:20.321620: Pseudo dice [0.7891]
2025-02-26 03:57:20.321723: Epoch time: 65.37 s
2025-02-26 03:57:22.116787: 
2025-02-26 03:57:22.117013: Epoch 645
2025-02-26 03:57:22.117153: Current learning rate: 0.00394
2025-02-26 03:58:29.488716: train_loss -0.916
2025-02-26 03:58:29.489143: val_loss -0.7428
2025-02-26 03:58:29.489244: Pseudo dice [0.8032]
2025-02-26 03:58:29.489372: Epoch time: 67.37 s
2025-02-26 03:58:30.805165: 
2025-02-26 03:58:30.805434: Epoch 646
2025-02-26 03:58:30.805572: Current learning rate: 0.00393
2025-02-26 03:59:37.625945: train_loss -0.9151
2025-02-26 03:59:37.626341: val_loss -0.7502
2025-02-26 03:59:37.626441: Pseudo dice [0.8094]
2025-02-26 03:59:37.626560: Epoch time: 66.82 s
2025-02-26 03:59:38.958556: 
2025-02-26 03:59:38.958785: Epoch 647
2025-02-26 03:59:38.958908: Current learning rate: 0.00392
2025-02-26 04:00:44.880938: train_loss -0.8994
2025-02-26 04:00:44.881257: val_loss -0.7227
2025-02-26 04:00:44.881363: Pseudo dice [0.7791]
2025-02-26 04:00:44.881459: Epoch time: 65.92 s
2025-02-26 04:00:46.237465: 
2025-02-26 04:00:46.237713: Epoch 648
2025-02-26 04:00:46.237845: Current learning rate: 0.00391
2025-02-26 04:01:52.922776: train_loss -0.9075
2025-02-26 04:01:52.923234: val_loss -0.734
2025-02-26 04:01:52.923336: Pseudo dice [0.7851]
2025-02-26 04:01:52.923450: Epoch time: 66.69 s
2025-02-26 04:01:54.379724: 
2025-02-26 04:01:54.379977: Epoch 649
2025-02-26 04:01:54.380105: Current learning rate: 0.0039
2025-02-26 04:02:59.466541: train_loss -0.9023
2025-02-26 04:02:59.466973: val_loss -0.7429
2025-02-26 04:02:59.467058: Pseudo dice [0.792]
2025-02-26 04:02:59.467160: Epoch time: 65.09 s
2025-02-26 04:03:01.347175: 
2025-02-26 04:03:01.347487: Epoch 650
2025-02-26 04:03:01.347617: Current learning rate: 0.00389
2025-02-26 04:04:08.278993: train_loss -0.9057
2025-02-26 04:04:08.279400: val_loss -0.7197
2025-02-26 04:04:08.279517: Pseudo dice [0.7754]
2025-02-26 04:04:08.279628: Epoch time: 66.93 s
2025-02-26 04:04:09.695614: 
2025-02-26 04:04:09.695867: Epoch 651
2025-02-26 04:04:09.695993: Current learning rate: 0.00388
2025-02-26 04:05:16.510436: train_loss -0.9123
2025-02-26 04:05:16.510936: val_loss -0.7392
2025-02-26 04:05:16.511042: Pseudo dice [0.7993]
2025-02-26 04:05:16.511156: Epoch time: 66.82 s
2025-02-26 04:05:17.849975: 
2025-02-26 04:05:17.850210: Epoch 652
2025-02-26 04:05:17.850340: Current learning rate: 0.00387
2025-02-26 04:06:22.327211: train_loss -0.911
2025-02-26 04:06:22.327612: val_loss -0.7463
2025-02-26 04:06:22.327695: Pseudo dice [0.8027]
2025-02-26 04:06:22.327793: Epoch time: 64.48 s
2025-02-26 04:06:23.642998: 
2025-02-26 04:06:23.643212: Epoch 653
2025-02-26 04:06:23.643356: Current learning rate: 0.00386
2025-02-26 04:07:28.360193: train_loss -0.9166
2025-02-26 04:07:28.360559: val_loss -0.755
2025-02-26 04:07:28.360663: Pseudo dice [0.8057]
2025-02-26 04:07:28.360780: Epoch time: 64.72 s
2025-02-26 04:07:29.747988: 
2025-02-26 04:07:29.748199: Epoch 654
2025-02-26 04:07:29.748329: Current learning rate: 0.00385
2025-02-26 04:08:36.789453: train_loss -0.9104
2025-02-26 04:08:36.789846: val_loss -0.7321
2025-02-26 04:08:36.790357: Pseudo dice [0.7852]
2025-02-26 04:08:36.790473: Epoch time: 67.04 s
2025-02-26 04:08:38.108705: 
2025-02-26 04:08:38.108903: Epoch 655
2025-02-26 04:08:38.109030: Current learning rate: 0.00384
2025-02-26 04:09:44.017423: train_loss -0.921
2025-02-26 04:09:44.017802: val_loss -0.7355
2025-02-26 04:09:44.017889: Pseudo dice [0.7911]
2025-02-26 04:09:44.017995: Epoch time: 65.91 s
2025-02-26 04:09:45.402109: 
2025-02-26 04:09:45.402323: Epoch 656
2025-02-26 04:09:45.402454: Current learning rate: 0.00383
2025-02-26 04:10:52.373111: train_loss -0.9029
2025-02-26 04:10:52.373522: val_loss -0.7381
2025-02-26 04:10:52.373610: Pseudo dice [0.7915]
2025-02-26 04:10:52.373712: Epoch time: 66.97 s
2025-02-26 04:10:54.144097: 
2025-02-26 04:10:54.144343: Epoch 657
2025-02-26 04:10:54.144464: Current learning rate: 0.00382
2025-02-26 04:11:59.476380: train_loss -0.9178
2025-02-26 04:11:59.476794: val_loss -0.7327
2025-02-26 04:11:59.476906: Pseudo dice [0.7935]
2025-02-26 04:11:59.477011: Epoch time: 65.33 s
2025-02-26 04:12:00.793076: 
2025-02-26 04:12:00.793289: Epoch 658
2025-02-26 04:12:00.793423: Current learning rate: 0.00381
2025-02-26 04:13:08.064133: train_loss -0.9036
2025-02-26 04:13:08.064553: val_loss -0.7582
2025-02-26 04:13:08.064677: Pseudo dice [0.8053]
2025-02-26 04:13:08.064873: Epoch time: 67.27 s
2025-02-26 04:13:09.411350: 
2025-02-26 04:13:09.411589: Epoch 659
2025-02-26 04:13:09.411717: Current learning rate: 0.0038
2025-02-26 04:14:16.738169: train_loss -0.9095
2025-02-26 04:14:16.738627: val_loss -0.7541
2025-02-26 04:14:16.738732: Pseudo dice [0.797]
2025-02-26 04:14:16.738836: Epoch time: 67.33 s
2025-02-26 04:14:18.053382: 
2025-02-26 04:14:18.053598: Epoch 660
2025-02-26 04:14:18.053719: Current learning rate: 0.00379
2025-02-26 04:15:24.431934: train_loss -0.9035
2025-02-26 04:15:24.432395: val_loss -0.7403
2025-02-26 04:15:24.432493: Pseudo dice [0.7879]
2025-02-26 04:15:24.432598: Epoch time: 66.38 s
2025-02-26 04:15:25.768254: 
2025-02-26 04:15:25.768487: Epoch 661
2025-02-26 04:15:25.768609: Current learning rate: 0.00378
2025-02-26 04:16:33.958028: train_loss -0.8963
2025-02-26 04:16:33.958450: val_loss -0.7379
2025-02-26 04:16:33.958541: Pseudo dice [0.7969]
2025-02-26 04:16:33.958650: Epoch time: 68.19 s
2025-02-26 04:16:35.291445: 
2025-02-26 04:16:35.291665: Epoch 662
2025-02-26 04:16:35.291785: Current learning rate: 0.00377
2025-02-26 04:17:41.851995: train_loss -0.9087
2025-02-26 04:17:41.852422: val_loss -0.7154
2025-02-26 04:17:41.852520: Pseudo dice [0.7766]
2025-02-26 04:17:41.852721: Epoch time: 66.56 s
2025-02-26 04:17:43.187150: 
2025-02-26 04:17:43.187400: Epoch 663
2025-02-26 04:17:43.187520: Current learning rate: 0.00376
2025-02-26 04:18:49.782416: train_loss -0.9106
2025-02-26 04:18:49.782812: val_loss -0.7381
2025-02-26 04:18:49.782898: Pseudo dice [0.7989]
2025-02-26 04:18:49.783004: Epoch time: 66.6 s
2025-02-26 04:18:51.153732: 
2025-02-26 04:18:51.153968: Epoch 664
2025-02-26 04:18:51.154092: Current learning rate: 0.00375
2025-02-26 04:19:59.175980: train_loss -0.9042
2025-02-26 04:19:59.176373: val_loss -0.7278
2025-02-26 04:19:59.176467: Pseudo dice [0.7843]
2025-02-26 04:19:59.176573: Epoch time: 68.02 s
2025-02-26 04:20:00.592590: 
2025-02-26 04:20:00.592808: Epoch 665
2025-02-26 04:20:00.592928: Current learning rate: 0.00374
2025-02-26 04:21:05.809982: train_loss -0.9119
2025-02-26 04:21:05.810367: val_loss -0.7432
2025-02-26 04:21:05.810456: Pseudo dice [0.7941]
2025-02-26 04:21:05.810563: Epoch time: 65.22 s
2025-02-26 04:21:07.163917: 
2025-02-26 04:21:07.164119: Epoch 666
2025-02-26 04:21:07.164253: Current learning rate: 0.00373
2025-02-26 04:22:13.238514: train_loss -0.9126
2025-02-26 04:22:13.238937: val_loss -0.7357
2025-02-26 04:22:13.239023: Pseudo dice [0.7915]
2025-02-26 04:22:13.239126: Epoch time: 66.08 s
2025-02-26 04:22:14.701686: 
2025-02-26 04:22:14.701906: Epoch 667
2025-02-26 04:22:14.702025: Current learning rate: 0.00372
2025-02-26 04:23:21.680353: train_loss -0.9219
2025-02-26 04:23:21.680820: val_loss -0.7171
2025-02-26 04:23:21.680914: Pseudo dice [0.7652]
2025-02-26 04:23:21.681026: Epoch time: 66.98 s
2025-02-26 04:23:23.396331: 
2025-02-26 04:23:23.396551: Epoch 668
2025-02-26 04:23:23.396678: Current learning rate: 0.00371
2025-02-26 04:24:29.882356: train_loss -0.9133
2025-02-26 04:24:29.882711: val_loss -0.7329
2025-02-26 04:24:29.882801: Pseudo dice [0.7934]
2025-02-26 04:24:29.882902: Epoch time: 66.49 s
2025-02-26 04:24:31.212112: 
2025-02-26 04:24:31.212480: Epoch 669
2025-02-26 04:24:31.212611: Current learning rate: 0.0037
2025-02-26 04:25:35.499851: train_loss -0.9109
2025-02-26 04:25:35.500368: val_loss -0.7268
2025-02-26 04:25:35.500546: Pseudo dice [0.7836]
2025-02-26 04:25:35.500641: Epoch time: 64.29 s
2025-02-26 04:25:36.817680: 
2025-02-26 04:25:36.817990: Epoch 670
2025-02-26 04:25:36.818126: Current learning rate: 0.00369
2025-02-26 04:26:44.333257: train_loss -0.8897
2025-02-26 04:26:44.333709: val_loss -0.717
2025-02-26 04:26:44.333817: Pseudo dice [0.7763]
2025-02-26 04:26:44.333941: Epoch time: 67.52 s
2025-02-26 04:26:45.698974: 
2025-02-26 04:26:45.699205: Epoch 671
2025-02-26 04:26:45.699334: Current learning rate: 0.00368
2025-02-26 04:27:50.012634: train_loss -0.9069
2025-02-26 04:27:50.013020: val_loss -0.7384
2025-02-26 04:27:50.013128: Pseudo dice [0.7917]
2025-02-26 04:27:50.013216: Epoch time: 64.32 s
2025-02-26 04:27:51.395842: 
2025-02-26 04:27:51.396049: Epoch 672
2025-02-26 04:27:51.396176: Current learning rate: 0.00367
2025-02-26 04:28:56.895837: train_loss -0.9038
2025-02-26 04:28:56.896206: val_loss -0.7307
2025-02-26 04:28:56.896330: Pseudo dice [0.7833]
2025-02-26 04:28:56.896461: Epoch time: 65.5 s
2025-02-26 04:28:58.275182: 
2025-02-26 04:28:58.275424: Epoch 673
2025-02-26 04:28:58.275546: Current learning rate: 0.00366
2025-02-26 04:30:03.181240: train_loss -0.9102
2025-02-26 04:30:03.181807: val_loss -0.7289
2025-02-26 04:30:03.181948: Pseudo dice [0.7832]
2025-02-26 04:30:03.182068: Epoch time: 64.91 s
2025-02-26 04:30:04.594555: 
2025-02-26 04:30:04.594759: Epoch 674
2025-02-26 04:30:04.594888: Current learning rate: 0.00365
2025-02-26 04:31:10.338514: train_loss -0.9032
2025-02-26 04:31:10.338892: val_loss -0.7291
2025-02-26 04:31:10.338979: Pseudo dice [0.7828]
2025-02-26 04:31:10.339083: Epoch time: 65.75 s
2025-02-26 04:31:11.746855: 
2025-02-26 04:31:11.747078: Epoch 675
2025-02-26 04:31:11.747205: Current learning rate: 0.00364
2025-02-26 04:32:17.207309: train_loss -0.8922
2025-02-26 04:32:17.207709: val_loss -0.6855
2025-02-26 04:32:17.207794: Pseudo dice [0.7788]
2025-02-26 04:32:17.207894: Epoch time: 65.46 s
2025-02-26 04:32:18.551771: 
2025-02-26 04:32:18.551963: Epoch 676
2025-02-26 04:32:18.552083: Current learning rate: 0.00363
2025-02-26 04:33:24.068119: train_loss -0.8742
2025-02-26 04:33:24.068581: val_loss -0.7011
2025-02-26 04:33:24.068678: Pseudo dice [0.7694]
2025-02-26 04:33:24.068789: Epoch time: 65.52 s
2025-02-26 04:33:25.488527: 
2025-02-26 04:33:25.488805: Epoch 677
2025-02-26 04:33:25.488930: Current learning rate: 0.00362
2025-02-26 04:34:30.963057: train_loss -0.8754
2025-02-26 04:34:30.974581: val_loss -0.7263
2025-02-26 04:34:30.974779: Pseudo dice [0.7828]
2025-02-26 04:34:30.974881: Epoch time: 65.48 s
2025-02-26 04:34:32.291080: 
2025-02-26 04:34:32.291314: Epoch 678
2025-02-26 04:34:32.291448: Current learning rate: 0.00361
2025-02-26 04:35:36.475292: train_loss -0.8635
2025-02-26 04:35:36.475695: val_loss -0.7375
2025-02-26 04:35:36.475799: Pseudo dice [0.7893]
2025-02-26 04:35:36.475900: Epoch time: 64.19 s
2025-02-26 04:35:37.850629: 
2025-02-26 04:35:37.850879: Epoch 679
2025-02-26 04:35:37.851008: Current learning rate: 0.0036
2025-02-26 04:36:42.537260: train_loss -0.8772
2025-02-26 04:36:42.537718: val_loss -0.7265
2025-02-26 04:36:42.537814: Pseudo dice [0.7777]
2025-02-26 04:36:42.537927: Epoch time: 64.69 s
2025-02-26 04:36:44.312926: 
2025-02-26 04:36:44.313160: Epoch 680
2025-02-26 04:36:44.313305: Current learning rate: 0.00359
2025-02-26 04:37:50.360333: train_loss -0.8954
2025-02-26 04:37:50.360691: val_loss -0.7289
2025-02-26 04:37:50.361161: Pseudo dice [0.7801]
2025-02-26 04:37:50.361294: Epoch time: 66.05 s
2025-02-26 04:37:51.707889: 
2025-02-26 04:37:51.708127: Epoch 681
2025-02-26 04:37:51.708249: Current learning rate: 0.00358
2025-02-26 04:38:56.215896: train_loss -0.9014
2025-02-26 04:38:56.216424: val_loss -0.7467
2025-02-26 04:38:56.216539: Pseudo dice [0.7988]
2025-02-26 04:38:56.216658: Epoch time: 64.51 s
2025-02-26 04:38:57.591186: 
2025-02-26 04:38:57.591424: Epoch 682
2025-02-26 04:38:57.591550: Current learning rate: 0.00357
2025-02-26 04:40:04.058097: train_loss -0.9095
2025-02-26 04:40:04.058516: val_loss -0.732
2025-02-26 04:40:04.058669: Pseudo dice [0.7896]
2025-02-26 04:40:04.058775: Epoch time: 66.47 s
2025-02-26 04:40:05.399996: 
2025-02-26 04:40:05.400231: Epoch 683
2025-02-26 04:40:05.400360: Current learning rate: 0.00356
2025-02-26 04:41:10.436208: train_loss -0.9054
2025-02-26 04:41:10.436526: val_loss -0.7265
2025-02-26 04:41:10.436711: Pseudo dice [0.7906]
2025-02-26 04:41:10.436838: Epoch time: 65.04 s
2025-02-26 04:41:11.812603: 
2025-02-26 04:41:11.812845: Epoch 684
2025-02-26 04:41:11.812968: Current learning rate: 0.00355
2025-02-26 04:42:18.250126: train_loss -0.9005
2025-02-26 04:42:18.250467: val_loss -0.7408
2025-02-26 04:42:18.250550: Pseudo dice [0.7927]
2025-02-26 04:42:18.250644: Epoch time: 66.44 s
2025-02-26 04:42:19.588145: 
2025-02-26 04:42:19.588371: Epoch 685
2025-02-26 04:42:19.588496: Current learning rate: 0.00354
2025-02-26 04:43:25.119649: train_loss -0.9104
2025-02-26 04:43:25.120058: val_loss -0.749
2025-02-26 04:43:25.120142: Pseudo dice [0.7978]
2025-02-26 04:43:25.120240: Epoch time: 65.53 s
2025-02-26 04:43:26.451161: 
2025-02-26 04:43:26.451418: Epoch 686
2025-02-26 04:43:26.451546: Current learning rate: 0.00353
2025-02-26 04:44:30.274293: train_loss -0.9173
2025-02-26 04:44:30.274714: val_loss -0.7266
2025-02-26 04:44:30.274808: Pseudo dice [0.7769]
2025-02-26 04:44:30.274912: Epoch time: 63.82 s
2025-02-26 04:44:31.567866: 
2025-02-26 04:44:31.568106: Epoch 687
2025-02-26 04:44:31.568229: Current learning rate: 0.00352
2025-02-26 04:45:36.888220: train_loss -0.9105
2025-02-26 04:45:36.888571: val_loss -0.7399
2025-02-26 04:45:36.888680: Pseudo dice [0.7849]
2025-02-26 04:45:36.888798: Epoch time: 65.32 s
2025-02-26 04:45:38.254863: 
2025-02-26 04:45:38.255077: Epoch 688
2025-02-26 04:45:38.255197: Current learning rate: 0.00351
2025-02-26 04:46:43.105490: train_loss -0.9172
2025-02-26 04:46:43.105977: val_loss -0.7328
2025-02-26 04:46:43.106063: Pseudo dice [0.7837]
2025-02-26 04:46:43.106167: Epoch time: 64.85 s
2025-02-26 04:46:44.414569: 
2025-02-26 04:46:44.414783: Epoch 689
2025-02-26 04:46:44.414905: Current learning rate: 0.0035
2025-02-26 04:47:48.669843: train_loss -0.9024
2025-02-26 04:47:48.670310: val_loss -0.7427
2025-02-26 04:47:48.670408: Pseudo dice [0.7993]
2025-02-26 04:47:48.670524: Epoch time: 64.26 s
2025-02-26 04:47:50.006112: 
2025-02-26 04:47:50.006321: Epoch 690
2025-02-26 04:47:50.006448: Current learning rate: 0.00349
2025-02-26 04:48:56.952363: train_loss -0.913
2025-02-26 04:48:56.952790: val_loss -0.7387
2025-02-26 04:48:56.952876: Pseudo dice [0.7908]
2025-02-26 04:48:56.952977: Epoch time: 66.95 s
2025-02-26 04:48:58.758821: 
2025-02-26 04:48:58.759066: Epoch 691
2025-02-26 04:48:58.759191: Current learning rate: 0.00348
2025-02-26 04:50:03.265042: train_loss -0.922
2025-02-26 04:50:03.265486: val_loss -0.7404
2025-02-26 04:50:03.265579: Pseudo dice [0.7978]
2025-02-26 04:50:03.265684: Epoch time: 64.51 s
2025-02-26 04:50:04.617954: 
2025-02-26 04:50:04.618184: Epoch 692
2025-02-26 04:50:04.618310: Current learning rate: 0.00346
2025-02-26 04:51:08.606775: train_loss -0.9242
2025-02-26 04:51:08.607165: val_loss -0.7228
2025-02-26 04:51:08.607251: Pseudo dice [0.7832]
2025-02-26 04:51:08.607396: Epoch time: 63.99 s
2025-02-26 04:51:09.942240: 
2025-02-26 04:51:09.942477: Epoch 693
2025-02-26 04:51:09.942609: Current learning rate: 0.00345
2025-02-26 04:52:13.866903: train_loss -0.9088
2025-02-26 04:52:13.867245: val_loss -0.7392
2025-02-26 04:52:13.867347: Pseudo dice [0.7903]
2025-02-26 04:52:13.867450: Epoch time: 63.93 s
2025-02-26 04:52:15.174351: 
2025-02-26 04:52:15.174577: Epoch 694
2025-02-26 04:52:15.174695: Current learning rate: 0.00344
2025-02-26 04:53:20.960644: train_loss -0.9115
2025-02-26 04:53:20.961050: val_loss -0.7383
2025-02-26 04:53:20.961151: Pseudo dice [0.7857]
2025-02-26 04:53:20.961263: Epoch time: 65.79 s
2025-02-26 04:53:22.301201: 
2025-02-26 04:53:22.301450: Epoch 695
2025-02-26 04:53:22.301573: Current learning rate: 0.00343
2025-02-26 04:54:27.157633: train_loss -0.9089
2025-02-26 04:54:27.158036: val_loss -0.7324
2025-02-26 04:54:27.158120: Pseudo dice [0.7823]
2025-02-26 04:54:27.158223: Epoch time: 64.86 s
2025-02-26 04:54:28.699257: 
2025-02-26 04:54:28.699523: Epoch 696
2025-02-26 04:54:28.699648: Current learning rate: 0.00342
2025-02-26 04:55:33.367459: train_loss -0.9048
2025-02-26 04:55:33.367931: val_loss -0.7138
2025-02-26 04:55:33.368024: Pseudo dice [0.7753]
2025-02-26 04:55:33.368146: Epoch time: 64.67 s
2025-02-26 04:55:34.730905: 
2025-02-26 04:55:34.731171: Epoch 697
2025-02-26 04:55:34.731292: Current learning rate: 0.00341
2025-02-26 04:56:40.182006: train_loss -0.9024
2025-02-26 04:56:40.182456: val_loss -0.7438
2025-02-26 04:56:40.182570: Pseudo dice [0.798]
2025-02-26 04:56:40.182698: Epoch time: 65.45 s
2025-02-26 04:56:41.521165: 
2025-02-26 04:56:41.521382: Epoch 698
2025-02-26 04:56:41.521502: Current learning rate: 0.0034
2025-02-26 04:57:47.980266: train_loss -0.9007
2025-02-26 04:57:47.980664: val_loss -0.7423
2025-02-26 04:57:47.980744: Pseudo dice [0.7935]
2025-02-26 04:57:47.980844: Epoch time: 66.46 s
2025-02-26 04:57:49.329436: 
2025-02-26 04:57:49.329653: Epoch 699
2025-02-26 04:57:49.329779: Current learning rate: 0.00339
2025-02-26 04:58:54.720782: train_loss -0.8971
2025-02-26 04:58:54.721191: val_loss -0.7409
2025-02-26 04:58:54.721271: Pseudo dice [0.7896]
2025-02-26 04:58:54.721391: Epoch time: 65.39 s
2025-02-26 04:58:56.621768: 
2025-02-26 04:58:56.621988: Epoch 700
2025-02-26 04:58:56.622114: Current learning rate: 0.00338
2025-02-26 05:00:01.206977: train_loss -0.9153
2025-02-26 05:00:01.207406: val_loss -0.7204
2025-02-26 05:00:01.207499: Pseudo dice [0.7896]
2025-02-26 05:00:01.207616: Epoch time: 64.59 s
2025-02-26 05:00:02.517332: 
2025-02-26 05:00:02.517549: Epoch 701
2025-02-26 05:00:02.517667: Current learning rate: 0.00337
2025-02-26 05:01:06.983151: train_loss -0.9084
2025-02-26 05:01:06.983534: val_loss -0.7321
2025-02-26 05:01:06.983617: Pseudo dice [0.7955]
2025-02-26 05:01:06.983704: Epoch time: 64.47 s
2025-02-26 05:01:08.715326: 
2025-02-26 05:01:08.715551: Epoch 702
2025-02-26 05:01:08.715675: Current learning rate: 0.00336
2025-02-26 05:02:13.440117: train_loss -0.9145
2025-02-26 05:02:13.440524: val_loss -0.7306
2025-02-26 05:02:13.440602: Pseudo dice [0.7898]
2025-02-26 05:02:13.440687: Epoch time: 64.73 s
2025-02-26 05:02:14.795876: 
2025-02-26 05:02:14.796121: Epoch 703
2025-02-26 05:02:14.796245: Current learning rate: 0.00335
2025-02-26 05:03:19.843788: train_loss -0.9136
2025-02-26 05:03:19.844169: val_loss -0.7281
2025-02-26 05:03:19.844256: Pseudo dice [0.7813]
2025-02-26 05:03:19.844376: Epoch time: 65.05 s
2025-02-26 05:03:21.214561: 
2025-02-26 05:03:21.214801: Epoch 704
2025-02-26 05:03:21.214928: Current learning rate: 0.00334
2025-02-26 05:04:25.791864: train_loss -0.9203
2025-02-26 05:04:25.792165: val_loss -0.7386
2025-02-26 05:04:25.792248: Pseudo dice [0.7894]
2025-02-26 05:04:25.792365: Epoch time: 64.58 s
2025-02-26 05:04:27.142651: 
2025-02-26 05:04:27.142878: Epoch 705
2025-02-26 05:04:27.143001: Current learning rate: 0.00333
2025-02-26 05:05:32.295668: train_loss -0.9002
2025-02-26 05:05:32.296060: val_loss -0.7241
2025-02-26 05:05:32.296146: Pseudo dice [0.7786]
2025-02-26 05:05:32.296259: Epoch time: 65.15 s
2025-02-26 05:05:33.635670: 
2025-02-26 05:05:33.635951: Epoch 706
2025-02-26 05:05:33.636071: Current learning rate: 0.00332
2025-02-26 05:06:38.187059: train_loss -0.9047
2025-02-26 05:06:38.187531: val_loss -0.745
2025-02-26 05:06:38.188130: Pseudo dice [0.8016]
2025-02-26 05:06:38.188243: Epoch time: 64.55 s
2025-02-26 05:06:39.535992: 
2025-02-26 05:06:39.536225: Epoch 707
2025-02-26 05:06:39.536357: Current learning rate: 0.00331
2025-02-26 05:07:44.906844: train_loss -0.9096
2025-02-26 05:07:44.907256: val_loss -0.7311
2025-02-26 05:07:44.907364: Pseudo dice [0.7921]
2025-02-26 05:07:44.907472: Epoch time: 65.37 s
2025-02-26 05:07:46.250517: 
2025-02-26 05:07:46.250728: Epoch 708
2025-02-26 05:07:46.250852: Current learning rate: 0.0033
2025-02-26 05:08:51.462260: train_loss -0.9115
2025-02-26 05:08:51.462639: val_loss -0.7265
2025-02-26 05:08:51.462732: Pseudo dice [0.7848]
2025-02-26 05:08:51.462838: Epoch time: 65.21 s
2025-02-26 05:08:52.841403: 
2025-02-26 05:08:52.841619: Epoch 709
2025-02-26 05:08:52.841739: Current learning rate: 0.00329
2025-02-26 05:09:57.258454: train_loss -0.9039
2025-02-26 05:09:57.258865: val_loss -0.7362
2025-02-26 05:09:57.258950: Pseudo dice [0.7898]
2025-02-26 05:09:57.259049: Epoch time: 64.42 s
2025-02-26 05:09:58.630572: 
2025-02-26 05:09:58.630794: Epoch 710
2025-02-26 05:09:58.630921: Current learning rate: 0.00328
2025-02-26 05:11:02.434996: train_loss -0.9207
2025-02-26 05:11:02.435419: val_loss -0.7453
2025-02-26 05:11:02.435504: Pseudo dice [0.7994]
2025-02-26 05:11:02.435602: Epoch time: 63.81 s
2025-02-26 05:11:03.776341: 
2025-02-26 05:11:03.776560: Epoch 711
2025-02-26 05:11:03.776681: Current learning rate: 0.00327
2025-02-26 05:12:08.832919: train_loss -0.9013
2025-02-26 05:12:08.833375: val_loss -0.7345
2025-02-26 05:12:08.833481: Pseudo dice [0.7948]
2025-02-26 05:12:08.833584: Epoch time: 65.06 s
2025-02-26 05:12:10.165476: 
2025-02-26 05:12:10.165684: Epoch 712
2025-02-26 05:12:10.165803: Current learning rate: 0.00326
2025-02-26 05:13:13.673382: train_loss -0.8996
2025-02-26 05:13:13.673824: val_loss -0.7371
2025-02-26 05:13:13.673915: Pseudo dice [0.7927]
2025-02-26 05:13:13.674024: Epoch time: 63.51 s
2025-02-26 05:13:15.030752: 
2025-02-26 05:13:15.030949: Epoch 713
2025-02-26 05:13:15.031068: Current learning rate: 0.00325
2025-02-26 05:14:18.626625: train_loss -0.9063
2025-02-26 05:14:18.627057: val_loss -0.7162
2025-02-26 05:14:18.627146: Pseudo dice [0.7686]
2025-02-26 05:14:18.627254: Epoch time: 63.6 s
2025-02-26 05:14:20.456818: 
2025-02-26 05:14:20.457056: Epoch 714
2025-02-26 05:14:20.457185: Current learning rate: 0.00324
2025-02-26 05:15:26.576476: train_loss -0.9045
2025-02-26 05:15:26.576995: val_loss -0.7304
2025-02-26 05:15:26.577075: Pseudo dice [0.7897]
2025-02-26 05:15:26.577163: Epoch time: 66.12 s
2025-02-26 05:15:27.958712: 
2025-02-26 05:15:27.958981: Epoch 715
2025-02-26 05:15:27.959108: Current learning rate: 0.00323
2025-02-26 05:16:32.844613: train_loss -0.9162
2025-02-26 05:16:32.844959: val_loss -0.7328
2025-02-26 05:16:32.845031: Pseudo dice [0.7872]
2025-02-26 05:16:32.845110: Epoch time: 64.89 s
2025-02-26 05:16:34.225611: 
2025-02-26 05:16:34.225829: Epoch 716
2025-02-26 05:16:34.225949: Current learning rate: 0.00322
2025-02-26 05:17:38.428975: train_loss -0.899
2025-02-26 05:17:38.429440: val_loss -0.7028
2025-02-26 05:17:38.429532: Pseudo dice [0.7707]
2025-02-26 05:17:38.429653: Epoch time: 64.2 s
2025-02-26 05:17:39.805273: 
2025-02-26 05:17:39.805499: Epoch 717
2025-02-26 05:17:39.805621: Current learning rate: 0.00321
2025-02-26 05:18:43.972941: train_loss -0.8849
2025-02-26 05:18:43.973357: val_loss -0.7254
2025-02-26 05:18:43.973449: Pseudo dice [0.7803]
2025-02-26 05:18:43.973554: Epoch time: 64.17 s
2025-02-26 05:18:45.296542: 
2025-02-26 05:18:45.296768: Epoch 718
2025-02-26 05:18:45.296891: Current learning rate: 0.0032
2025-02-26 05:19:49.769426: train_loss -0.8749
2025-02-26 05:19:49.769828: val_loss -0.7011
2025-02-26 05:19:49.769912: Pseudo dice [0.7627]
2025-02-26 05:19:49.770019: Epoch time: 64.47 s
2025-02-26 05:19:51.137841: 
2025-02-26 05:19:51.138049: Epoch 719
2025-02-26 05:19:51.138170: Current learning rate: 0.00319
2025-02-26 05:20:56.215406: train_loss -0.8823
2025-02-26 05:20:56.215788: val_loss -0.718
2025-02-26 05:20:56.215866: Pseudo dice [0.7816]
2025-02-26 05:20:56.215958: Epoch time: 65.08 s
2025-02-26 05:20:57.571555: 
2025-02-26 05:20:57.571796: Epoch 720
2025-02-26 05:20:57.571920: Current learning rate: 0.00318
2025-02-26 05:21:59.496840: train_loss -0.8702
2025-02-26 05:21:59.497233: val_loss -0.7127
2025-02-26 05:21:59.497339: Pseudo dice [0.7652]
2025-02-26 05:21:59.497455: Epoch time: 61.93 s
2025-02-26 05:22:00.903734: 
2025-02-26 05:22:00.903941: Epoch 721
2025-02-26 05:22:00.904063: Current learning rate: 0.00317
2025-02-26 05:23:05.335121: train_loss -0.8931
2025-02-26 05:23:05.335501: val_loss -0.7213
2025-02-26 05:23:05.335584: Pseudo dice [0.7873]
2025-02-26 05:23:05.335684: Epoch time: 64.43 s
2025-02-26 05:23:06.643732: 
2025-02-26 05:23:06.643948: Epoch 722
2025-02-26 05:23:06.644069: Current learning rate: 0.00316
2025-02-26 05:24:09.419591: train_loss -0.9017
2025-02-26 05:24:09.419876: val_loss -0.7273
2025-02-26 05:24:09.419956: Pseudo dice [0.7854]
2025-02-26 05:24:09.420048: Epoch time: 62.78 s
2025-02-26 05:24:10.738235: 
2025-02-26 05:24:10.738445: Epoch 723
2025-02-26 05:24:10.738567: Current learning rate: 0.00315
2025-02-26 05:25:16.437564: train_loss -0.9059
2025-02-26 05:25:16.438027: val_loss -0.7381
2025-02-26 05:25:16.438129: Pseudo dice [0.7919]
2025-02-26 05:25:16.438247: Epoch time: 65.7 s
2025-02-26 05:25:17.763493: 
2025-02-26 05:25:17.763704: Epoch 724
2025-02-26 05:25:17.763825: Current learning rate: 0.00314
2025-02-26 05:26:22.961673: train_loss -0.9089
2025-02-26 05:26:22.962084: val_loss -0.7321
2025-02-26 05:26:22.962173: Pseudo dice [0.7888]
2025-02-26 05:26:22.962285: Epoch time: 65.2 s
2025-02-26 05:26:24.284267: 
2025-02-26 05:26:24.284478: Epoch 725
2025-02-26 05:26:24.284600: Current learning rate: 0.00313
2025-02-26 05:27:27.320171: train_loss -0.9054
2025-02-26 05:27:27.320585: val_loss -0.7308
2025-02-26 05:27:27.320677: Pseudo dice [0.7916]
2025-02-26 05:27:27.320781: Epoch time: 63.04 s
2025-02-26 05:27:29.092269: 
2025-02-26 05:27:29.092526: Epoch 726
2025-02-26 05:27:29.092650: Current learning rate: 0.00312
2025-02-26 05:28:33.987946: train_loss -0.9135
2025-02-26 05:28:33.988342: val_loss -0.7209
2025-02-26 05:28:33.988427: Pseudo dice [0.7786]
2025-02-26 05:28:33.988523: Epoch time: 64.9 s
2025-02-26 05:28:35.348082: 
2025-02-26 05:28:35.348354: Epoch 727
2025-02-26 05:28:35.348487: Current learning rate: 0.00311
2025-02-26 05:29:41.562481: train_loss -0.9063
2025-02-26 05:29:41.562847: val_loss -0.7462
2025-02-26 05:29:41.562927: Pseudo dice [0.7999]
2025-02-26 05:29:41.563035: Epoch time: 66.22 s
2025-02-26 05:29:43.185024: 
2025-02-26 05:29:43.185283: Epoch 728
2025-02-26 05:29:43.185416: Current learning rate: 0.0031
2025-02-26 05:30:46.426829: train_loss -0.9074
2025-02-26 05:30:46.427211: val_loss -0.725
2025-02-26 05:30:46.427314: Pseudo dice [0.7778]
2025-02-26 05:30:46.427425: Epoch time: 63.24 s
2025-02-26 05:30:47.762106: 
2025-02-26 05:30:47.762312: Epoch 729
2025-02-26 05:30:47.762434: Current learning rate: 0.00309
2025-02-26 05:31:51.431353: train_loss -0.9184
2025-02-26 05:31:51.431780: val_loss -0.7348
2025-02-26 05:31:51.431879: Pseudo dice [0.7887]
2025-02-26 05:31:51.431988: Epoch time: 63.67 s
2025-02-26 05:31:52.747909: 
2025-02-26 05:31:52.748137: Epoch 730
2025-02-26 05:31:52.748264: Current learning rate: 0.00308
2025-02-26 05:32:57.467249: train_loss -0.9103
2025-02-26 05:32:57.467648: val_loss -0.7284
2025-02-26 05:32:57.467800: Pseudo dice [0.7841]
2025-02-26 05:32:57.467908: Epoch time: 64.72 s
2025-02-26 05:32:58.788846: 
2025-02-26 05:32:58.789052: Epoch 731
2025-02-26 05:32:58.789174: Current learning rate: 0.00307
2025-02-26 05:34:04.583437: train_loss -0.9119
2025-02-26 05:34:04.583843: val_loss -0.7268
2025-02-26 05:34:04.583922: Pseudo dice [0.7781]
2025-02-26 05:34:04.584018: Epoch time: 65.8 s
2025-02-26 05:34:05.985262: 
2025-02-26 05:34:05.985493: Epoch 732
2025-02-26 05:34:05.985618: Current learning rate: 0.00306
2025-02-26 05:35:10.684546: train_loss -0.9089
2025-02-26 05:35:10.684949: val_loss -0.7159
2025-02-26 05:35:10.685642: Pseudo dice [0.782]
2025-02-26 05:35:10.685763: Epoch time: 64.7 s
2025-02-26 05:35:11.984548: 
2025-02-26 05:35:11.984762: Epoch 733
2025-02-26 05:35:11.984880: Current learning rate: 0.00305
2025-02-26 05:36:16.254002: train_loss -0.9043
2025-02-26 05:36:16.254456: val_loss -0.7316
2025-02-26 05:36:16.254560: Pseudo dice [0.7937]
2025-02-26 05:36:16.254667: Epoch time: 64.27 s
2025-02-26 05:36:17.620518: 
2025-02-26 05:36:17.620720: Epoch 734
2025-02-26 05:36:17.620840: Current learning rate: 0.00304
2025-02-26 05:37:22.749774: train_loss -0.9077
2025-02-26 05:37:22.750252: val_loss -0.7305
2025-02-26 05:37:22.750376: Pseudo dice [0.7882]
2025-02-26 05:37:22.750484: Epoch time: 65.13 s
2025-02-26 05:37:24.077981: 
2025-02-26 05:37:24.078179: Epoch 735
2025-02-26 05:37:24.078311: Current learning rate: 0.00303
2025-02-26 05:38:29.780934: train_loss -0.9078
2025-02-26 05:38:29.781311: val_loss -0.7272
2025-02-26 05:38:29.781396: Pseudo dice [0.7879]
2025-02-26 05:38:29.781488: Epoch time: 65.7 s
2025-02-26 05:38:31.069382: 
2025-02-26 05:38:31.069577: Epoch 736
2025-02-26 05:38:31.069700: Current learning rate: 0.00302
2025-02-26 05:39:36.222771: train_loss -0.9088
2025-02-26 05:39:36.223063: val_loss -0.7305
2025-02-26 05:39:36.223142: Pseudo dice [0.7866]
2025-02-26 05:39:36.223233: Epoch time: 65.16 s
2025-02-26 05:39:37.973161: 
2025-02-26 05:39:37.973396: Epoch 737
2025-02-26 05:39:37.973522: Current learning rate: 0.00301
2025-02-26 05:40:41.269394: train_loss -0.9111
2025-02-26 05:40:41.269756: val_loss -0.7399
2025-02-26 05:40:41.269848: Pseudo dice [0.7908]
2025-02-26 05:40:41.269952: Epoch time: 63.3 s
2025-02-26 05:40:42.581882: 
2025-02-26 05:40:42.582096: Epoch 738
2025-02-26 05:40:42.582215: Current learning rate: 0.003
2025-02-26 05:41:47.298263: train_loss -0.9105
2025-02-26 05:41:47.298731: val_loss -0.6927
2025-02-26 05:41:47.298813: Pseudo dice [0.7607]
2025-02-26 05:41:47.298901: Epoch time: 64.72 s
2025-02-26 05:41:48.601853: 
2025-02-26 05:41:48.602072: Epoch 739
2025-02-26 05:41:48.602189: Current learning rate: 0.00299
2025-02-26 05:42:53.765607: train_loss -0.9101
2025-02-26 05:42:53.766008: val_loss -0.7124
2025-02-26 05:42:53.766093: Pseudo dice [0.778]
2025-02-26 05:42:53.766206: Epoch time: 65.17 s
2025-02-26 05:42:55.107671: 
2025-02-26 05:42:55.107932: Epoch 740
2025-02-26 05:42:55.108077: Current learning rate: 0.00297
2025-02-26 05:44:00.331703: train_loss -0.92
2025-02-26 05:44:00.332135: val_loss -0.7305
2025-02-26 05:44:00.332228: Pseudo dice [0.7836]
2025-02-26 05:44:00.332340: Epoch time: 65.23 s
2025-02-26 05:44:01.670437: 
2025-02-26 05:44:01.670663: Epoch 741
2025-02-26 05:44:01.670785: Current learning rate: 0.00296
2025-02-26 05:45:07.098252: train_loss -0.9165
2025-02-26 05:45:07.098668: val_loss -0.7258
2025-02-26 05:45:07.098768: Pseudo dice [0.7786]
2025-02-26 05:45:07.098871: Epoch time: 65.43 s
2025-02-26 05:45:08.437340: 
2025-02-26 05:45:08.437571: Epoch 742
2025-02-26 05:45:08.437691: Current learning rate: 0.00295
2025-02-26 05:46:12.801606: train_loss -0.9173
2025-02-26 05:46:12.802027: val_loss -0.7279
2025-02-26 05:46:12.802109: Pseudo dice [0.7834]
2025-02-26 05:46:12.802201: Epoch time: 64.37 s
2025-02-26 05:46:14.152445: 
2025-02-26 05:46:14.152720: Epoch 743
2025-02-26 05:46:14.152842: Current learning rate: 0.00294
2025-02-26 05:47:19.552483: train_loss -0.9205
2025-02-26 05:47:19.553165: val_loss -0.72
2025-02-26 05:47:19.553248: Pseudo dice [0.7853]
2025-02-26 05:47:19.553348: Epoch time: 65.4 s
2025-02-26 05:47:20.980101: 
2025-02-26 05:47:20.980377: Epoch 744
2025-02-26 05:47:20.980502: Current learning rate: 0.00293
2025-02-26 05:48:26.842469: train_loss -0.9204
2025-02-26 05:48:26.842843: val_loss -0.7252
2025-02-26 05:48:26.842929: Pseudo dice [0.7869]
2025-02-26 05:48:26.843033: Epoch time: 65.86 s
2025-02-26 05:48:28.168643: 
2025-02-26 05:48:28.168845: Epoch 745
2025-02-26 05:48:28.168961: Current learning rate: 0.00292
2025-02-26 05:49:32.960847: train_loss -0.9182
2025-02-26 05:49:32.961244: val_loss -0.7366
2025-02-26 05:49:32.961354: Pseudo dice [0.8007]
2025-02-26 05:49:32.961468: Epoch time: 64.79 s
2025-02-26 05:49:34.284939: 
2025-02-26 05:49:34.285141: Epoch 746
2025-02-26 05:49:34.285267: Current learning rate: 0.00291
2025-02-26 05:50:41.528647: train_loss -0.9176
2025-02-26 05:50:41.529088: val_loss -0.7346
2025-02-26 05:50:41.529181: Pseudo dice [0.7946]
2025-02-26 05:50:41.529290: Epoch time: 67.25 s
2025-02-26 05:50:42.885937: 
2025-02-26 05:50:42.886135: Epoch 747
2025-02-26 05:50:42.886254: Current learning rate: 0.0029
2025-02-26 05:51:50.817082: train_loss -0.9245
2025-02-26 05:51:50.817509: val_loss -0.7236
2025-02-26 05:51:50.817597: Pseudo dice [0.786]
2025-02-26 05:51:50.817702: Epoch time: 67.93 s
2025-02-26 05:51:52.169905: 
2025-02-26 05:51:52.170099: Epoch 748
2025-02-26 05:51:52.170216: Current learning rate: 0.00289
2025-02-26 05:52:59.710829: train_loss -0.9254
2025-02-26 05:52:59.711172: val_loss -0.7268
2025-02-26 05:52:59.711258: Pseudo dice [0.7882]
2025-02-26 05:52:59.711376: Epoch time: 67.54 s
2025-02-26 05:53:01.469453: 
2025-02-26 05:53:01.469692: Epoch 749
2025-02-26 05:53:01.469814: Current learning rate: 0.00288
2025-02-26 05:54:06.514769: train_loss -0.9215
2025-02-26 05:54:06.515150: val_loss -0.7387
2025-02-26 05:54:06.515242: Pseudo dice [0.7934]
2025-02-26 05:54:06.515354: Epoch time: 65.05 s
2025-02-26 05:54:08.367081: 
2025-02-26 05:54:08.367310: Epoch 750
2025-02-26 05:54:08.367431: Current learning rate: 0.00287
2025-02-26 05:55:12.199182: train_loss -0.9223
2025-02-26 05:55:12.199661: val_loss -0.7133
2025-02-26 05:55:12.199754: Pseudo dice [0.7735]
2025-02-26 05:55:12.199862: Epoch time: 63.83 s
2025-02-26 05:55:13.525007: 
2025-02-26 05:55:13.525310: Epoch 751
2025-02-26 05:55:13.525447: Current learning rate: 0.00286
2025-02-26 05:56:16.844941: train_loss -0.9131
2025-02-26 05:56:16.845290: val_loss -0.7302
2025-02-26 05:56:16.845402: Pseudo dice [0.7852]
2025-02-26 05:56:16.845560: Epoch time: 63.32 s
2025-02-26 05:56:18.180357: 
2025-02-26 05:56:18.180595: Epoch 752
2025-02-26 05:56:18.180722: Current learning rate: 0.00285
2025-02-26 05:57:22.231512: train_loss -0.9236
2025-02-26 05:57:22.231988: val_loss -0.7287
2025-02-26 05:57:22.232313: Pseudo dice [0.789]
2025-02-26 05:57:22.232819: Epoch time: 64.05 s
2025-02-26 05:57:23.599237: 
2025-02-26 05:57:23.599458: Epoch 753
2025-02-26 05:57:23.599579: Current learning rate: 0.00284
2025-02-26 05:58:27.461276: train_loss -0.9291
2025-02-26 05:58:27.461650: val_loss -0.7396
2025-02-26 05:58:27.461738: Pseudo dice [0.7955]
2025-02-26 05:58:27.461836: Epoch time: 63.86 s
2025-02-26 05:58:28.801399: 
2025-02-26 05:58:28.801617: Epoch 754
2025-02-26 05:58:28.801739: Current learning rate: 0.00283
2025-02-26 05:59:35.267029: train_loss -0.9269
2025-02-26 05:59:35.267442: val_loss -0.7135
2025-02-26 05:59:35.267534: Pseudo dice [0.7744]
2025-02-26 05:59:35.267617: Epoch time: 66.47 s
2025-02-26 05:59:36.582236: 
2025-02-26 05:59:36.582478: Epoch 755
2025-02-26 05:59:36.582600: Current learning rate: 0.00282
2025-02-26 06:00:41.145562: train_loss -0.9246
2025-02-26 06:00:41.145885: val_loss -0.7253
2025-02-26 06:00:41.145983: Pseudo dice [0.7848]
2025-02-26 06:00:41.146089: Epoch time: 64.57 s
2025-02-26 06:00:42.557678: 
2025-02-26 06:00:42.557879: Epoch 756
2025-02-26 06:00:42.558015: Current learning rate: 0.00281
2025-02-26 06:01:44.716048: train_loss -0.9186
2025-02-26 06:01:44.716411: val_loss -0.7358
2025-02-26 06:01:44.716500: Pseudo dice [0.7864]
2025-02-26 06:01:44.716602: Epoch time: 62.16 s
2025-02-26 06:01:46.091447: 
2025-02-26 06:01:46.091680: Epoch 757
2025-02-26 06:01:46.091809: Current learning rate: 0.0028
2025-02-26 06:02:50.227147: train_loss -0.92
2025-02-26 06:02:50.227587: val_loss -0.6999
2025-02-26 06:02:50.227676: Pseudo dice [0.7712]
2025-02-26 06:02:50.227783: Epoch time: 64.14 s
2025-02-26 06:02:51.605790: 
2025-02-26 06:02:51.605989: Epoch 758
2025-02-26 06:02:51.606110: Current learning rate: 0.00279
2025-02-26 06:03:59.050553: train_loss -0.912
2025-02-26 06:03:59.051026: val_loss -0.7215
2025-02-26 06:03:59.051649: Pseudo dice [0.7863]
2025-02-26 06:03:59.051771: Epoch time: 67.45 s
2025-02-26 06:04:00.387591: 
2025-02-26 06:04:00.387816: Epoch 759
2025-02-26 06:04:00.387935: Current learning rate: 0.00278
2025-02-26 06:05:05.095881: train_loss -0.9234
2025-02-26 06:05:05.096372: val_loss -0.7439
2025-02-26 06:05:05.096467: Pseudo dice [0.8]
2025-02-26 06:05:05.096580: Epoch time: 64.71 s
2025-02-26 06:05:06.825162: 
2025-02-26 06:05:06.825402: Epoch 760
2025-02-26 06:05:06.825536: Current learning rate: 0.00277
2025-02-26 06:06:12.720968: train_loss -0.9186
2025-02-26 06:06:12.721371: val_loss -0.7283
2025-02-26 06:06:12.721457: Pseudo dice [0.7814]
2025-02-26 06:06:12.721553: Epoch time: 65.9 s
2025-02-26 06:06:14.038933: 
2025-02-26 06:06:14.039163: Epoch 761
2025-02-26 06:06:14.039290: Current learning rate: 0.00276
2025-02-26 06:07:18.214425: train_loss -0.9203
2025-02-26 06:07:18.214822: val_loss -0.7269
2025-02-26 06:07:18.214902: Pseudo dice [0.778]
2025-02-26 06:07:18.215009: Epoch time: 64.18 s
2025-02-26 06:07:19.561568: 
2025-02-26 06:07:19.561793: Epoch 762
2025-02-26 06:07:19.561910: Current learning rate: 0.00275
2025-02-26 06:08:22.843284: train_loss -0.9126
2025-02-26 06:08:22.843722: val_loss -0.7153
2025-02-26 06:08:22.843809: Pseudo dice [0.7717]
2025-02-26 06:08:22.843911: Epoch time: 63.28 s
2025-02-26 06:08:24.212000: 
2025-02-26 06:08:24.212215: Epoch 763
2025-02-26 06:08:24.212344: Current learning rate: 0.00274
2025-02-26 06:09:29.379820: train_loss -0.9275
2025-02-26 06:09:29.380284: val_loss -0.7218
2025-02-26 06:09:29.380402: Pseudo dice [0.7838]
2025-02-26 06:09:29.380509: Epoch time: 65.17 s
2025-02-26 06:09:30.796612: 
2025-02-26 06:09:30.796836: Epoch 764
2025-02-26 06:09:30.796955: Current learning rate: 0.00273
2025-02-26 06:10:32.762931: train_loss -0.9295
2025-02-26 06:10:32.763322: val_loss -0.7379
2025-02-26 06:10:32.763413: Pseudo dice [0.7943]
2025-02-26 06:10:32.763512: Epoch time: 61.97 s
2025-02-26 06:10:34.116264: 
2025-02-26 06:10:34.116479: Epoch 765
2025-02-26 06:10:34.116602: Current learning rate: 0.00272
2025-02-26 06:11:40.284392: train_loss -0.9204
2025-02-26 06:11:40.284798: val_loss -0.7249
2025-02-26 06:11:40.284879: Pseudo dice [0.7808]
2025-02-26 06:11:40.284974: Epoch time: 66.17 s
2025-02-26 06:11:41.601806: 
2025-02-26 06:11:41.602003: Epoch 766
2025-02-26 06:11:41.602123: Current learning rate: 0.00271
2025-02-26 06:12:47.324593: train_loss -0.923
2025-02-26 06:12:47.325004: val_loss -0.7402
2025-02-26 06:12:47.325091: Pseudo dice [0.7919]
2025-02-26 06:12:47.325192: Epoch time: 65.72 s
2025-02-26 06:12:48.637142: 
2025-02-26 06:12:48.637366: Epoch 767
2025-02-26 06:12:48.637498: Current learning rate: 0.0027
2025-02-26 06:13:50.952067: train_loss -0.9163
2025-02-26 06:13:50.952448: val_loss -0.7228
2025-02-26 06:13:50.952528: Pseudo dice [0.7787]
2025-02-26 06:13:50.952637: Epoch time: 62.32 s
2025-02-26 06:13:52.383720: 
2025-02-26 06:13:52.383915: Epoch 768
2025-02-26 06:13:52.384035: Current learning rate: 0.00268
2025-02-26 06:14:57.628320: train_loss -0.9233
2025-02-26 06:14:57.628734: val_loss -0.7334
2025-02-26 06:14:57.628815: Pseudo dice [0.7964]
2025-02-26 06:14:57.628912: Epoch time: 65.25 s
2025-02-26 06:14:58.937120: 
2025-02-26 06:14:58.937332: Epoch 769
2025-02-26 06:14:58.937456: Current learning rate: 0.00267
2025-02-26 06:16:04.235157: train_loss -0.9182
2025-02-26 06:16:04.235543: val_loss -0.7259
2025-02-26 06:16:04.235632: Pseudo dice [0.7853]
2025-02-26 06:16:04.235744: Epoch time: 65.3 s
2025-02-26 06:16:05.582878: 
2025-02-26 06:16:05.583150: Epoch 770
2025-02-26 06:16:05.583343: Current learning rate: 0.00266
2025-02-26 06:17:08.035858: train_loss -0.9059
2025-02-26 06:17:08.036240: val_loss -0.7137
2025-02-26 06:17:08.036333: Pseudo dice [0.7731]
2025-02-26 06:17:08.036437: Epoch time: 62.45 s
2025-02-26 06:17:09.860626: 
2025-02-26 06:17:09.860916: Epoch 771
2025-02-26 06:17:09.861099: Current learning rate: 0.00265
2025-02-26 06:18:14.594263: train_loss -0.9013
2025-02-26 06:18:14.594680: val_loss -0.7191
2025-02-26 06:18:14.594768: Pseudo dice [0.7771]
2025-02-26 06:18:14.594871: Epoch time: 64.74 s
2025-02-26 06:18:15.978633: 
2025-02-26 06:18:15.978841: Epoch 772
2025-02-26 06:18:15.978964: Current learning rate: 0.00264
2025-02-26 06:19:20.601585: train_loss -0.9113
2025-02-26 06:19:20.601965: val_loss -0.7322
2025-02-26 06:19:20.602046: Pseudo dice [0.7939]
2025-02-26 06:19:20.602143: Epoch time: 64.62 s
2025-02-26 06:19:21.961203: 
2025-02-26 06:19:21.961436: Epoch 773
2025-02-26 06:19:21.961557: Current learning rate: 0.00263
2025-02-26 06:20:26.805764: train_loss -0.9074
2025-02-26 06:20:26.806195: val_loss -0.7291
2025-02-26 06:20:26.806293: Pseudo dice [0.787]
2025-02-26 06:20:26.806421: Epoch time: 64.85 s
2025-02-26 06:20:28.130186: 
2025-02-26 06:20:28.130402: Epoch 774
2025-02-26 06:20:28.130520: Current learning rate: 0.00262
2025-02-26 06:21:32.233950: train_loss -0.9213
2025-02-26 06:21:32.234357: val_loss -0.7374
2025-02-26 06:21:32.234448: Pseudo dice [0.7975]
2025-02-26 06:21:32.234550: Epoch time: 64.11 s
2025-02-26 06:21:33.620426: 
2025-02-26 06:21:33.620651: Epoch 775
2025-02-26 06:21:33.620773: Current learning rate: 0.00261
2025-02-26 06:22:38.460162: train_loss -0.9089
2025-02-26 06:22:38.460607: val_loss -0.7107
2025-02-26 06:22:38.460698: Pseudo dice [0.7708]
2025-02-26 06:22:38.460799: Epoch time: 64.84 s
2025-02-26 06:22:39.784510: 
2025-02-26 06:22:39.784705: Epoch 776
2025-02-26 06:22:39.784822: Current learning rate: 0.0026
2025-02-26 06:23:43.125820: train_loss -0.9149
2025-02-26 06:23:43.126225: val_loss -0.7046
2025-02-26 06:23:43.126338: Pseudo dice [0.7866]
2025-02-26 06:23:43.126438: Epoch time: 63.34 s
2025-02-26 06:23:44.454642: 
2025-02-26 06:23:44.454865: Epoch 777
2025-02-26 06:23:44.454986: Current learning rate: 0.00259
2025-02-26 06:24:49.617184: train_loss -0.9022
2025-02-26 06:24:49.617665: val_loss -0.7218
2025-02-26 06:24:49.617751: Pseudo dice [0.7809]
2025-02-26 06:24:49.617846: Epoch time: 65.16 s
2025-02-26 06:24:50.987607: 
2025-02-26 06:24:50.987826: Epoch 778
2025-02-26 06:24:50.987942: Current learning rate: 0.00258
2025-02-26 06:25:56.173087: train_loss -0.9127
2025-02-26 06:25:56.173658: val_loss -0.7337
2025-02-26 06:25:56.173744: Pseudo dice [0.7976]
2025-02-26 06:25:56.173844: Epoch time: 65.19 s
2025-02-26 06:25:57.579463: 
2025-02-26 06:25:57.579687: Epoch 779
2025-02-26 06:25:57.579812: Current learning rate: 0.00257
2025-02-26 06:27:02.684782: train_loss -0.8988
2025-02-26 06:27:02.685191: val_loss -0.736
2025-02-26 06:27:02.685282: Pseudo dice [0.7922]
2025-02-26 06:27:02.685407: Epoch time: 65.11 s
2025-02-26 06:27:04.069422: 
2025-02-26 06:27:04.069623: Epoch 780
2025-02-26 06:27:04.069750: Current learning rate: 0.00256
2025-02-26 06:28:10.131514: train_loss -0.9101
2025-02-26 06:28:10.131954: val_loss -0.7158
2025-02-26 06:28:10.132042: Pseudo dice [0.779]
2025-02-26 06:28:10.132146: Epoch time: 66.06 s
2025-02-26 06:28:11.513716: 
2025-02-26 06:28:11.513914: Epoch 781
2025-02-26 06:28:11.514031: Current learning rate: 0.00255
2025-02-26 06:29:16.225310: train_loss -0.9222
2025-02-26 06:29:16.225853: val_loss -0.7288
2025-02-26 06:29:16.225950: Pseudo dice [0.785]
2025-02-26 06:29:16.226047: Epoch time: 64.71 s
2025-02-26 06:29:18.001023: 
2025-02-26 06:29:18.001252: Epoch 782
2025-02-26 06:29:18.001395: Current learning rate: 0.00254
2025-02-26 06:30:21.690613: train_loss -0.9123
2025-02-26 06:30:21.690949: val_loss -0.7247
2025-02-26 06:30:21.691030: Pseudo dice [0.7783]
2025-02-26 06:30:21.691124: Epoch time: 63.69 s
2025-02-26 06:30:23.114594: 
2025-02-26 06:30:23.114825: Epoch 783
2025-02-26 06:30:23.114940: Current learning rate: 0.00253
2025-02-26 06:31:27.093805: train_loss -0.9057
2025-02-26 06:31:27.094208: val_loss -0.7134
2025-02-26 06:31:27.094290: Pseudo dice [0.7676]
2025-02-26 06:31:27.094415: Epoch time: 63.98 s
2025-02-26 06:31:28.425447: 
2025-02-26 06:31:28.425657: Epoch 784
2025-02-26 06:31:28.425774: Current learning rate: 0.00252
2025-02-26 06:32:31.798447: train_loss -0.9185
2025-02-26 06:32:31.798829: val_loss -0.7291
2025-02-26 06:32:31.799363: Pseudo dice [0.7846]
2025-02-26 06:32:31.799484: Epoch time: 63.37 s
2025-02-26 06:32:33.125676: 
2025-02-26 06:32:33.125911: Epoch 785
2025-02-26 06:32:33.126040: Current learning rate: 0.00251
2025-02-26 06:33:37.458638: train_loss -0.9215
2025-02-26 06:33:37.459040: val_loss -0.7242
2025-02-26 06:33:37.459133: Pseudo dice [0.7752]
2025-02-26 06:33:37.459241: Epoch time: 64.33 s
2025-02-26 06:33:38.810756: 
2025-02-26 06:33:38.811014: Epoch 786
2025-02-26 06:33:38.811166: Current learning rate: 0.0025
2025-02-26 06:34:43.676636: train_loss -0.9238
2025-02-26 06:34:43.677104: val_loss -0.7476
2025-02-26 06:34:43.677207: Pseudo dice [0.7944]
2025-02-26 06:34:43.677335: Epoch time: 64.87 s
2025-02-26 06:34:44.989630: 
2025-02-26 06:34:44.989844: Epoch 787
2025-02-26 06:34:44.989966: Current learning rate: 0.00249
2025-02-26 06:35:48.447094: train_loss -0.9281
2025-02-26 06:35:48.447506: val_loss -0.7164
2025-02-26 06:35:48.447593: Pseudo dice [0.7798]
2025-02-26 06:35:48.447705: Epoch time: 63.46 s
2025-02-26 06:35:49.770515: 
2025-02-26 06:35:49.770780: Epoch 788
2025-02-26 06:35:49.770909: Current learning rate: 0.00248
2025-02-26 06:36:52.733113: train_loss -0.9208
2025-02-26 06:36:52.733484: val_loss -0.7287
2025-02-26 06:36:52.733554: Pseudo dice [0.7886]
2025-02-26 06:36:52.733636: Epoch time: 62.96 s
2025-02-26 06:36:54.303158: 
2025-02-26 06:36:54.303367: Epoch 789
2025-02-26 06:36:54.303488: Current learning rate: 0.00247
2025-02-26 06:37:58.270185: train_loss -0.9102
2025-02-26 06:37:58.270579: val_loss -0.7234
2025-02-26 06:37:58.270659: Pseudo dice [0.7873]
2025-02-26 06:37:58.270741: Epoch time: 63.97 s
2025-02-26 06:37:59.667313: 
2025-02-26 06:37:59.667530: Epoch 790
2025-02-26 06:37:59.667675: Current learning rate: 0.00245
2025-02-26 06:39:04.064528: train_loss -0.9206
2025-02-26 06:39:04.064888: val_loss -0.7322
2025-02-26 06:39:04.064973: Pseudo dice [0.7918]
2025-02-26 06:39:04.065077: Epoch time: 64.4 s
2025-02-26 06:39:05.379745: 
2025-02-26 06:39:05.379947: Epoch 791
2025-02-26 06:39:05.380062: Current learning rate: 0.00244
2025-02-26 06:40:09.762333: train_loss -0.911
2025-02-26 06:40:09.762699: val_loss -0.7305
2025-02-26 06:40:09.762780: Pseudo dice [0.7769]
2025-02-26 06:40:09.762875: Epoch time: 64.38 s
2025-02-26 06:40:11.073402: 
2025-02-26 06:40:11.073605: Epoch 792
2025-02-26 06:40:11.073726: Current learning rate: 0.00243
2025-02-26 06:41:16.998893: train_loss -0.9236
2025-02-26 06:41:16.999346: val_loss -0.7369
2025-02-26 06:41:16.999467: Pseudo dice [0.7894]
2025-02-26 06:41:16.999590: Epoch time: 65.93 s
2025-02-26 06:41:18.768873: 
2025-02-26 06:41:18.769109: Epoch 793
2025-02-26 06:41:18.769244: Current learning rate: 0.00242
2025-02-26 06:42:22.995029: train_loss -0.9151
2025-02-26 06:42:22.995422: val_loss -0.7214
2025-02-26 06:42:22.995543: Pseudo dice [0.7817]
2025-02-26 06:42:22.995663: Epoch time: 64.23 s
2025-02-26 06:42:24.329955: 
2025-02-26 06:42:24.330196: Epoch 794
2025-02-26 06:42:24.330327: Current learning rate: 0.00241
2025-02-26 06:43:27.957981: train_loss -0.9145
2025-02-26 06:43:27.958264: val_loss -0.7189
2025-02-26 06:43:27.958368: Pseudo dice [0.7816]
2025-02-26 06:43:27.958468: Epoch time: 63.63 s
2025-02-26 06:43:29.377718: 
2025-02-26 06:43:29.377971: Epoch 795
2025-02-26 06:43:29.378106: Current learning rate: 0.0024
2025-02-26 06:44:34.021017: train_loss -0.9212
2025-02-26 06:44:34.021415: val_loss -0.7147
2025-02-26 06:44:34.021499: Pseudo dice [0.773]
2025-02-26 06:44:34.021718: Epoch time: 64.64 s
2025-02-26 06:44:35.354068: 
2025-02-26 06:44:35.354283: Epoch 796
2025-02-26 06:44:35.354421: Current learning rate: 0.00239
2025-02-26 06:45:38.068095: train_loss -0.9232
2025-02-26 06:45:38.068496: val_loss -0.7356
2025-02-26 06:45:38.068570: Pseudo dice [0.797]
2025-02-26 06:45:38.068660: Epoch time: 62.72 s
2025-02-26 06:45:39.440803: 
2025-02-26 06:45:39.441036: Epoch 797
2025-02-26 06:45:39.441166: Current learning rate: 0.00238
2025-02-26 06:46:43.676218: train_loss -0.9266
2025-02-26 06:46:43.676674: val_loss -0.7336
2025-02-26 06:46:43.676762: Pseudo dice [0.7932]
2025-02-26 06:46:43.676865: Epoch time: 64.24 s
2025-02-26 06:46:45.039892: 
2025-02-26 06:46:45.040146: Epoch 798
2025-02-26 06:46:45.040276: Current learning rate: 0.00237
2025-02-26 06:47:49.327408: train_loss -0.9285
2025-02-26 06:47:49.327788: val_loss -0.747
2025-02-26 06:47:49.327876: Pseudo dice [0.8002]
2025-02-26 06:47:49.327977: Epoch time: 64.29 s
2025-02-26 06:47:50.707363: 
2025-02-26 06:47:50.707568: Epoch 799
2025-02-26 06:47:50.707687: Current learning rate: 0.00236
2025-02-26 06:48:53.519598: train_loss -0.9235
2025-02-26 06:48:53.520082: val_loss -0.7403
2025-02-26 06:48:53.520181: Pseudo dice [0.7885]
2025-02-26 06:48:53.520317: Epoch time: 62.81 s
2025-02-26 06:48:55.408551: 
2025-02-26 06:48:55.408762: Epoch 800
2025-02-26 06:48:55.408880: Current learning rate: 0.00235
2025-02-26 06:49:59.921996: train_loss -0.9204
2025-02-26 06:49:59.922375: val_loss -0.7189
2025-02-26 06:49:59.922469: Pseudo dice [0.7717]
2025-02-26 06:49:59.922574: Epoch time: 64.51 s
2025-02-26 06:50:01.316288: 
2025-02-26 06:50:01.316514: Epoch 801
2025-02-26 06:50:01.316637: Current learning rate: 0.00234
2025-02-26 06:51:03.709644: train_loss -0.9249
2025-02-26 06:51:03.710054: val_loss -0.7273
2025-02-26 06:51:03.710132: Pseudo dice [0.7859]
2025-02-26 06:51:03.710236: Epoch time: 62.39 s
2025-02-26 06:51:05.030907: 
2025-02-26 06:51:05.031155: Epoch 802
2025-02-26 06:51:05.031281: Current learning rate: 0.00233
2025-02-26 06:52:08.437204: train_loss -0.9263
2025-02-26 06:52:08.437653: val_loss -0.7371
2025-02-26 06:52:08.437904: Pseudo dice [0.7907]
2025-02-26 06:52:08.438510: Epoch time: 63.41 s
2025-02-26 06:52:09.799891: 
2025-02-26 06:52:09.800092: Epoch 803
2025-02-26 06:52:09.800210: Current learning rate: 0.00232
2025-02-26 06:53:15.964453: train_loss -0.927
2025-02-26 06:53:15.964787: val_loss -0.7308
2025-02-26 06:53:15.964864: Pseudo dice [0.7837]
2025-02-26 06:53:15.964960: Epoch time: 66.17 s
2025-02-26 06:53:17.689923: 
2025-02-26 06:53:17.690171: Epoch 804
2025-02-26 06:53:17.690291: Current learning rate: 0.00231
2025-02-26 06:54:19.966152: train_loss -0.9258
2025-02-26 06:54:19.966583: val_loss -0.7238
2025-02-26 06:54:19.966679: Pseudo dice [0.7897]
2025-02-26 06:54:19.966785: Epoch time: 62.28 s
2025-02-26 06:54:21.347666: 
2025-02-26 06:54:21.347878: Epoch 805
2025-02-26 06:54:21.347994: Current learning rate: 0.0023
2025-02-26 06:55:25.468164: train_loss -0.9205
2025-02-26 06:55:25.468910: val_loss -0.7375
2025-02-26 06:55:25.469020: Pseudo dice [0.7932]
2025-02-26 06:55:25.469118: Epoch time: 64.12 s
2025-02-26 06:55:26.851086: 
2025-02-26 06:55:26.851353: Epoch 806
2025-02-26 06:55:26.851482: Current learning rate: 0.00229
2025-02-26 06:56:31.455133: train_loss -0.9124
2025-02-26 06:56:31.455524: val_loss -0.7468
2025-02-26 06:56:31.455606: Pseudo dice [0.8004]
2025-02-26 06:56:31.455701: Epoch time: 64.61 s
2025-02-26 06:56:32.792927: 
2025-02-26 06:56:32.793163: Epoch 807
2025-02-26 06:56:32.793281: Current learning rate: 0.00228
2025-02-26 06:57:37.966407: train_loss -0.9178
2025-02-26 06:57:37.966823: val_loss -0.7224
2025-02-26 06:57:37.966906: Pseudo dice [0.7832]
2025-02-26 06:57:37.967007: Epoch time: 65.18 s
2025-02-26 06:57:39.370479: 
2025-02-26 06:57:39.370829: Epoch 808
2025-02-26 06:57:39.370954: Current learning rate: 0.00226
2025-02-26 06:58:46.283596: train_loss -0.9219
2025-02-26 06:58:46.283977: val_loss -0.737
2025-02-26 06:58:46.284083: Pseudo dice [0.7956]
2025-02-26 06:58:46.284206: Epoch time: 66.92 s
2025-02-26 06:58:47.609706: 
2025-02-26 06:58:47.609931: Epoch 809
2025-02-26 06:58:47.610055: Current learning rate: 0.00225
2025-02-26 06:59:53.952165: train_loss -0.9218
2025-02-26 06:59:53.952628: val_loss -0.7429
2025-02-26 06:59:53.952718: Pseudo dice [0.7966]
2025-02-26 06:59:53.952837: Epoch time: 66.34 s
2025-02-26 06:59:55.410877: 
2025-02-26 06:59:55.411094: Epoch 810
2025-02-26 06:59:55.411214: Current learning rate: 0.00224
2025-02-26 07:01:01.543051: train_loss -0.9154
2025-02-26 07:01:01.543444: val_loss -0.7257
2025-02-26 07:01:01.544228: Pseudo dice [0.782]
2025-02-26 07:01:01.544674: Epoch time: 66.13 s
2025-02-26 07:01:02.845711: 
2025-02-26 07:01:02.845914: Epoch 811
2025-02-26 07:01:02.846033: Current learning rate: 0.00223
2025-02-26 07:02:08.136290: train_loss -0.917
2025-02-26 07:02:08.136685: val_loss -0.7451
2025-02-26 07:02:08.136770: Pseudo dice [0.7997]
2025-02-26 07:02:08.136871: Epoch time: 65.29 s
2025-02-26 07:02:09.485125: 
2025-02-26 07:02:09.485344: Epoch 812
2025-02-26 07:02:09.485465: Current learning rate: 0.00222
2025-02-26 07:03:14.117804: train_loss -0.9259
2025-02-26 07:03:14.118234: val_loss -0.7507
2025-02-26 07:03:14.118391: Pseudo dice [0.8078]
2025-02-26 07:03:14.118509: Epoch time: 64.63 s
2025-02-26 07:03:15.499562: 
2025-02-26 07:03:15.499780: Epoch 813
2025-02-26 07:03:15.499901: Current learning rate: 0.00221
2025-02-26 07:04:20.842151: train_loss -0.9323
2025-02-26 07:04:20.842490: val_loss -0.7427
2025-02-26 07:04:20.842564: Pseudo dice [0.7985]
2025-02-26 07:04:20.842655: Epoch time: 65.34 s
2025-02-26 07:04:22.262076: 
2025-02-26 07:04:22.262279: Epoch 814
2025-02-26 07:04:22.262425: Current learning rate: 0.0022
2025-02-26 07:05:29.107430: train_loss -0.9266
2025-02-26 07:05:29.107805: val_loss -0.7431
2025-02-26 07:05:29.107879: Pseudo dice [0.7987]
2025-02-26 07:05:29.107966: Epoch time: 66.85 s
2025-02-26 07:05:30.832515: 
2025-02-26 07:05:30.832763: Epoch 815
2025-02-26 07:05:30.832917: Current learning rate: 0.00219
2025-02-26 07:06:34.250143: train_loss -0.9246
2025-02-26 07:06:34.250628: val_loss -0.7348
2025-02-26 07:06:34.250744: Pseudo dice [0.7911]
2025-02-26 07:06:34.250832: Epoch time: 63.42 s
2025-02-26 07:06:35.627789: 
2025-02-26 07:06:35.628003: Epoch 816
2025-02-26 07:06:35.628120: Current learning rate: 0.00218
2025-02-26 07:07:41.808006: train_loss -0.9283
2025-02-26 07:07:41.808481: val_loss -0.7414
2025-02-26 07:07:41.808573: Pseudo dice [0.7934]
2025-02-26 07:07:41.808672: Epoch time: 66.18 s
2025-02-26 07:07:43.171393: 
2025-02-26 07:07:43.171609: Epoch 817
2025-02-26 07:07:43.171727: Current learning rate: 0.00217
2025-02-26 07:08:48.491832: train_loss -0.93
2025-02-26 07:08:48.492242: val_loss -0.7239
2025-02-26 07:08:48.492356: Pseudo dice [0.7783]
2025-02-26 07:08:48.492466: Epoch time: 65.32 s
2025-02-26 07:08:49.863716: 
2025-02-26 07:08:49.863933: Epoch 818
2025-02-26 07:08:49.864060: Current learning rate: 0.00216
2025-02-26 07:09:54.540953: train_loss -0.9251
2025-02-26 07:09:54.541360: val_loss -0.7192
2025-02-26 07:09:54.541455: Pseudo dice [0.7776]
2025-02-26 07:09:54.541583: Epoch time: 64.68 s
2025-02-26 07:09:55.947993: 
2025-02-26 07:09:55.948219: Epoch 819
2025-02-26 07:09:55.948348: Current learning rate: 0.00215
2025-02-26 07:11:02.890921: train_loss -0.9217
2025-02-26 07:11:02.891673: val_loss -0.7308
2025-02-26 07:11:02.891764: Pseudo dice [0.7909]
2025-02-26 07:11:02.891873: Epoch time: 66.94 s
2025-02-26 07:11:04.217913: 
2025-02-26 07:11:04.218149: Epoch 820
2025-02-26 07:11:04.218269: Current learning rate: 0.00214
2025-02-26 07:12:09.876700: train_loss -0.9312
2025-02-26 07:12:09.877125: val_loss -0.7493
2025-02-26 07:12:09.877208: Pseudo dice [0.7989]
2025-02-26 07:12:09.877326: Epoch time: 65.66 s
2025-02-26 07:12:11.153754: 
2025-02-26 07:12:11.153970: Epoch 821
2025-02-26 07:12:11.154091: Current learning rate: 0.00213
2025-02-26 07:13:16.499070: train_loss -0.9288
2025-02-26 07:13:16.499459: val_loss -0.7315
2025-02-26 07:13:16.499543: Pseudo dice [0.7912]
2025-02-26 07:13:16.499644: Epoch time: 65.35 s
2025-02-26 07:13:17.873645: 
2025-02-26 07:13:17.873886: Epoch 822
2025-02-26 07:13:17.874008: Current learning rate: 0.00212
2025-02-26 07:14:21.482062: train_loss -0.9256
2025-02-26 07:14:21.482675: val_loss -0.745
2025-02-26 07:14:21.482799: Pseudo dice [0.7991]
2025-02-26 07:14:21.482920: Epoch time: 63.61 s
2025-02-26 07:14:22.838839: 
2025-02-26 07:14:22.839050: Epoch 823
2025-02-26 07:14:22.839173: Current learning rate: 0.0021
2025-02-26 07:15:29.001896: train_loss -0.926
2025-02-26 07:15:29.002292: val_loss -0.7289
2025-02-26 07:15:29.002399: Pseudo dice [0.7919]
2025-02-26 07:15:29.002508: Epoch time: 66.16 s
2025-02-26 07:15:30.391249: 
2025-02-26 07:15:30.391464: Epoch 824
2025-02-26 07:15:30.391589: Current learning rate: 0.00209
2025-02-26 07:16:35.652553: train_loss -0.9355
2025-02-26 07:16:35.652929: val_loss -0.7349
2025-02-26 07:16:35.653010: Pseudo dice [0.7938]
2025-02-26 07:16:35.653105: Epoch time: 65.26 s
2025-02-26 07:16:36.945105: 
2025-02-26 07:16:36.945320: Epoch 825
2025-02-26 07:16:36.945445: Current learning rate: 0.00208
2025-02-26 07:17:44.797239: train_loss -0.9293
2025-02-26 07:17:44.797675: val_loss -0.7361
2025-02-26 07:17:44.797761: Pseudo dice [0.7926]
2025-02-26 07:17:44.797869: Epoch time: 67.85 s
2025-02-26 07:17:46.127850: 
2025-02-26 07:17:46.128044: Epoch 826
2025-02-26 07:17:46.128165: Current learning rate: 0.00207
2025-02-26 07:18:52.132329: train_loss -0.9301
2025-02-26 07:18:52.132710: val_loss -0.7457
2025-02-26 07:18:52.132792: Pseudo dice [0.7995]
2025-02-26 07:18:52.132894: Epoch time: 66.01 s
2025-02-26 07:18:53.954068: 
2025-02-26 07:18:53.954287: Epoch 827
2025-02-26 07:18:53.954437: Current learning rate: 0.00206
2025-02-26 07:19:58.893079: train_loss -0.9268
2025-02-26 07:19:58.893456: val_loss -0.7298
2025-02-26 07:19:58.893530: Pseudo dice [0.7888]
2025-02-26 07:19:58.893616: Epoch time: 64.94 s
2025-02-26 07:20:00.217476: 
2025-02-26 07:20:00.217757: Epoch 828
2025-02-26 07:20:00.217884: Current learning rate: 0.00205
2025-02-26 07:21:04.013946: train_loss -0.9211
2025-02-26 07:21:04.014645: val_loss -0.7388
2025-02-26 07:21:04.014766: Pseudo dice [0.7962]
2025-02-26 07:21:04.014873: Epoch time: 63.8 s
2025-02-26 07:21:05.329863: 
2025-02-26 07:21:05.330137: Epoch 829
2025-02-26 07:21:05.330261: Current learning rate: 0.00204
2025-02-26 07:22:11.700948: train_loss -0.9313
2025-02-26 07:22:11.701359: val_loss -0.7442
2025-02-26 07:22:11.701449: Pseudo dice [0.7977]
2025-02-26 07:22:11.701556: Epoch time: 66.37 s
2025-02-26 07:22:13.062644: 
2025-02-26 07:22:13.062875: Epoch 830
2025-02-26 07:22:13.062999: Current learning rate: 0.00203
2025-02-26 07:23:19.823998: train_loss -0.9191
2025-02-26 07:23:19.824446: val_loss -0.724
2025-02-26 07:23:19.824543: Pseudo dice [0.7838]
2025-02-26 07:23:19.824669: Epoch time: 66.76 s
2025-02-26 07:23:21.101000: 
2025-02-26 07:23:21.101226: Epoch 831
2025-02-26 07:23:21.101357: Current learning rate: 0.00202
2025-02-26 07:24:25.460700: train_loss -0.9363
2025-02-26 07:24:25.461120: val_loss -0.7271
2025-02-26 07:24:25.461201: Pseudo dice [0.785]
2025-02-26 07:24:25.461310: Epoch time: 64.36 s
2025-02-26 07:24:26.801967: 
2025-02-26 07:24:26.802174: Epoch 832
2025-02-26 07:24:26.802305: Current learning rate: 0.00201
2025-02-26 07:25:33.661389: train_loss -0.9362
2025-02-26 07:25:33.661780: val_loss -0.7415
2025-02-26 07:25:33.661862: Pseudo dice [0.7981]
2025-02-26 07:25:33.661956: Epoch time: 66.86 s
2025-02-26 07:25:35.059427: 
2025-02-26 07:25:35.059644: Epoch 833
2025-02-26 07:25:35.059763: Current learning rate: 0.002
2025-02-26 07:26:38.314994: train_loss -0.9325
2025-02-26 07:26:38.315402: val_loss -0.7437
2025-02-26 07:26:38.315492: Pseudo dice [0.7947]
2025-02-26 07:26:38.315590: Epoch time: 63.26 s
2025-02-26 07:26:39.662540: 
2025-02-26 07:26:39.662748: Epoch 834
2025-02-26 07:26:39.662865: Current learning rate: 0.00199
2025-02-26 07:27:44.554021: train_loss -0.9331
2025-02-26 07:27:44.554504: val_loss -0.7232
2025-02-26 07:27:44.554604: Pseudo dice [0.7912]
2025-02-26 07:27:44.554723: Epoch time: 64.89 s
2025-02-26 07:27:45.873543: 
2025-02-26 07:27:45.873766: Epoch 835
2025-02-26 07:27:45.873888: Current learning rate: 0.00198
2025-02-26 07:28:49.501875: train_loss -0.9285
2025-02-26 07:28:49.502259: val_loss -0.7362
2025-02-26 07:28:49.502365: Pseudo dice [0.7926]
2025-02-26 07:28:49.502472: Epoch time: 63.63 s
2025-02-26 07:28:50.823983: 
2025-02-26 07:28:50.824202: Epoch 836
2025-02-26 07:28:50.824332: Current learning rate: 0.00196
2025-02-26 07:29:55.849261: train_loss -0.9283
2025-02-26 07:29:55.849651: val_loss -0.7098
2025-02-26 07:29:55.850076: Pseudo dice [0.7866]
2025-02-26 07:29:55.850164: Epoch time: 65.03 s
2025-02-26 07:29:57.174591: 
2025-02-26 07:29:57.174791: Epoch 837
2025-02-26 07:29:57.174912: Current learning rate: 0.00195
2025-02-26 07:31:03.500846: train_loss -0.9208
2025-02-26 07:31:03.501278: val_loss -0.7314
2025-02-26 07:31:03.501401: Pseudo dice [0.7944]
2025-02-26 07:31:03.501519: Epoch time: 66.33 s
2025-02-26 07:31:04.854106: 
2025-02-26 07:31:04.854320: Epoch 838
2025-02-26 07:31:04.854448: Current learning rate: 0.00194
2025-02-26 07:32:12.116277: train_loss -0.9253
2025-02-26 07:32:12.116817: val_loss -0.7388
2025-02-26 07:32:12.116941: Pseudo dice [0.7926]
2025-02-26 07:32:12.117064: Epoch time: 67.26 s
2025-02-26 07:32:13.901691: 
2025-02-26 07:32:13.901920: Epoch 839
2025-02-26 07:32:13.902056: Current learning rate: 0.00193
2025-02-26 07:33:20.609933: train_loss -0.9276
2025-02-26 07:33:20.610657: val_loss -0.7212
2025-02-26 07:33:20.610764: Pseudo dice [0.7811]
2025-02-26 07:33:20.610879: Epoch time: 66.71 s
2025-02-26 07:33:21.946062: 
2025-02-26 07:33:21.946392: Epoch 840
2025-02-26 07:33:21.946513: Current learning rate: 0.00192
2025-02-26 07:34:26.651850: train_loss -0.9365
2025-02-26 07:34:26.652194: val_loss -0.7271
2025-02-26 07:34:26.652290: Pseudo dice [0.7791]
2025-02-26 07:34:26.652420: Epoch time: 64.71 s
2025-02-26 07:34:28.029962: 
2025-02-26 07:34:28.030169: Epoch 841
2025-02-26 07:34:28.030307: Current learning rate: 0.00191
2025-02-26 07:35:34.954067: train_loss -0.9286
2025-02-26 07:35:34.954477: val_loss -0.7229
2025-02-26 07:35:34.954571: Pseudo dice [0.7909]
2025-02-26 07:35:34.954675: Epoch time: 66.93 s
2025-02-26 07:35:36.325483: 
2025-02-26 07:35:36.325713: Epoch 842
2025-02-26 07:35:36.325836: Current learning rate: 0.0019
2025-02-26 07:36:41.143665: train_loss -0.9309
2025-02-26 07:36:41.144119: val_loss -0.7321
2025-02-26 07:36:41.144200: Pseudo dice [0.7969]
2025-02-26 07:36:41.144286: Epoch time: 64.82 s
2025-02-26 07:36:42.482695: 
2025-02-26 07:36:42.482911: Epoch 843
2025-02-26 07:36:42.483041: Current learning rate: 0.00189
2025-02-26 07:37:48.192918: train_loss -0.9301
2025-02-26 07:37:48.193353: val_loss -0.7059
2025-02-26 07:37:48.193454: Pseudo dice [0.7715]
2025-02-26 07:37:48.193562: Epoch time: 65.71 s
2025-02-26 07:37:49.491879: 
2025-02-26 07:37:49.492081: Epoch 844
2025-02-26 07:37:49.492221: Current learning rate: 0.00188
2025-02-26 07:38:55.110013: train_loss -0.9239
2025-02-26 07:38:55.110440: val_loss -0.7113
2025-02-26 07:38:55.110523: Pseudo dice [0.78]
2025-02-26 07:38:55.110621: Epoch time: 65.62 s
2025-02-26 07:38:56.450308: 
2025-02-26 07:38:56.450520: Epoch 845
2025-02-26 07:38:56.450643: Current learning rate: 0.00187
2025-02-26 07:40:01.890910: train_loss -0.9224
2025-02-26 07:40:01.891257: val_loss -0.7418
2025-02-26 07:40:01.891346: Pseudo dice [0.8012]
2025-02-26 07:40:01.891433: Epoch time: 65.44 s
2025-02-26 07:40:03.216516: 
2025-02-26 07:40:03.216793: Epoch 846
2025-02-26 07:40:03.216912: Current learning rate: 0.00186
2025-02-26 07:41:09.202688: train_loss -0.9305
2025-02-26 07:41:09.203064: val_loss -0.7422
2025-02-26 07:41:09.203155: Pseudo dice [0.7961]
2025-02-26 07:41:09.203259: Epoch time: 65.99 s
2025-02-26 07:41:10.533291: 
2025-02-26 07:41:10.533503: Epoch 847
2025-02-26 07:41:10.533622: Current learning rate: 0.00185
2025-02-26 07:42:15.538512: train_loss -0.9303
2025-02-26 07:42:15.538913: val_loss -0.7399
2025-02-26 07:42:15.539086: Pseudo dice [0.7949]
2025-02-26 07:42:15.539272: Epoch time: 65.01 s
2025-02-26 07:42:16.872395: 
2025-02-26 07:42:16.872596: Epoch 848
2025-02-26 07:42:16.872722: Current learning rate: 0.00184
2025-02-26 07:43:22.725217: train_loss -0.9232
2025-02-26 07:43:22.725659: val_loss -0.723
2025-02-26 07:43:22.725774: Pseudo dice [0.7918]
2025-02-26 07:43:22.725968: Epoch time: 65.85 s
2025-02-26 07:43:24.041935: 
2025-02-26 07:43:24.042153: Epoch 849
2025-02-26 07:43:24.042279: Current learning rate: 0.00182
2025-02-26 07:44:29.880819: train_loss -0.9275
2025-02-26 07:44:29.881263: val_loss -0.7266
2025-02-26 07:44:29.881375: Pseudo dice [0.7877]
2025-02-26 07:44:29.881488: Epoch time: 65.84 s
2025-02-26 07:44:31.752601: 
2025-02-26 07:44:31.752804: Epoch 850
2025-02-26 07:44:31.752931: Current learning rate: 0.00181
2025-02-26 07:45:37.180720: train_loss -0.932
2025-02-26 07:45:37.181091: val_loss -0.7355
2025-02-26 07:45:37.181178: Pseudo dice [0.792]
2025-02-26 07:45:37.181283: Epoch time: 65.43 s
2025-02-26 07:45:38.947834: 
2025-02-26 07:45:38.948065: Epoch 851
2025-02-26 07:45:38.948186: Current learning rate: 0.0018
2025-02-26 07:46:44.696814: train_loss -0.9325
2025-02-26 07:46:44.697214: val_loss -0.7194
2025-02-26 07:46:44.697317: Pseudo dice [0.777]
2025-02-26 07:46:44.697420: Epoch time: 65.75 s
2025-02-26 07:46:45.958934: 
2025-02-26 07:46:45.959140: Epoch 852
2025-02-26 07:46:45.959255: Current learning rate: 0.00179
2025-02-26 07:47:50.161824: train_loss -0.9362
2025-02-26 07:47:50.162214: val_loss -0.7341
2025-02-26 07:47:50.162324: Pseudo dice [0.7956]
2025-02-26 07:47:50.162445: Epoch time: 64.2 s
2025-02-26 07:47:51.470767: 
2025-02-26 07:47:51.470980: Epoch 853
2025-02-26 07:47:51.471098: Current learning rate: 0.00178
2025-02-26 07:48:58.302276: train_loss -0.9341
2025-02-26 07:48:58.302586: val_loss -0.716
2025-02-26 07:48:58.302672: Pseudo dice [0.786]
2025-02-26 07:48:58.302773: Epoch time: 66.83 s
2025-02-26 07:48:59.647205: 
2025-02-26 07:48:59.647429: Epoch 854
2025-02-26 07:48:59.647562: Current learning rate: 0.00177
2025-02-26 07:50:03.069330: train_loss -0.9329
2025-02-26 07:50:03.069832: val_loss -0.7388
2025-02-26 07:50:03.069932: Pseudo dice [0.7976]
2025-02-26 07:50:03.070053: Epoch time: 63.42 s
2025-02-26 07:50:04.407433: 
2025-02-26 07:50:04.407649: Epoch 855
2025-02-26 07:50:04.407771: Current learning rate: 0.00176
2025-02-26 07:51:09.760588: train_loss -0.9301
2025-02-26 07:51:09.760949: val_loss -0.7281
2025-02-26 07:51:09.761021: Pseudo dice [0.7877]
2025-02-26 07:51:09.761104: Epoch time: 65.35 s
2025-02-26 07:51:11.046268: 
2025-02-26 07:51:11.046512: Epoch 856
2025-02-26 07:51:11.046633: Current learning rate: 0.00175
2025-02-26 07:52:14.521577: train_loss -0.9371
2025-02-26 07:52:14.521978: val_loss -0.7342
2025-02-26 07:52:14.522063: Pseudo dice [0.784]
2025-02-26 07:52:14.522165: Epoch time: 63.48 s
2025-02-26 07:52:15.787759: 
2025-02-26 07:52:15.787979: Epoch 857
2025-02-26 07:52:15.788096: Current learning rate: 0.00174
2025-02-26 07:53:20.003448: train_loss -0.9333
2025-02-26 07:53:20.003887: val_loss -0.7282
2025-02-26 07:53:20.003978: Pseudo dice [0.7862]
2025-02-26 07:53:20.004091: Epoch time: 64.22 s
2025-02-26 07:53:21.274970: 
2025-02-26 07:53:21.275165: Epoch 858
2025-02-26 07:53:21.275285: Current learning rate: 0.00173
2025-02-26 07:54:26.944249: train_loss -0.9307
2025-02-26 07:54:26.944696: val_loss -0.7148
2025-02-26 07:54:26.944792: Pseudo dice [0.7735]
2025-02-26 07:54:26.944903: Epoch time: 65.67 s
2025-02-26 07:54:28.236708: 
2025-02-26 07:54:28.236939: Epoch 859
2025-02-26 07:54:28.237076: Current learning rate: 0.00172
2025-02-26 07:55:34.777141: train_loss -0.9311
2025-02-26 07:55:34.777530: val_loss -0.7205
2025-02-26 07:55:34.777612: Pseudo dice [0.7843]
2025-02-26 07:55:34.777712: Epoch time: 66.54 s
2025-02-26 07:55:36.062149: 
2025-02-26 07:55:36.062366: Epoch 860
2025-02-26 07:55:36.062505: Current learning rate: 0.0017
2025-02-26 07:56:44.574819: train_loss -0.9106
2025-02-26 07:56:44.575243: val_loss -0.7261
2025-02-26 07:56:44.575348: Pseudo dice [0.795]
2025-02-26 07:56:44.575464: Epoch time: 68.51 s
2025-02-26 07:56:45.836070: 
2025-02-26 07:56:45.836272: Epoch 861
2025-02-26 07:56:45.836402: Current learning rate: 0.00169
2025-02-26 07:57:51.130467: train_loss -0.9219
2025-02-26 07:57:51.130875: val_loss -0.7292
2025-02-26 07:57:51.130956: Pseudo dice [0.791]
2025-02-26 07:57:51.131056: Epoch time: 65.3 s
2025-02-26 07:57:52.480407: 
2025-02-26 07:57:52.480607: Epoch 862
2025-02-26 07:57:52.480728: Current learning rate: 0.00168
2025-02-26 07:59:00.351457: train_loss -0.9276
2025-02-26 07:59:00.351931: val_loss -0.7074
2025-02-26 07:59:00.352525: Pseudo dice [0.7702]
2025-02-26 07:59:00.352681: Epoch time: 67.87 s
2025-02-26 07:59:02.086383: 
2025-02-26 07:59:02.086592: Epoch 863
2025-02-26 07:59:02.086716: Current learning rate: 0.00167
2025-02-26 08:00:07.778549: train_loss -0.9255
2025-02-26 08:00:07.778971: val_loss -0.7336
2025-02-26 08:00:07.779058: Pseudo dice [0.789]
2025-02-26 08:00:07.779175: Epoch time: 65.69 s
2025-02-26 08:00:09.121135: 
2025-02-26 08:00:09.121368: Epoch 864
2025-02-26 08:00:09.121485: Current learning rate: 0.00166
2025-02-26 08:01:14.032627: train_loss -0.9275
2025-02-26 08:01:14.032972: val_loss -0.7421
2025-02-26 08:01:14.033056: Pseudo dice [0.7954]
2025-02-26 08:01:14.033156: Epoch time: 64.91 s
2025-02-26 08:01:15.337828: 
2025-02-26 08:01:15.338060: Epoch 865
2025-02-26 08:01:15.338182: Current learning rate: 0.00165
2025-02-26 08:02:21.077960: train_loss -0.9283
2025-02-26 08:02:21.078754: val_loss -0.7429
2025-02-26 08:02:21.078971: Pseudo dice [0.7945]
2025-02-26 08:02:21.079087: Epoch time: 65.74 s
2025-02-26 08:02:22.455454: 
2025-02-26 08:02:22.455678: Epoch 866
2025-02-26 08:02:22.455804: Current learning rate: 0.00164
2025-02-26 08:03:29.186348: train_loss -0.9267
2025-02-26 08:03:29.186721: val_loss -0.7277
2025-02-26 08:03:29.186808: Pseudo dice [0.7927]
2025-02-26 08:03:29.186907: Epoch time: 66.73 s
2025-02-26 08:03:30.510114: 
2025-02-26 08:03:30.510349: Epoch 867
2025-02-26 08:03:30.510470: Current learning rate: 0.00163
2025-02-26 08:04:37.058549: train_loss -0.9247
2025-02-26 08:04:37.058956: val_loss -0.7318
2025-02-26 08:04:37.059054: Pseudo dice [0.7931]
2025-02-26 08:04:37.059154: Epoch time: 66.55 s
2025-02-26 08:04:38.381774: 
2025-02-26 08:04:38.381991: Epoch 868
2025-02-26 08:04:38.382112: Current learning rate: 0.00162
2025-02-26 08:05:41.434105: train_loss -0.9244
2025-02-26 08:05:41.434623: val_loss -0.7195
2025-02-26 08:05:41.434711: Pseudo dice [0.7905]
2025-02-26 08:05:41.434813: Epoch time: 63.05 s
2025-02-26 08:05:42.784391: 
2025-02-26 08:05:42.784628: Epoch 869
2025-02-26 08:05:42.784752: Current learning rate: 0.00161
2025-02-26 08:06:46.601253: train_loss -0.9225
2025-02-26 08:06:46.601611: val_loss -0.7188
2025-02-26 08:06:46.601700: Pseudo dice [0.7725]
2025-02-26 08:06:46.601847: Epoch time: 63.82 s
2025-02-26 08:06:47.958090: 
2025-02-26 08:06:47.958311: Epoch 870
2025-02-26 08:06:47.958440: Current learning rate: 0.00159
2025-02-26 08:07:53.685408: train_loss -0.9284
2025-02-26 08:07:53.685707: val_loss -0.7354
2025-02-26 08:07:53.685793: Pseudo dice [0.7904]
2025-02-26 08:07:53.685889: Epoch time: 65.73 s
2025-02-26 08:07:54.977431: 
2025-02-26 08:07:54.977629: Epoch 871
2025-02-26 08:07:54.977750: Current learning rate: 0.00158
2025-02-26 08:09:00.212730: train_loss -0.928
2025-02-26 08:09:00.213176: val_loss -0.7211
2025-02-26 08:09:00.213268: Pseudo dice [0.7857]
2025-02-26 08:09:00.213402: Epoch time: 65.24 s
2025-02-26 08:09:01.565983: 
2025-02-26 08:09:01.566184: Epoch 872
2025-02-26 08:09:01.566314: Current learning rate: 0.00157
2025-02-26 08:10:08.149871: train_loss -0.9262
2025-02-26 08:10:08.150211: val_loss -0.7273
2025-02-26 08:10:08.150291: Pseudo dice [0.7895]
2025-02-26 08:10:08.150409: Epoch time: 66.59 s
2025-02-26 08:10:09.460811: 
2025-02-26 08:10:09.461021: Epoch 873
2025-02-26 08:10:09.461142: Current learning rate: 0.00156
2025-02-26 08:11:16.892173: train_loss -0.9216
2025-02-26 08:11:16.892573: val_loss -0.7365
2025-02-26 08:11:16.892658: Pseudo dice [0.7917]
2025-02-26 08:11:16.892753: Epoch time: 67.43 s
2025-02-26 08:11:18.221467: 
2025-02-26 08:11:18.221663: Epoch 874
2025-02-26 08:11:18.221782: Current learning rate: 0.00155
2025-02-26 08:12:29.537862: train_loss -0.9248
2025-02-26 08:12:29.538266: val_loss -0.7248
2025-02-26 08:12:29.538356: Pseudo dice [0.7919]
2025-02-26 08:12:29.538447: Epoch time: 71.32 s
2025-02-26 08:12:30.872484: 
2025-02-26 08:12:30.872691: Epoch 875
2025-02-26 08:12:30.872818: Current learning rate: 0.00154
2025-02-26 08:13:38.594959: train_loss -0.9246
2025-02-26 08:13:38.595382: val_loss -0.7328
2025-02-26 08:13:38.595493: Pseudo dice [0.7898]
2025-02-26 08:13:38.595606: Epoch time: 67.72 s
2025-02-26 08:13:40.395802: 
2025-02-26 08:13:40.396035: Epoch 876
2025-02-26 08:13:40.396157: Current learning rate: 0.00153
2025-02-26 08:14:46.156955: train_loss -0.9306
2025-02-26 08:14:46.157390: val_loss -0.7329
2025-02-26 08:14:46.157481: Pseudo dice [0.7868]
2025-02-26 08:14:46.157591: Epoch time: 65.76 s
2025-02-26 08:14:47.452979: 
2025-02-26 08:14:47.453219: Epoch 877
2025-02-26 08:14:47.453357: Current learning rate: 0.00152
2025-02-26 08:15:51.294514: train_loss -0.9363
2025-02-26 08:15:51.294865: val_loss -0.7117
2025-02-26 08:15:51.294943: Pseudo dice [0.7756]
2025-02-26 08:15:51.295025: Epoch time: 63.84 s
2025-02-26 08:15:52.602060: 
2025-02-26 08:15:52.602330: Epoch 878
2025-02-26 08:15:52.602459: Current learning rate: 0.00151
2025-02-26 08:16:56.360868: train_loss -0.9318
2025-02-26 08:16:56.361248: val_loss -0.7431
2025-02-26 08:16:56.361350: Pseudo dice [0.7987]
2025-02-26 08:16:56.361451: Epoch time: 63.76 s
2025-02-26 08:16:57.681917: 
2025-02-26 08:16:57.682144: Epoch 879
2025-02-26 08:16:57.682269: Current learning rate: 0.00149
2025-02-26 08:18:02.819418: train_loss -0.93
2025-02-26 08:18:02.819856: val_loss -0.7526
2025-02-26 08:18:02.819951: Pseudo dice [0.8052]
2025-02-26 08:18:02.820067: Epoch time: 65.14 s
2025-02-26 08:18:04.185452: 
2025-02-26 08:18:04.185655: Epoch 880
2025-02-26 08:18:04.185775: Current learning rate: 0.00148
2025-02-26 08:19:08.935739: train_loss -0.9386
2025-02-26 08:19:08.936138: val_loss -0.7393
2025-02-26 08:19:08.936229: Pseudo dice [0.7927]
2025-02-26 08:19:08.936344: Epoch time: 64.75 s
2025-02-26 08:19:10.225644: 
2025-02-26 08:19:10.225854: Epoch 881
2025-02-26 08:19:10.225976: Current learning rate: 0.00147
2025-02-26 08:20:17.254527: train_loss -0.9317
2025-02-26 08:20:17.255346: val_loss -0.7298
2025-02-26 08:20:17.255693: Pseudo dice [0.7863]
2025-02-26 08:20:17.255810: Epoch time: 67.03 s
2025-02-26 08:20:18.601623: 
2025-02-26 08:20:18.601835: Epoch 882
2025-02-26 08:20:18.601954: Current learning rate: 0.00146
2025-02-26 08:21:21.638883: train_loss -0.9345
2025-02-26 08:21:21.639269: val_loss -0.7311
2025-02-26 08:21:21.639371: Pseudo dice [0.7983]
2025-02-26 08:21:21.639477: Epoch time: 63.04 s
2025-02-26 08:21:22.928006: 
2025-02-26 08:21:22.928242: Epoch 883
2025-02-26 08:21:22.928384: Current learning rate: 0.00145
2025-02-26 08:22:29.190310: train_loss -0.9353
2025-02-26 08:22:29.190659: val_loss -0.7473
2025-02-26 08:22:29.190827: Pseudo dice [0.7984]
2025-02-26 08:22:29.191082: Epoch time: 66.26 s
2025-02-26 08:22:30.488451: 
2025-02-26 08:22:30.488652: Epoch 884
2025-02-26 08:22:30.488778: Current learning rate: 0.00144
2025-02-26 08:23:35.591024: train_loss -0.933
2025-02-26 08:23:35.591440: val_loss -0.7382
2025-02-26 08:23:35.591523: Pseudo dice [0.8001]
2025-02-26 08:23:35.591615: Epoch time: 65.1 s
2025-02-26 08:23:36.935683: 
2025-02-26 08:23:36.935913: Epoch 885
2025-02-26 08:23:36.936041: Current learning rate: 0.00143
2025-02-26 08:24:44.586701: train_loss -0.933
2025-02-26 08:24:44.587094: val_loss -0.7263
2025-02-26 08:24:44.587180: Pseudo dice [0.7861]
2025-02-26 08:24:44.587275: Epoch time: 67.65 s
2025-02-26 08:24:45.928681: 
2025-02-26 08:24:45.928898: Epoch 886
2025-02-26 08:24:45.929018: Current learning rate: 0.00142
2025-02-26 08:25:52.255474: train_loss -0.9298
2025-02-26 08:25:52.255860: val_loss -0.7301
2025-02-26 08:25:52.255962: Pseudo dice [0.784]
2025-02-26 08:25:52.256081: Epoch time: 66.33 s
2025-02-26 08:25:53.546280: 
2025-02-26 08:25:53.546562: Epoch 887
2025-02-26 08:25:53.546684: Current learning rate: 0.00141
2025-02-26 08:27:02.087426: train_loss -0.9307
2025-02-26 08:27:02.087781: val_loss -0.7214
2025-02-26 08:27:02.087855: Pseudo dice [0.7913]
2025-02-26 08:27:02.087937: Epoch time: 68.54 s
2025-02-26 08:27:03.363699: 
2025-02-26 08:27:03.363919: Epoch 888
2025-02-26 08:27:03.364051: Current learning rate: 0.00139
2025-02-26 08:28:10.383426: train_loss -0.9253
2025-02-26 08:28:10.383783: val_loss -0.7086
2025-02-26 08:28:10.384495: Pseudo dice [0.777]
2025-02-26 08:28:10.384634: Epoch time: 67.02 s
2025-02-26 08:28:11.681633: 
2025-02-26 08:28:11.681853: Epoch 889
2025-02-26 08:28:11.681971: Current learning rate: 0.00138
2025-02-26 08:29:15.295604: train_loss -0.9304
2025-02-26 08:29:15.295902: val_loss -0.7372
2025-02-26 08:29:15.295970: Pseudo dice [0.7917]
2025-02-26 08:29:15.296056: Epoch time: 63.62 s
2025-02-26 08:29:16.592576: 
2025-02-26 08:29:16.592814: Epoch 890
2025-02-26 08:29:16.592940: Current learning rate: 0.00137
2025-02-26 08:30:20.716702: train_loss -0.9335
2025-02-26 08:30:20.717114: val_loss -0.7392
2025-02-26 08:30:20.717200: Pseudo dice [0.7929]
2025-02-26 08:30:20.717328: Epoch time: 64.13 s
2025-02-26 08:30:22.046964: 
2025-02-26 08:30:22.047188: Epoch 891
2025-02-26 08:30:22.047320: Current learning rate: 0.00136
2025-02-26 08:31:26.723354: train_loss -0.9332
2025-02-26 08:31:26.723783: val_loss -0.7325
2025-02-26 08:31:26.723875: Pseudo dice [0.7985]
2025-02-26 08:31:26.723986: Epoch time: 64.68 s
2025-02-26 08:31:28.063560: 
2025-02-26 08:31:28.063773: Epoch 892
2025-02-26 08:31:28.063901: Current learning rate: 0.00135
2025-02-26 08:32:31.726436: train_loss -0.9344
2025-02-26 08:32:31.726774: val_loss -0.7263
2025-02-26 08:32:31.726844: Pseudo dice [0.7895]
2025-02-26 08:32:31.726926: Epoch time: 63.66 s
2025-02-26 08:32:33.023521: 
2025-02-26 08:32:33.023741: Epoch 893
2025-02-26 08:32:33.023867: Current learning rate: 0.00134
2025-02-26 08:33:38.378164: train_loss -0.9392
2025-02-26 08:33:38.378529: val_loss -0.7335
2025-02-26 08:33:38.378613: Pseudo dice [0.7938]
2025-02-26 08:33:38.378705: Epoch time: 65.36 s
2025-02-26 08:33:39.742026: 
2025-02-26 08:33:39.742255: Epoch 894
2025-02-26 08:33:39.742388: Current learning rate: 0.00133
2025-02-26 08:34:44.804527: train_loss -0.9339
2025-02-26 08:34:44.804810: val_loss -0.7381
2025-02-26 08:34:44.804894: Pseudo dice [0.8057]
2025-02-26 08:34:44.804989: Epoch time: 65.06 s
2025-02-26 08:34:46.168411: 
2025-02-26 08:34:46.168619: Epoch 895
2025-02-26 08:34:46.168754: Current learning rate: 0.00132
2025-02-26 08:35:50.858459: train_loss -0.9299
2025-02-26 08:35:50.858905: val_loss -0.752
2025-02-26 08:35:50.858999: Pseudo dice [0.806]
2025-02-26 08:35:50.859115: Epoch time: 64.69 s
2025-02-26 08:35:52.190198: 
2025-02-26 08:35:52.190417: Epoch 896
2025-02-26 08:35:52.190537: Current learning rate: 0.0013
2025-02-26 08:36:56.659630: train_loss -0.9329
2025-02-26 08:36:56.660013: val_loss -0.7482
2025-02-26 08:36:56.660101: Pseudo dice [0.8016]
2025-02-26 08:36:56.660204: Epoch time: 64.47 s
2025-02-26 08:36:58.018277: 
2025-02-26 08:36:58.018506: Epoch 897
2025-02-26 08:36:58.018633: Current learning rate: 0.00129
2025-02-26 08:38:06.152964: train_loss -0.9267
2025-02-26 08:38:06.153365: val_loss -0.7374
2025-02-26 08:38:06.153454: Pseudo dice [0.7949]
2025-02-26 08:38:06.153557: Epoch time: 68.14 s
2025-02-26 08:38:07.461914: 
2025-02-26 08:38:07.462119: Epoch 898
2025-02-26 08:38:07.462238: Current learning rate: 0.00128
2025-02-26 08:39:15.190356: train_loss -0.9409
2025-02-26 08:39:15.190657: val_loss -0.7413
2025-02-26 08:39:15.190743: Pseudo dice [0.8017]
2025-02-26 08:39:15.190841: Epoch time: 67.73 s
2025-02-26 08:39:16.514933: 
2025-02-26 08:39:16.515132: Epoch 899
2025-02-26 08:39:16.515254: Current learning rate: 0.00127
2025-02-26 08:40:25.600094: train_loss -0.9368
2025-02-26 08:40:25.600533: val_loss -0.7445
2025-02-26 08:40:25.600615: Pseudo dice [0.8025]
2025-02-26 08:40:25.600718: Epoch time: 69.09 s
2025-02-26 08:40:27.502653: 
2025-02-26 08:40:27.502899: Epoch 900
2025-02-26 08:40:27.503023: Current learning rate: 0.00126
2025-02-26 08:41:34.526794: train_loss -0.9315
2025-02-26 08:41:34.527214: val_loss -0.7307
2025-02-26 08:41:34.527323: Pseudo dice [0.7967]
2025-02-26 08:41:34.527432: Epoch time: 67.03 s
2025-02-26 08:41:36.287009: 
2025-02-26 08:41:36.287237: Epoch 901
2025-02-26 08:41:36.287369: Current learning rate: 0.00125
2025-02-26 08:42:41.153220: train_loss -0.9364
2025-02-26 08:42:41.153609: val_loss -0.7169
2025-02-26 08:42:41.153693: Pseudo dice [0.7808]
2025-02-26 08:42:41.153799: Epoch time: 64.87 s
2025-02-26 08:42:42.478141: 
2025-02-26 08:42:42.478383: Epoch 902
2025-02-26 08:42:42.478507: Current learning rate: 0.00124
2025-02-26 08:43:47.975135: train_loss -0.9307
2025-02-26 08:43:47.975482: val_loss -0.7383
2025-02-26 08:43:47.975556: Pseudo dice [0.7973]
2025-02-26 08:43:47.975640: Epoch time: 65.5 s
2025-02-26 08:43:49.291088: 
2025-02-26 08:43:49.291325: Epoch 903
2025-02-26 08:43:49.291449: Current learning rate: 0.00122
2025-02-26 08:44:55.748881: train_loss -0.9354
2025-02-26 08:44:55.749277: val_loss -0.7424
2025-02-26 08:44:55.749381: Pseudo dice [0.7993]
2025-02-26 08:44:55.749494: Epoch time: 66.46 s
2025-02-26 08:44:57.034400: 
2025-02-26 08:44:57.034607: Epoch 904
2025-02-26 08:44:57.034731: Current learning rate: 0.00121
2025-02-26 08:46:01.830146: train_loss -0.9311
2025-02-26 08:46:01.830508: val_loss -0.7384
2025-02-26 08:46:01.830597: Pseudo dice [0.7941]
2025-02-26 08:46:01.830693: Epoch time: 64.8 s
2025-02-26 08:46:03.197631: 
2025-02-26 08:46:03.197834: Epoch 905
2025-02-26 08:46:03.197957: Current learning rate: 0.0012
2025-02-26 08:47:09.797913: train_loss -0.9379
2025-02-26 08:47:09.798328: val_loss -0.7479
2025-02-26 08:47:09.798418: Pseudo dice [0.7948]
2025-02-26 08:47:09.798516: Epoch time: 66.6 s
2025-02-26 08:47:11.209373: 
2025-02-26 08:47:11.209587: Epoch 906
2025-02-26 08:47:11.209713: Current learning rate: 0.00119
2025-02-26 08:48:15.523662: train_loss -0.9416
2025-02-26 08:48:15.524103: val_loss -0.7292
2025-02-26 08:48:15.524210: Pseudo dice [0.7931]
2025-02-26 08:48:15.524335: Epoch time: 64.32 s
2025-02-26 08:48:16.808724: 
2025-02-26 08:48:16.808930: Epoch 907
2025-02-26 08:48:16.809045: Current learning rate: 0.00118
2025-02-26 08:49:23.786837: train_loss -0.9357
2025-02-26 08:49:23.787274: val_loss -0.7358
2025-02-26 08:49:23.787410: Pseudo dice [0.7873]
2025-02-26 08:49:23.787683: Epoch time: 66.98 s
2025-02-26 08:49:25.071286: 
2025-02-26 08:49:25.071500: Epoch 908
2025-02-26 08:49:25.071619: Current learning rate: 0.00117
2025-02-26 08:50:32.248486: train_loss -0.9332
2025-02-26 08:50:32.248876: val_loss -0.7368
2025-02-26 08:50:32.248973: Pseudo dice [0.7922]
2025-02-26 08:50:32.249077: Epoch time: 67.18 s
2025-02-26 08:50:33.553611: 
2025-02-26 08:50:33.553834: Epoch 909
2025-02-26 08:50:33.553952: Current learning rate: 0.00116
2025-02-26 08:51:39.226585: train_loss -0.9369
2025-02-26 08:51:39.226993: val_loss -0.7252
2025-02-26 08:51:39.227087: Pseudo dice [0.786]
2025-02-26 08:51:39.227191: Epoch time: 65.67 s
2025-02-26 08:51:40.507348: 
2025-02-26 08:51:40.507551: Epoch 910
2025-02-26 08:51:40.507670: Current learning rate: 0.00115
2025-02-26 08:52:49.650497: train_loss -0.9247
2025-02-26 08:52:49.651029: val_loss -0.738
2025-02-26 08:52:49.651135: Pseudo dice [0.7971]
2025-02-26 08:52:49.651290: Epoch time: 69.14 s
2025-02-26 08:52:50.934877: 
2025-02-26 08:52:50.935101: Epoch 911
2025-02-26 08:52:50.935230: Current learning rate: 0.00113
2025-02-26 08:54:01.723993: train_loss -0.9324
2025-02-26 08:54:01.724397: val_loss -0.7237
2025-02-26 08:54:01.724488: Pseudo dice [0.7839]
2025-02-26 08:54:01.724596: Epoch time: 70.79 s
2025-02-26 08:54:03.023287: 
2025-02-26 08:54:03.023523: Epoch 912
2025-02-26 08:54:03.023662: Current learning rate: 0.00112
2025-02-26 08:55:14.838967: train_loss -0.9345
2025-02-26 08:55:14.839354: val_loss -0.7276
2025-02-26 08:55:14.839442: Pseudo dice [0.795]
2025-02-26 08:55:14.839540: Epoch time: 71.82 s
2025-02-26 08:55:16.566756: 
2025-02-26 08:55:16.567009: Epoch 913
2025-02-26 08:55:16.567136: Current learning rate: 0.00111
2025-02-26 08:56:19.994078: train_loss -0.9326
2025-02-26 08:56:19.994482: val_loss -0.7279
2025-02-26 08:56:19.994567: Pseudo dice [0.7818]
2025-02-26 08:56:19.994677: Epoch time: 63.43 s
2025-02-26 08:56:21.320819: 
2025-02-26 08:56:21.321028: Epoch 914
2025-02-26 08:56:21.321147: Current learning rate: 0.0011
2025-02-26 08:57:26.079630: train_loss -0.9274
2025-02-26 08:57:26.079991: val_loss -0.7108
2025-02-26 08:57:26.080695: Pseudo dice [0.7746]
2025-02-26 08:57:26.080838: Epoch time: 64.76 s
2025-02-26 08:57:27.375435: 
2025-02-26 08:57:27.375659: Epoch 915
2025-02-26 08:57:27.375778: Current learning rate: 0.00109
2025-02-26 08:58:33.573145: train_loss -0.9281
2025-02-26 08:58:33.573544: val_loss -0.715
2025-02-26 08:58:33.573629: Pseudo dice [0.7832]
2025-02-26 08:58:33.573729: Epoch time: 66.2 s
2025-02-26 08:58:34.861781: 
2025-02-26 08:58:34.861991: Epoch 916
2025-02-26 08:58:34.862106: Current learning rate: 0.00108
2025-02-26 08:59:38.606219: train_loss -0.9366
2025-02-26 08:59:38.606577: val_loss -0.7325
2025-02-26 08:59:38.606655: Pseudo dice [0.7884]
2025-02-26 08:59:38.606746: Epoch time: 63.75 s
2025-02-26 08:59:39.960899: 
2025-02-26 08:59:39.961107: Epoch 917
2025-02-26 08:59:39.961226: Current learning rate: 0.00106
2025-02-26 09:00:45.103030: train_loss -0.9362
2025-02-26 09:00:45.103456: val_loss -0.7444
2025-02-26 09:00:45.103551: Pseudo dice [0.8047]
2025-02-26 09:00:45.103685: Epoch time: 65.14 s
2025-02-26 09:00:46.403108: 
2025-02-26 09:00:46.403345: Epoch 918
2025-02-26 09:00:46.403468: Current learning rate: 0.00105
2025-02-26 09:01:51.162784: train_loss -0.9406
2025-02-26 09:01:51.163151: val_loss -0.7184
2025-02-26 09:01:51.163236: Pseudo dice [0.7921]
2025-02-26 09:01:51.163354: Epoch time: 64.76 s
2025-02-26 09:01:52.484806: 
2025-02-26 09:01:52.485011: Epoch 919
2025-02-26 09:01:52.485130: Current learning rate: 0.00104
2025-02-26 09:02:57.126837: train_loss -0.9378
2025-02-26 09:02:57.127198: val_loss -0.7478
2025-02-26 09:02:57.127273: Pseudo dice [0.8019]
2025-02-26 09:02:57.127373: Epoch time: 64.64 s
2025-02-26 09:02:58.401070: 
2025-02-26 09:02:58.401291: Epoch 920
2025-02-26 09:02:58.401420: Current learning rate: 0.00103
2025-02-26 09:04:03.116750: train_loss -0.938
2025-02-26 09:04:03.117100: val_loss -0.7449
2025-02-26 09:04:03.117199: Pseudo dice [0.7997]
2025-02-26 09:04:03.117291: Epoch time: 64.72 s
2025-02-26 09:04:04.394704: 
2025-02-26 09:04:04.394923: Epoch 921
2025-02-26 09:04:04.395042: Current learning rate: 0.00102
2025-02-26 09:05:12.792745: train_loss -0.9437
2025-02-26 09:05:12.793143: val_loss -0.7388
2025-02-26 09:05:12.793244: Pseudo dice [0.795]
2025-02-26 09:05:12.793387: Epoch time: 68.4 s
2025-02-26 09:05:14.071067: 
2025-02-26 09:05:14.071311: Epoch 922
2025-02-26 09:05:14.071446: Current learning rate: 0.00101
2025-02-26 09:06:18.953460: train_loss -0.9425
2025-02-26 09:06:18.953858: val_loss -0.7289
2025-02-26 09:06:18.953946: Pseudo dice [0.7896]
2025-02-26 09:06:18.954052: Epoch time: 64.88 s
2025-02-26 09:06:20.344553: 
2025-02-26 09:06:20.344762: Epoch 923
2025-02-26 09:06:20.344879: Current learning rate: 0.001
2025-02-26 09:07:26.665661: train_loss -0.9351
2025-02-26 09:07:26.666028: val_loss -0.7348
2025-02-26 09:07:26.666115: Pseudo dice [0.7921]
2025-02-26 09:07:26.666218: Epoch time: 66.32 s
2025-02-26 09:07:27.985594: 
2025-02-26 09:07:27.985788: Epoch 924
2025-02-26 09:07:27.985916: Current learning rate: 0.00098
2025-02-26 09:08:36.550211: train_loss -0.9375
2025-02-26 09:08:36.550558: val_loss -0.7309
2025-02-26 09:08:36.550659: Pseudo dice [0.786]
2025-02-26 09:08:36.550770: Epoch time: 68.57 s
2025-02-26 09:08:37.902511: 
2025-02-26 09:08:37.902716: Epoch 925
2025-02-26 09:08:37.902838: Current learning rate: 0.00097
2025-02-26 09:09:46.708958: train_loss -0.9359
2025-02-26 09:09:46.709486: val_loss -0.7346
2025-02-26 09:09:46.709583: Pseudo dice [0.7978]
2025-02-26 09:09:46.709685: Epoch time: 68.81 s
2025-02-26 09:09:48.036513: 
2025-02-26 09:09:48.036776: Epoch 926
2025-02-26 09:09:48.036910: Current learning rate: 0.00096
2025-02-26 09:10:53.502757: train_loss -0.9349
2025-02-26 09:10:53.503149: val_loss -0.7345
2025-02-26 09:10:53.503230: Pseudo dice [0.7883]
2025-02-26 09:10:53.503332: Epoch time: 65.47 s
2025-02-26 09:10:54.815361: 
2025-02-26 09:10:54.815565: Epoch 927
2025-02-26 09:10:54.815687: Current learning rate: 0.00095
2025-02-26 09:11:58.905079: train_loss -0.9341
2025-02-26 09:11:58.905498: val_loss -0.722
2025-02-26 09:11:58.905586: Pseudo dice [0.7879]
2025-02-26 09:11:58.905686: Epoch time: 64.09 s
2025-02-26 09:12:00.232460: 
2025-02-26 09:12:00.232702: Epoch 928
2025-02-26 09:12:00.232823: Current learning rate: 0.00094
2025-02-26 09:13:07.333292: train_loss -0.9354
2025-02-26 09:13:07.333699: val_loss -0.72
2025-02-26 09:13:07.333782: Pseudo dice [0.7796]
2025-02-26 09:13:07.333880: Epoch time: 67.1 s
2025-02-26 09:13:08.697494: 
2025-02-26 09:13:08.697708: Epoch 929
2025-02-26 09:13:08.697840: Current learning rate: 0.00092
2025-02-26 09:14:13.641078: train_loss -0.9408
2025-02-26 09:14:13.641512: val_loss -0.7296
2025-02-26 09:14:13.641605: Pseudo dice [0.7895]
2025-02-26 09:14:13.641708: Epoch time: 64.95 s
2025-02-26 09:14:14.952968: 
2025-02-26 09:14:14.953189: Epoch 930
2025-02-26 09:14:14.953322: Current learning rate: 0.00091
2025-02-26 09:15:24.509539: train_loss -0.9395
2025-02-26 09:15:24.509939: val_loss -0.7318
2025-02-26 09:15:24.510023: Pseudo dice [0.7951]
2025-02-26 09:15:24.510123: Epoch time: 69.56 s
2025-02-26 09:15:25.864600: 
2025-02-26 09:15:25.864871: Epoch 931
2025-02-26 09:15:25.865012: Current learning rate: 0.0009
2025-02-26 09:16:33.855710: train_loss -0.9403
2025-02-26 09:16:33.856093: val_loss -0.7151
2025-02-26 09:16:33.856183: Pseudo dice [0.7776]
2025-02-26 09:16:33.856289: Epoch time: 67.99 s
2025-02-26 09:16:35.151063: 
2025-02-26 09:16:35.151313: Epoch 932
2025-02-26 09:16:35.151438: Current learning rate: 0.00089
2025-02-26 09:17:41.135469: train_loss -0.9372
2025-02-26 09:17:41.135912: val_loss -0.7263
2025-02-26 09:17:41.136001: Pseudo dice [0.7953]
2025-02-26 09:17:41.136107: Epoch time: 65.99 s
2025-02-26 09:17:42.441134: 
2025-02-26 09:17:42.441350: Epoch 933
2025-02-26 09:17:42.441473: Current learning rate: 0.00088
2025-02-26 09:18:45.189844: train_loss -0.9399
2025-02-26 09:18:45.190253: val_loss -0.7311
2025-02-26 09:18:45.190359: Pseudo dice [0.79]
2025-02-26 09:18:45.190685: Epoch time: 62.75 s
2025-02-26 09:18:46.512755: 
2025-02-26 09:18:46.512981: Epoch 934
2025-02-26 09:18:46.513105: Current learning rate: 0.00087
2025-02-26 09:19:52.444105: train_loss -0.9357
2025-02-26 09:19:52.444478: val_loss -0.7277
2025-02-26 09:19:52.444561: Pseudo dice [0.7955]
2025-02-26 09:19:52.444656: Epoch time: 65.93 s
2025-02-26 09:19:53.786506: 
2025-02-26 09:19:53.786752: Epoch 935
2025-02-26 09:19:53.786875: Current learning rate: 0.00085
2025-02-26 09:21:03.409379: train_loss -0.9395
2025-02-26 09:21:03.409739: val_loss -0.7184
2025-02-26 09:21:03.409823: Pseudo dice [0.7803]
2025-02-26 09:21:03.409923: Epoch time: 69.62 s
2025-02-26 09:21:04.725064: 
2025-02-26 09:21:04.725276: Epoch 936
2025-02-26 09:21:04.725416: Current learning rate: 0.00084
2025-02-26 09:22:15.991522: train_loss -0.9392
2025-02-26 09:22:15.992049: val_loss -0.7365
2025-02-26 09:22:15.992147: Pseudo dice [0.7957]
2025-02-26 09:22:15.992259: Epoch time: 71.27 s
2025-02-26 09:22:17.286468: 
2025-02-26 09:22:17.286688: Epoch 937
2025-02-26 09:22:17.286820: Current learning rate: 0.00083
2025-02-26 09:23:30.233325: train_loss -0.938
2025-02-26 09:23:30.233795: val_loss -0.7343
2025-02-26 09:23:30.233886: Pseudo dice [0.7941]
2025-02-26 09:23:30.234002: Epoch time: 72.95 s
2025-02-26 09:23:31.941843: 
2025-02-26 09:23:31.942080: Epoch 938
2025-02-26 09:23:31.942203: Current learning rate: 0.00082
2025-02-26 09:24:41.627742: train_loss -0.9344
2025-02-26 09:24:41.628154: val_loss -0.736
2025-02-26 09:24:41.628246: Pseudo dice [0.7933]
2025-02-26 09:24:41.628367: Epoch time: 69.69 s
2025-02-26 09:24:42.977359: 
2025-02-26 09:24:42.977578: Epoch 939
2025-02-26 09:24:42.977700: Current learning rate: 0.00081
2025-02-26 09:25:50.922733: train_loss -0.9428
2025-02-26 09:25:50.923161: val_loss -0.7266
2025-02-26 09:25:50.923248: Pseudo dice [0.7881]
2025-02-26 09:25:50.923376: Epoch time: 67.95 s
2025-02-26 09:25:52.264065: 
2025-02-26 09:25:52.264294: Epoch 940
2025-02-26 09:25:52.264430: Current learning rate: 0.00079
2025-02-26 09:27:03.319363: train_loss -0.9313
2025-02-26 09:27:03.319740: val_loss -0.7289
2025-02-26 09:27:03.320335: Pseudo dice [0.7954]
2025-02-26 09:27:03.320450: Epoch time: 71.06 s
2025-02-26 09:27:04.661793: 
2025-02-26 09:27:04.662029: Epoch 941
2025-02-26 09:27:04.662156: Current learning rate: 0.00078
2025-02-26 09:28:14.784868: train_loss -0.9352
2025-02-26 09:28:14.785293: val_loss -0.7263
2025-02-26 09:28:14.785399: Pseudo dice [0.7917]
2025-02-26 09:28:14.785506: Epoch time: 70.12 s
2025-02-26 09:28:16.098415: 
2025-02-26 09:28:16.098615: Epoch 942
2025-02-26 09:28:16.098732: Current learning rate: 0.00077
2025-02-26 09:29:24.868808: train_loss -0.941
2025-02-26 09:29:24.869166: val_loss -0.7313
2025-02-26 09:29:24.869249: Pseudo dice [0.8011]
2025-02-26 09:29:24.869357: Epoch time: 68.77 s
2025-02-26 09:29:26.170313: 
2025-02-26 09:29:26.170506: Epoch 943
2025-02-26 09:29:26.170629: Current learning rate: 0.00076
2025-02-26 09:30:35.129905: train_loss -0.9389
2025-02-26 09:30:35.130317: val_loss -0.7246
2025-02-26 09:30:35.130409: Pseudo dice [0.7857]
2025-02-26 09:30:35.130525: Epoch time: 68.96 s
2025-02-26 09:30:36.477778: 
2025-02-26 09:30:36.478014: Epoch 944
2025-02-26 09:30:36.478165: Current learning rate: 0.00075
2025-02-26 09:31:45.603280: train_loss -0.9447
2025-02-26 09:31:45.603674: val_loss -0.7228
2025-02-26 09:31:45.603754: Pseudo dice [0.7894]
2025-02-26 09:31:45.603853: Epoch time: 69.13 s
2025-02-26 09:31:46.890409: 
2025-02-26 09:31:46.890632: Epoch 945
2025-02-26 09:31:46.890756: Current learning rate: 0.00074
2025-02-26 09:32:57.237602: train_loss -0.939
2025-02-26 09:32:57.238021: val_loss -0.7405
2025-02-26 09:32:57.238106: Pseudo dice [0.7989]
2025-02-26 09:32:57.238207: Epoch time: 70.35 s
2025-02-26 09:32:58.522561: 
2025-02-26 09:32:58.522780: Epoch 946
2025-02-26 09:32:58.522920: Current learning rate: 0.00072
2025-02-26 09:34:11.273986: train_loss -0.9336
2025-02-26 09:34:11.274399: val_loss -0.7298
2025-02-26 09:34:11.274487: Pseudo dice [0.7938]
2025-02-26 09:34:11.274595: Epoch time: 72.75 s
2025-02-26 09:34:12.589369: 
2025-02-26 09:34:12.589586: Epoch 947
2025-02-26 09:34:12.589708: Current learning rate: 0.00071
2025-02-26 09:35:21.307851: train_loss -0.9392
2025-02-26 09:35:21.308136: val_loss -0.7453
2025-02-26 09:35:21.308229: Pseudo dice [0.8036]
2025-02-26 09:35:21.308436: Epoch time: 68.72 s
2025-02-26 09:35:22.655598: 
2025-02-26 09:35:22.655803: Epoch 948
2025-02-26 09:35:22.655926: Current learning rate: 0.0007
2025-02-26 09:36:31.356596: train_loss -0.9345
2025-02-26 09:36:31.356961: val_loss -0.7332
2025-02-26 09:36:31.357054: Pseudo dice [0.7947]
2025-02-26 09:36:31.357141: Epoch time: 68.7 s
2025-02-26 09:36:32.718194: 
2025-02-26 09:36:32.718442: Epoch 949
2025-02-26 09:36:32.718570: Current learning rate: 0.00069
2025-02-26 09:37:42.371967: train_loss -0.9382
2025-02-26 09:37:42.372370: val_loss -0.7223
2025-02-26 09:37:42.372467: Pseudo dice [0.79]
2025-02-26 09:37:42.372575: Epoch time: 69.66 s
2025-02-26 09:37:44.665758: 
2025-02-26 09:37:44.665984: Epoch 950
2025-02-26 09:37:44.666112: Current learning rate: 0.00067
2025-02-26 09:38:52.652429: train_loss -0.9403
2025-02-26 09:38:52.652852: val_loss -0.7194
2025-02-26 09:38:52.652941: Pseudo dice [0.7891]
2025-02-26 09:38:52.653046: Epoch time: 67.99 s
2025-02-26 09:38:54.047415: 
2025-02-26 09:38:54.047655: Epoch 951
2025-02-26 09:38:54.047799: Current learning rate: 0.00066
2025-02-26 09:40:02.347900: train_loss -0.9309
2025-02-26 09:40:02.348367: val_loss -0.7273
2025-02-26 09:40:02.348496: Pseudo dice [0.7907]
2025-02-26 09:40:02.348609: Epoch time: 68.3 s
2025-02-26 09:40:03.687171: 
2025-02-26 09:40:03.687582: Epoch 952
2025-02-26 09:40:03.687706: Current learning rate: 0.00065
2025-02-26 09:41:12.620850: train_loss -0.9215
2025-02-26 09:41:12.621263: val_loss -0.7195
2025-02-26 09:41:12.621362: Pseudo dice [0.7901]
2025-02-26 09:41:12.621461: Epoch time: 68.94 s
2025-02-26 09:41:13.962330: 
2025-02-26 09:41:13.962552: Epoch 953
2025-02-26 09:41:13.962674: Current learning rate: 0.00064
2025-02-26 09:42:20.752609: train_loss -0.9382
2025-02-26 09:42:20.752993: val_loss -0.7122
2025-02-26 09:42:20.753074: Pseudo dice [0.7759]
2025-02-26 09:42:20.753171: Epoch time: 66.79 s
2025-02-26 09:42:22.175236: 
2025-02-26 09:42:22.175474: Epoch 954
2025-02-26 09:42:22.175598: Current learning rate: 0.00063
2025-02-26 09:43:31.962988: train_loss -0.9315
2025-02-26 09:43:31.963381: val_loss -0.7145
2025-02-26 09:43:31.963474: Pseudo dice [0.7768]
2025-02-26 09:43:31.963577: Epoch time: 69.79 s
2025-02-26 09:43:33.293562: 
2025-02-26 09:43:33.293795: Epoch 955
2025-02-26 09:43:33.293920: Current learning rate: 0.00061
2025-02-26 09:44:44.814930: train_loss -0.931
2025-02-26 09:44:44.815459: val_loss -0.749
2025-02-26 09:44:44.815551: Pseudo dice [0.8029]
2025-02-26 09:44:44.815649: Epoch time: 71.52 s
2025-02-26 09:44:46.140023: 
2025-02-26 09:44:46.140234: Epoch 956
2025-02-26 09:44:46.140367: Current learning rate: 0.0006
2025-02-26 09:45:56.846099: train_loss -0.9409
2025-02-26 09:45:56.846534: val_loss -0.7133
2025-02-26 09:45:56.846632: Pseudo dice [0.7804]
2025-02-26 09:45:56.846735: Epoch time: 70.71 s
2025-02-26 09:45:58.190334: 
2025-02-26 09:45:58.190562: Epoch 957
2025-02-26 09:45:58.190688: Current learning rate: 0.00059
2025-02-26 09:47:07.211254: train_loss -0.939
2025-02-26 09:47:07.211690: val_loss -0.7387
2025-02-26 09:47:07.211773: Pseudo dice [0.7994]
2025-02-26 09:47:07.211873: Epoch time: 69.02 s
2025-02-26 09:47:08.539669: 
2025-02-26 09:47:08.539890: Epoch 958
2025-02-26 09:47:08.540018: Current learning rate: 0.00058
2025-02-26 09:48:23.254586: train_loss -0.9383
2025-02-26 09:48:23.254885: val_loss -0.7268
2025-02-26 09:48:23.254974: Pseudo dice [0.7899]
2025-02-26 09:48:23.255074: Epoch time: 74.72 s
2025-02-26 09:48:24.719164: 
2025-02-26 09:48:24.719393: Epoch 959
2025-02-26 09:48:24.719517: Current learning rate: 0.00056
2025-02-26 09:49:42.464799: train_loss -0.9377
2025-02-26 09:49:42.465194: val_loss -0.7379
2025-02-26 09:49:42.465283: Pseudo dice [0.799]
2025-02-26 09:49:42.465414: Epoch time: 77.75 s
2025-02-26 09:49:43.978004: 
2025-02-26 09:49:43.978269: Epoch 960
2025-02-26 09:49:43.978411: Current learning rate: 0.00055
2025-02-26 09:51:05.311894: train_loss -0.9388
2025-02-26 09:51:05.312345: val_loss -0.7411
2025-02-26 09:51:05.312444: Pseudo dice [0.8048]
2025-02-26 09:51:05.312559: Epoch time: 81.34 s
2025-02-26 09:51:06.665384: 
2025-02-26 09:51:06.665593: Epoch 961
2025-02-26 09:51:06.665713: Current learning rate: 0.00054
2025-02-26 09:52:24.484622: train_loss -0.9361
2025-02-26 09:52:24.485030: val_loss -0.728
2025-02-26 09:52:24.485120: Pseudo dice [0.792]
2025-02-26 09:52:24.485228: Epoch time: 77.82 s
2025-02-26 09:52:25.954888: 
2025-02-26 09:52:25.955106: Epoch 962
2025-02-26 09:52:25.955230: Current learning rate: 0.00053
2025-02-26 09:53:42.506052: train_loss -0.9457
2025-02-26 09:53:42.506505: val_loss -0.7314
2025-02-26 09:53:42.506611: Pseudo dice [0.7951]
2025-02-26 09:53:42.506726: Epoch time: 76.55 s
2025-02-26 09:53:44.311570: 
2025-02-26 09:53:44.311813: Epoch 963
2025-02-26 09:53:44.311939: Current learning rate: 0.00051
2025-02-26 09:54:57.285989: train_loss -0.9351
2025-02-26 09:54:57.286407: val_loss -0.74
2025-02-26 09:54:57.286503: Pseudo dice [0.7965]
2025-02-26 09:54:57.286591: Epoch time: 72.98 s
2025-02-26 09:54:58.689203: 
2025-02-26 09:54:58.689443: Epoch 964
2025-02-26 09:54:58.689573: Current learning rate: 0.0005
2025-02-26 09:56:14.259798: train_loss -0.9381
2025-02-26 09:56:14.260368: val_loss -0.7121
2025-02-26 09:56:14.260514: Pseudo dice [0.7802]
2025-02-26 09:56:14.260678: Epoch time: 75.57 s
2025-02-26 09:56:15.603026: 
2025-02-26 09:56:15.603244: Epoch 965
2025-02-26 09:56:15.603375: Current learning rate: 0.00049
2025-02-26 09:57:32.148545: train_loss -0.9402
2025-02-26 09:57:32.148958: val_loss -0.7221
2025-02-26 09:57:32.149045: Pseudo dice [0.784]
2025-02-26 09:57:32.149163: Epoch time: 76.55 s
2025-02-26 09:57:33.491899: 
2025-02-26 09:57:33.492143: Epoch 966
2025-02-26 09:57:33.492265: Current learning rate: 0.00048
2025-02-26 09:58:50.019660: train_loss -0.9416
2025-02-26 09:58:50.020084: val_loss -0.7325
2025-02-26 09:58:50.031773: Pseudo dice [0.7954]
2025-02-26 09:58:50.032179: Epoch time: 76.53 s
2025-02-26 09:58:51.410146: 
2025-02-26 09:58:51.410378: Epoch 967
2025-02-26 09:58:51.410505: Current learning rate: 0.00046
2025-02-26 10:00:05.981573: train_loss -0.9426
2025-02-26 10:00:05.981999: val_loss -0.7376
2025-02-26 10:00:05.982090: Pseudo dice [0.7904]
2025-02-26 10:00:05.982197: Epoch time: 74.57 s
2025-02-26 10:00:07.643703: 
2025-02-26 10:00:07.643999: Epoch 968
2025-02-26 10:00:07.644150: Current learning rate: 0.00045
2025-02-26 10:01:24.933942: train_loss -0.9416
2025-02-26 10:01:24.934362: val_loss -0.7311
2025-02-26 10:01:24.934455: Pseudo dice [0.791]
2025-02-26 10:01:24.934561: Epoch time: 77.29 s
2025-02-26 10:01:26.323844: 
2025-02-26 10:01:26.324072: Epoch 969
2025-02-26 10:01:26.324273: Current learning rate: 0.00044
2025-02-26 10:02:42.698597: train_loss -0.942
2025-02-26 10:02:42.699036: val_loss -0.7274
2025-02-26 10:02:42.699126: Pseudo dice [0.7926]
2025-02-26 10:02:42.699231: Epoch time: 76.38 s
2025-02-26 10:02:44.176977: 
2025-02-26 10:02:44.177205: Epoch 970
2025-02-26 10:02:44.177346: Current learning rate: 0.00043
2025-02-26 10:04:01.344370: train_loss -0.9347
2025-02-26 10:04:01.344941: val_loss -0.7134
2025-02-26 10:04:01.345026: Pseudo dice [0.7755]
2025-02-26 10:04:01.345131: Epoch time: 77.17 s
2025-02-26 10:04:02.714841: 
2025-02-26 10:04:02.715073: Epoch 971
2025-02-26 10:04:02.715209: Current learning rate: 0.00041
2025-02-26 10:05:23.660699: train_loss -0.9372
2025-02-26 10:05:23.661116: val_loss -0.7356
2025-02-26 10:05:23.661237: Pseudo dice [0.7956]
2025-02-26 10:05:23.661375: Epoch time: 80.95 s
2025-02-26 10:05:25.006680: 
2025-02-26 10:05:25.006887: Epoch 972
2025-02-26 10:05:25.007012: Current learning rate: 0.0004
2025-02-26 10:06:44.187516: train_loss -0.9366
2025-02-26 10:06:44.187919: val_loss -0.7368
2025-02-26 10:06:44.188003: Pseudo dice [0.8013]
2025-02-26 10:06:44.188105: Epoch time: 79.18 s
2025-02-26 10:06:45.688845: 
2025-02-26 10:06:45.689065: Epoch 973
2025-02-26 10:06:45.689188: Current learning rate: 0.00039
2025-02-26 10:08:05.466377: train_loss -0.9323
2025-02-26 10:08:05.466691: val_loss -0.7242
2025-02-26 10:08:05.466776: Pseudo dice [0.7899]
2025-02-26 10:08:05.466875: Epoch time: 79.78 s
2025-02-26 10:08:06.881869: 
2025-02-26 10:08:06.882125: Epoch 974
2025-02-26 10:08:06.882252: Current learning rate: 0.00037
2025-02-26 10:09:26.834840: train_loss -0.9432
2025-02-26 10:09:26.835254: val_loss -0.7274
2025-02-26 10:09:26.835372: Pseudo dice [0.7879]
2025-02-26 10:09:26.835493: Epoch time: 79.95 s
2025-02-26 10:09:28.600097: 
2025-02-26 10:09:28.600331: Epoch 975
2025-02-26 10:09:28.600452: Current learning rate: 0.00036
2025-02-26 10:10:38.989048: train_loss -0.9433
2025-02-26 10:10:38.989489: val_loss -0.7316
2025-02-26 10:10:38.989596: Pseudo dice [0.7954]
2025-02-26 10:10:38.989721: Epoch time: 70.39 s
2025-02-26 10:10:40.356555: 
2025-02-26 10:10:40.356756: Epoch 976
2025-02-26 10:10:40.356883: Current learning rate: 0.00035
2025-02-26 10:11:46.771385: train_loss -0.9366
2025-02-26 10:11:46.771836: val_loss -0.7396
2025-02-26 10:11:46.771929: Pseudo dice [0.7952]
2025-02-26 10:11:46.772047: Epoch time: 66.42 s
2025-02-26 10:11:48.112888: 
2025-02-26 10:11:48.113108: Epoch 977
2025-02-26 10:11:48.113235: Current learning rate: 0.00034
2025-02-26 10:12:52.488772: train_loss -0.9436
2025-02-26 10:12:52.489198: val_loss -0.7222
2025-02-26 10:12:52.489293: Pseudo dice [0.7788]
2025-02-26 10:12:52.489422: Epoch time: 64.38 s
2025-02-26 10:12:53.819111: 
2025-02-26 10:12:53.819339: Epoch 978
2025-02-26 10:12:53.819468: Current learning rate: 0.00032
2025-02-26 10:14:05.665990: train_loss -0.9454
2025-02-26 10:14:05.666466: val_loss -0.7258
2025-02-26 10:14:05.666564: Pseudo dice [0.7857]
2025-02-26 10:14:05.666681: Epoch time: 71.85 s
2025-02-26 10:14:07.016041: 
2025-02-26 10:14:07.016265: Epoch 979
2025-02-26 10:14:07.016405: Current learning rate: 0.00031
2025-02-26 10:15:13.634042: train_loss -0.9443
2025-02-26 10:15:13.634420: val_loss -0.7427
2025-02-26 10:15:13.634509: Pseudo dice [0.8016]
2025-02-26 10:15:13.634611: Epoch time: 66.62 s
2025-02-26 10:15:14.963342: 
2025-02-26 10:15:14.963553: Epoch 980
2025-02-26 10:15:14.963678: Current learning rate: 0.0003
2025-02-26 10:16:22.210687: train_loss -0.9464
2025-02-26 10:16:22.211204: val_loss -0.7299
2025-02-26 10:16:22.211315: Pseudo dice [0.7872]
2025-02-26 10:16:22.211459: Epoch time: 67.25 s
2025-02-26 10:16:23.523557: 
2025-02-26 10:16:23.523779: Epoch 981
2025-02-26 10:16:23.523911: Current learning rate: 0.00028
2025-02-26 10:17:29.822356: train_loss -0.9446
2025-02-26 10:17:29.823151: val_loss -0.7376
2025-02-26 10:17:29.823260: Pseudo dice [0.7998]
2025-02-26 10:17:29.823402: Epoch time: 66.3 s
2025-02-26 10:17:31.118194: 
2025-02-26 10:17:31.118456: Epoch 982
2025-02-26 10:17:31.118586: Current learning rate: 0.00027
2025-02-26 10:18:43.920542: train_loss -0.9385
2025-02-26 10:18:43.920958: val_loss -0.7295
2025-02-26 10:18:43.921049: Pseudo dice [0.787]
2025-02-26 10:18:43.921160: Epoch time: 72.8 s
2025-02-26 10:18:45.312119: 
2025-02-26 10:18:45.312369: Epoch 983
2025-02-26 10:18:45.312518: Current learning rate: 0.00026
2025-02-26 10:19:53.754664: train_loss -0.9426
2025-02-26 10:19:53.755048: val_loss -0.7366
2025-02-26 10:19:53.755129: Pseudo dice [0.8014]
2025-02-26 10:19:53.755224: Epoch time: 68.44 s
2025-02-26 10:19:55.059905: 
2025-02-26 10:19:55.060114: Epoch 984
2025-02-26 10:19:55.060231: Current learning rate: 0.00024
2025-02-26 10:21:04.364304: train_loss -0.9354
2025-02-26 10:21:04.364807: val_loss -0.7281
2025-02-26 10:21:04.364897: Pseudo dice [0.791]
2025-02-26 10:21:04.365012: Epoch time: 69.31 s
2025-02-26 10:21:05.752750: 
2025-02-26 10:21:05.752952: Epoch 985
2025-02-26 10:21:05.753073: Current learning rate: 0.00023
2025-02-26 10:22:24.588954: train_loss -0.9462
2025-02-26 10:22:24.589378: val_loss -0.7406
2025-02-26 10:22:24.589477: Pseudo dice [0.7986]
2025-02-26 10:22:24.589587: Epoch time: 78.84 s
2025-02-26 10:22:26.013443: 
2025-02-26 10:22:26.013663: Epoch 986
2025-02-26 10:22:26.013785: Current learning rate: 0.00021
2025-02-26 10:23:42.719561: train_loss -0.9402
2025-02-26 10:23:42.719957: val_loss -0.7416
2025-02-26 10:23:42.720045: Pseudo dice [0.7986]
2025-02-26 10:23:42.720149: Epoch time: 76.71 s
2025-02-26 10:23:44.482224: 
2025-02-26 10:23:44.482496: Epoch 987
2025-02-26 10:23:44.482625: Current learning rate: 0.0002
2025-02-26 10:24:56.629183: train_loss -0.9354
2025-02-26 10:24:56.629608: val_loss -0.7412
2025-02-26 10:24:56.629691: Pseudo dice [0.7984]
2025-02-26 10:24:56.629796: Epoch time: 72.15 s
2025-02-26 10:24:58.006924: 
2025-02-26 10:24:58.007151: Epoch 988
2025-02-26 10:24:58.007279: Current learning rate: 0.00019
2025-02-26 10:26:12.276191: train_loss -0.9431
2025-02-26 10:26:12.276539: val_loss -0.7251
2025-02-26 10:26:12.276608: Pseudo dice [0.7884]
2025-02-26 10:26:12.276690: Epoch time: 74.27 s
2025-02-26 10:26:13.646281: 
2025-02-26 10:26:13.646495: Epoch 989
2025-02-26 10:26:13.646616: Current learning rate: 0.00017
2025-02-26 10:27:28.576621: train_loss -0.9424
2025-02-26 10:27:28.576963: val_loss -0.7386
2025-02-26 10:27:28.577061: Pseudo dice [0.7979]
2025-02-26 10:27:28.577172: Epoch time: 74.93 s
2025-02-26 10:27:29.953409: 
2025-02-26 10:27:29.953624: Epoch 990
2025-02-26 10:27:29.953748: Current learning rate: 0.00016
2025-02-26 10:28:41.708144: train_loss -0.9502
2025-02-26 10:28:41.708625: val_loss -0.7185
2025-02-26 10:28:41.708708: Pseudo dice [0.7897]
2025-02-26 10:28:41.708811: Epoch time: 71.76 s
2025-02-26 10:28:43.058453: 
2025-02-26 10:28:43.058657: Epoch 991
2025-02-26 10:28:43.058782: Current learning rate: 0.00014
2025-02-26 10:29:59.232586: train_loss -0.9447
2025-02-26 10:29:59.232980: val_loss -0.7383
2025-02-26 10:29:59.233065: Pseudo dice [0.7969]
2025-02-26 10:29:59.233170: Epoch time: 76.18 s
2025-02-26 10:30:00.704169: 
2025-02-26 10:30:00.704431: Epoch 992
2025-02-26 10:30:00.704557: Current learning rate: 0.00013
2025-02-26 10:31:14.936184: train_loss -0.9497
2025-02-26 10:31:14.936626: val_loss -0.725
2025-02-26 10:31:14.937143: Pseudo dice [0.7893]
2025-02-26 10:31:14.937256: Epoch time: 74.23 s
2025-02-26 10:31:16.331958: 
2025-02-26 10:31:16.332169: Epoch 993
2025-02-26 10:31:16.332317: Current learning rate: 0.00011
2025-02-26 10:32:30.651829: train_loss -0.941
2025-02-26 10:32:30.652254: val_loss -0.7226
2025-02-26 10:32:30.652364: Pseudo dice [0.7818]
2025-02-26 10:32:30.652480: Epoch time: 74.32 s
2025-02-26 10:32:31.987504: 
2025-02-26 10:32:31.987721: Epoch 994
2025-02-26 10:32:31.987845: Current learning rate: 0.0001
2025-02-26 10:33:49.279813: train_loss -0.932
2025-02-26 10:33:49.280326: val_loss -0.7217
2025-02-26 10:33:49.280430: Pseudo dice [0.7806]
2025-02-26 10:33:49.280549: Epoch time: 77.29 s
2025-02-26 10:33:50.642945: 
2025-02-26 10:33:50.643151: Epoch 995
2025-02-26 10:33:50.643268: Current learning rate: 8e-05
2025-02-26 10:35:10.227599: train_loss -0.942
2025-02-26 10:35:10.228026: val_loss -0.7286
2025-02-26 10:35:10.228111: Pseudo dice [0.7882]
2025-02-26 10:35:10.228216: Epoch time: 79.59 s
2025-02-26 10:35:11.636443: 
2025-02-26 10:35:11.636678: Epoch 996
2025-02-26 10:35:11.636810: Current learning rate: 7e-05
2025-02-26 10:36:30.122866: train_loss -0.9452
2025-02-26 10:36:30.123251: val_loss -0.7365
2025-02-26 10:36:30.123357: Pseudo dice [0.7945]
2025-02-26 10:36:30.123462: Epoch time: 78.49 s
2025-02-26 10:36:31.587497: 
2025-02-26 10:36:31.587728: Epoch 997
2025-02-26 10:36:31.587879: Current learning rate: 5e-05
2025-02-26 10:37:46.526884: train_loss -0.9471
2025-02-26 10:37:46.527319: val_loss -0.739
2025-02-26 10:37:46.527412: Pseudo dice [0.8027]
2025-02-26 10:37:46.527514: Epoch time: 74.94 s
2025-02-26 10:37:47.910375: 
2025-02-26 10:37:47.910588: Epoch 998
2025-02-26 10:37:47.910712: Current learning rate: 4e-05
2025-02-26 10:39:05.103395: train_loss -0.9509
2025-02-26 10:39:05.103774: val_loss -0.7303
2025-02-26 10:39:05.103855: Pseudo dice [0.7913]
2025-02-26 10:39:05.103956: Epoch time: 77.19 s
2025-02-26 10:39:06.944585: 
2025-02-26 10:39:06.944808: Epoch 999
2025-02-26 10:39:06.944942: Current learning rate: 2e-05
2025-02-26 10:40:21.417858: train_loss -0.9418
2025-02-26 10:40:21.418334: val_loss -0.7258
2025-02-26 10:40:21.418442: Pseudo dice [0.796]
2025-02-26 10:40:21.418557: Epoch time: 74.47 s
2025-02-26 10:40:23.382110: Training done.
2025-02-26 10:40:23.605534: Using splits from existing split file: /home/rth/jdekok/my-scratch/nnunetv2/nnUNet/nnUNet_preprocessed/Dataset520_NeckTumour/splits_final.json
2025-02-26 10:40:23.619507: The split file contains 5 splits.
2025-02-26 10:40:23.619661: Desired fold for training: 0
2025-02-26 10:40:23.619719: This split has 62 training and 16 validation cases.
2025-02-26 10:40:23.619997: predicting 002
2025-02-26 10:40:23.621262: 002, shape torch.Size([6, 29, 515, 560]), rank 0
2025-02-26 10:40:41.200984: predicting 004
2025-02-26 10:40:41.213289: 004, shape torch.Size([6, 29, 511, 560]), rank 0
2025-02-26 10:40:46.182025: predicting 006
2025-02-26 10:40:46.193566: 006, shape torch.Size([6, 29, 510, 560]), rank 0
2025-02-26 10:40:51.229784: predicting 013
2025-02-26 10:40:51.242091: 013, shape torch.Size([6, 29, 510, 560]), rank 0
2025-02-26 10:40:56.319745: predicting 020
2025-02-26 10:40:56.331439: 020, shape torch.Size([6, 29, 518, 559]), rank 0
2025-02-26 10:41:01.536850: predicting 021
2025-02-26 10:41:01.548188: 021, shape torch.Size([6, 29, 515, 560]), rank 0
2025-02-26 10:41:06.403395: predicting 025
2025-02-26 10:41:06.414514: 025, shape torch.Size([6, 29, 507, 559]), rank 0
2025-02-26 10:41:11.278886: predicting 030
2025-02-26 10:41:11.290101: 030, shape torch.Size([6, 29, 509, 558]), rank 0
2025-02-26 10:41:16.154538: predicting 035
2025-02-26 10:41:16.165497: 035, shape torch.Size([6, 29, 532, 560]), rank 0
2025-02-26 10:41:21.025138: predicting 042
2025-02-26 10:41:21.038145: 042, shape torch.Size([6, 29, 524, 560]), rank 0
2025-02-26 10:41:25.982275: predicting 049
2025-02-26 10:41:25.996103: 049, shape torch.Size([6, 29, 520, 560]), rank 0
2025-02-26 10:41:31.113032: predicting 051
2025-02-26 10:41:31.124887: 051, shape torch.Size([6, 29, 550, 560]), rank 0
2025-02-26 10:41:35.982060: predicting 058
2025-02-26 10:41:35.993895: 058, shape torch.Size([6, 29, 521, 558]), rank 0
2025-02-26 10:41:40.859961: predicting 061
2025-02-26 10:41:40.871791: 061, shape torch.Size([6, 29, 508, 558]), rank 0
2025-02-26 10:41:45.748174: predicting 066
2025-02-26 10:41:45.759610: 066, shape torch.Size([6, 29, 522, 560]), rank 0
2025-02-26 10:41:50.617970: predicting 071
2025-02-26 10:41:50.631416: 071, shape torch.Size([6, 29, 534, 558]), rank 0
2025-02-26 10:42:51.324845: Validation complete
2025-02-26 10:42:51.324951: Mean Validation Dice:  0.7811483832602584

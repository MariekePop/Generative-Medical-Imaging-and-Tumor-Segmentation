────────  predicting Task641_allBlack  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:01,  1.75s/it] 19%|█▉        | 7/36 [00:01<00:05,  5.01it/s] 31%|███       | 11/36 [00:01<00:03,  8.32it/s] 42%|████▏     | 15/36 [00:02<00:01, 11.63it/s] 53%|█████▎    | 19/36 [00:02<00:01, 14.87it/s] 64%|██████▍   | 23/36 [00:02<00:00, 17.90it/s] 75%|███████▌  | 27/36 [00:02<00:00, 20.54it/s] 86%|████████▌ | 31/36 [00:02<00:00, 22.71it/s] 94%|█████████▍| 34/36 [00:02<00:00, 23.63it/s]100%|██████████| 36/36 [00:02<00:00, 12.76it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 48.43it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.93it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.30it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.15it/s] 64%|██████▍   | 23/36 [00:00<00:00, 30.97it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.26it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.69it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 32.23it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 57.23it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.16it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.03it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.66it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.90it/s] 81%|████████  | 29/36 [00:00<00:00, 30.96it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.73it/s]100%|██████████| 36/36 [00:01<00:00, 32.40it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.24it/s] 33%|███▎      | 12/36 [00:00<00:00, 33.64it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.34it/s] 56%|█████▌    | 20/36 [00:00<00:00, 30.90it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.77it/s] 78%|███████▊  | 28/36 [00:00<00:00, 29.91it/s] 89%|████████▉ | 32/36 [00:01<00:00, 29.57it/s]100%|██████████| 36/36 [00:01<00:00, 30.13it/s]100%|██████████| 36/36 [00:01<00:00, 31.37it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.11it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.03it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.97it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.32it/s] 69%|██████▉   | 25/36 [00:00<00:00, 29.79it/s] 81%|████████  | 29/36 [00:00<00:00, 30.43it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.89it/s]100%|██████████| 36/36 [00:01<00:00, 31.96it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 57.10it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.74it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.30it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.19it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.59it/s] 81%|████████  | 29/36 [00:00<00:00, 30.50it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.50it/s]100%|██████████| 36/36 [00:01<00:00, 32.03it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.00it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.35it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.22it/s] 56%|█████▌    | 20/36 [00:00<00:00, 33.19it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.86it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.24it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.20it/s]100%|██████████| 36/36 [00:01<00:00, 30.54it/s]100%|██████████| 36/36 [00:01<00:00, 32.30it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 56.48it/s] 33%|███▎      | 12/36 [00:00<00:00, 35.47it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.81it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.17it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.14it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.59it/s] 89%|████████▉ | 32/36 [00:01<00:00, 29.89it/s]100%|██████████| 36/36 [00:01<00:00, 29.76it/s]100%|██████████| 36/36 [00:01<00:00, 31.59it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.57it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.49it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.17it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.87it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.64it/s] 81%|████████  | 29/36 [00:00<00:00, 30.42it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.62it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 41.50it/s] 28%|██▊       | 10/36 [00:00<00:00, 40.88it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.71it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.05it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.27it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.31it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.08it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 32.19it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.30it/s] 28%|██▊       | 10/36 [00:00<00:00, 37.86it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.32it/s] 50%|█████     | 18/36 [00:00<00:00, 32.91it/s] 61%|██████    | 22/36 [00:00<00:00, 31.65it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.25it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.58it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.09it/s]100%|██████████| 36/36 [00:01<00:00, 31.75it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 53.32it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.74it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.36it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.33it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.94it/s] 81%|████████  | 29/36 [00:00<00:00, 30.38it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.71it/s]100%|██████████| 36/36 [00:01<00:00, 32.29it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.22it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.18it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.82it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.72it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.38it/s] 81%|████████  | 29/36 [00:00<00:00, 30.61it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.77it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.59it/s] 33%|███▎      | 12/36 [00:00<00:00, 35.74it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.23it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.87it/s] 67%|██████▋   | 24/36 [00:00<00:00, 26.99it/s] 81%|████████  | 29/36 [00:00<00:00, 31.68it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.97it/s]100%|██████████| 36/36 [00:01<00:00, 31.79it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.91it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.44it/s] 50%|█████     | 18/36 [00:00<00:00, 34.26it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.60it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.93it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.07it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.71it/s] 44%|████▍     | 16/36 [00:00<00:00, 35.03it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.85it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.43it/s] 78%|███████▊  | 28/36 [00:00<00:00, 31.01it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.52it/s]100%|██████████| 36/36 [00:01<00:00, 30.11it/s]100%|██████████| 36/36 [00:01<00:00, 32.26it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task641_allBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task641_allBlack  ────────
────────  evaluating  (post) Task641_allBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task642_T1Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:02,  1.77s/it] 17%|█▋        | 6/36 [00:01<00:07,  4.24it/s] 31%|███       | 11/36 [00:02<00:02,  8.40it/s] 42%|████▏     | 15/36 [00:02<00:01, 11.63it/s] 53%|█████▎    | 19/36 [00:02<00:01, 14.84it/s] 64%|██████▍   | 23/36 [00:02<00:00, 17.73it/s] 75%|███████▌  | 27/36 [00:02<00:00, 20.21it/s] 86%|████████▌ | 31/36 [00:02<00:00, 22.81it/s] 97%|█████████▋| 35/36 [00:02<00:00, 24.54it/s]100%|██████████| 36/36 [00:02<00:00, 12.61it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 59.10it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.57it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.41it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.10it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.87it/s] 81%|████████  | 29/36 [00:00<00:00, 31.07it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.58it/s]100%|██████████| 36/36 [00:01<00:00, 32.48it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 59.06it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.09it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.11it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.53it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.96it/s]100%|██████████| 27/27 [00:00<00:00, 33.89it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.63it/s] 33%|███▎      | 9/27 [00:00<00:00, 41.39it/s] 52%|█████▏    | 14/27 [00:00<00:00, 35.25it/s] 67%|██████▋   | 18/27 [00:00<00:00, 31.93it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.29it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.18it/s]100%|██████████| 27/27 [00:00<00:00, 32.48it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.48it/s] 36%|███▌      | 13/36 [00:00<00:00, 34.09it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.91it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.32it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.10it/s] 81%|████████  | 29/36 [00:00<00:00, 30.82it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 31.79it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 57.69it/s] 44%|████▍     | 12/27 [00:00<00:00, 39.40it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.60it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.77it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.66it/s]100%|██████████| 27/27 [00:00<00:00, 33.81it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.27it/s] 28%|██▊       | 10/36 [00:00<00:00, 40.79it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.85it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.54it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.12it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.21it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.09it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.60it/s]100%|██████████| 36/36 [00:01<00:00, 31.77it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.37it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.66it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.26it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.14it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.20it/s] 81%|████████  | 29/36 [00:00<00:00, 30.43it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 31.50it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.85it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.59it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.25it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.67it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.78it/s] 81%|████████  | 29/36 [00:00<00:00, 30.18it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.82it/s]100%|██████████| 36/36 [00:01<00:00, 32.35it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.86it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.37it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.11it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.06it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.48it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.16it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 29.63it/s]100%|██████████| 36/36 [00:01<00:00, 31.80it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 50.42it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.33it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.22it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.29it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.52it/s] 81%|████████  | 29/36 [00:00<00:00, 30.86it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.02it/s]100%|██████████| 36/36 [00:01<00:00, 32.33it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 54.95it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.37it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.25it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.65it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.60it/s]100%|██████████| 27/27 [00:00<00:00, 33.87it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.72it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.57it/s] 50%|█████     | 18/36 [00:00<00:00, 34.18it/s] 61%|██████    | 22/36 [00:00<00:00, 32.14it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.66it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.63it/s]100%|██████████| 36/36 [00:01<00:00, 32.39it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.01it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.14it/s] 61%|██████    | 22/36 [00:00<00:00, 32.54it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.67it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.23it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.09it/s] 50%|█████     | 18/36 [00:00<00:00, 34.14it/s] 61%|██████    | 22/36 [00:00<00:00, 32.55it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.68it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 49.81it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.48it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.25it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.45it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.18it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.74it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.67it/s]100%|██████████| 36/36 [00:01<00:00, 30.08it/s]100%|██████████| 36/36 [00:01<00:00, 32.24it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task642_T1Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task642_T1Black  ────────
────────  evaluating  (post) Task642_T1Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task643_T1CBlack  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:02,  1.78s/it] 19%|█▉        | 7/36 [00:01<00:05,  4.93it/s] 31%|███       | 11/36 [00:02<00:03,  8.11it/s] 42%|████▏     | 15/36 [00:02<00:01, 11.36it/s] 53%|█████▎    | 19/36 [00:02<00:01, 14.65it/s] 64%|██████▍   | 23/36 [00:02<00:00, 17.50it/s] 75%|███████▌  | 27/36 [00:02<00:00, 20.08it/s] 86%|████████▌ | 31/36 [00:02<00:00, 22.70it/s] 97%|█████████▋| 35/36 [00:02<00:00, 24.26it/s]100%|██████████| 36/36 [00:02<00:00, 12.59it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.23it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.53it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.19it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.03it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.63it/s] 81%|████████  | 29/36 [00:00<00:00, 30.30it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.48it/s]100%|██████████| 36/36 [00:01<00:00, 32.14it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 58.79it/s] 44%|████▍     | 12/27 [00:00<00:00, 24.10it/s] 63%|██████▎   | 17/27 [00:00<00:00, 29.49it/s] 78%|███████▊  | 21/27 [00:00<00:00, 29.33it/s] 93%|█████████▎| 25/27 [00:00<00:00, 29.73it/s]100%|██████████| 27/27 [00:00<00:00, 29.59it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 49.42it/s] 37%|███▋      | 10/27 [00:00<00:00, 37.37it/s] 52%|█████▏    | 14/27 [00:00<00:00, 33.93it/s] 67%|██████▋   | 18/27 [00:00<00:00, 32.17it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.33it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.08it/s]100%|██████████| 27/27 [00:00<00:00, 32.17it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 39.36it/s] 25%|██▌       | 9/36 [00:00<00:00, 42.59it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.40it/s] 50%|█████     | 18/36 [00:00<00:00, 32.80it/s] 61%|██████    | 22/36 [00:00<00:00, 31.55it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.60it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.03it/s]100%|██████████| 36/36 [00:01<00:00, 32.09it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 27.59it/s] 26%|██▌       | 7/27 [00:00<00:00, 33.11it/s] 41%|████      | 11/27 [00:00<00:00, 34.87it/s] 56%|█████▌    | 15/27 [00:00<00:00, 32.00it/s] 70%|███████   | 19/27 [00:00<00:00, 30.51it/s] 85%|████████▌ | 23/27 [00:00<00:00, 32.55it/s]100%|██████████| 27/27 [00:00<00:00, 31.17it/s]100%|██████████| 27/27 [00:00<00:00, 31.64it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.18it/s] 33%|███▎      | 12/36 [00:00<00:00, 33.85it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.91it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.93it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.32it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.70it/s] 89%|████████▉ | 32/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 29.42it/s]100%|██████████| 36/36 [00:01<00:00, 31.31it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 52.81it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.26it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.05it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.46it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.13it/s] 81%|████████  | 29/36 [00:00<00:00, 30.91it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.04it/s]100%|██████████| 36/36 [00:01<00:00, 31.97it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 39.61it/s] 25%|██▌       | 9/36 [00:00<00:00, 39.80it/s] 36%|███▌      | 13/36 [00:00<00:00, 32.38it/s] 47%|████▋     | 17/36 [00:00<00:00, 30.85it/s] 61%|██████    | 22/36 [00:00<00:00, 31.16it/s] 72%|███████▏  | 26/36 [00:00<00:00, 32.87it/s] 83%|████████▎ | 30/36 [00:00<00:00, 29.50it/s] 94%|█████████▍| 34/36 [00:01<00:00, 31.17it/s]100%|██████████| 36/36 [00:01<00:00, 31.16it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 52.88it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.05it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.98it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.72it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.24it/s] 81%|████████  | 29/36 [00:00<00:00, 31.02it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.51it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 41.98it/s] 28%|██▊       | 10/36 [00:00<00:00, 42.38it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.57it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.48it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.06it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.45it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.87it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.02it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 32.04it/s] 30%|██▉       | 8/27 [00:00<00:00, 34.83it/s] 44%|████▍     | 12/27 [00:00<00:00, 35.47it/s] 59%|█████▉    | 16/27 [00:00<00:00, 35.53it/s] 74%|███████▍  | 20/27 [00:00<00:00, 31.96it/s] 89%|████████▉ | 24/27 [00:00<00:00, 29.43it/s]100%|██████████| 27/27 [00:00<00:00, 31.48it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.45it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.34it/s] 50%|█████     | 18/36 [00:00<00:00, 33.50it/s] 61%|██████    | 22/36 [00:00<00:00, 32.20it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.78it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.43it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.61it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.09it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 57.82it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.40it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.59it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.91it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.90it/s] 81%|████████  | 29/36 [00:00<00:00, 30.94it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.92it/s]100%|██████████| 36/36 [00:01<00:00, 32.45it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.26it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.91it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.95it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.34it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.35it/s] 81%|████████  | 29/36 [00:00<00:00, 30.73it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.35it/s]100%|██████████| 36/36 [00:01<00:00, 32.30it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task643_T1CBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task643_T1CBlack  ────────
────────  evaluating  (post) Task643_T1CBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task644_T2Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:02<01:19,  2.27s/it] 19%|█▉        | 7/36 [00:02<00:07,  3.95it/s] 31%|███       | 11/36 [00:02<00:03,  6.60it/s] 42%|████▏     | 15/36 [00:02<00:02,  9.54it/s] 53%|█████▎    | 19/36 [00:02<00:01, 12.67it/s] 64%|██████▍   | 23/36 [00:02<00:00, 15.53it/s] 72%|███████▏  | 26/36 [00:03<00:00, 17.82it/s] 83%|████████▎ | 30/36 [00:03<00:00, 20.77it/s] 94%|█████████▍| 34/36 [00:03<00:00, 23.00it/s]100%|██████████| 36/36 [00:03<00:00, 10.72it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.85it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.62it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.71it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.50it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.44it/s] 81%|████████  | 29/36 [00:00<00:00, 30.21it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 32.16it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 55.05it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.54it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.38it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.54it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.82it/s]100%|██████████| 27/27 [00:00<00:00, 33.13it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 58.32it/s] 44%|████▍     | 12/27 [00:00<00:00, 36.28it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.33it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.65it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.18it/s]100%|██████████| 27/27 [00:00<00:00, 32.92it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 54.19it/s] 33%|███▎      | 12/36 [00:00<00:00, 34.40it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.23it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.15it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.19it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.13it/s] 89%|████████▉ | 32/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 29.73it/s]100%|██████████| 36/36 [00:01<00:00, 31.52it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 47.61it/s] 37%|███▋      | 10/27 [00:00<00:00, 43.19it/s] 56%|█████▌    | 15/27 [00:00<00:00, 34.35it/s] 70%|███████   | 19/27 [00:00<00:00, 33.34it/s] 85%|████████▌ | 23/27 [00:00<00:00, 32.07it/s]100%|██████████| 27/27 [00:00<00:00, 30.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.10it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:13,  2.66it/s] 11%|█         | 4/36 [00:00<00:03, 10.16it/s] 19%|█▉        | 7/36 [00:00<00:01, 15.29it/s] 31%|███       | 11/36 [00:00<00:01, 19.92it/s] 42%|████▏     | 15/36 [00:00<00:00, 23.41it/s] 53%|█████▎    | 19/36 [00:00<00:00, 27.23it/s] 64%|██████▍   | 23/36 [00:01<00:00, 27.49it/s] 75%|███████▌  | 27/36 [00:01<00:00, 28.73it/s] 86%|████████▌ | 31/36 [00:01<00:00, 27.66it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.02it/s]100%|██████████| 36/36 [00:01<00:00, 23.67it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.12it/s] 36%|███▌      | 13/36 [00:00<00:00, 34.88it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.76it/s] 58%|█████▊    | 21/36 [00:00<00:00, 30.41it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.34it/s] 81%|████████  | 29/36 [00:00<00:00, 30.80it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.81it/s]100%|██████████| 36/36 [00:01<00:00, 31.66it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 57.18it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.08it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.53it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.85it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.91it/s] 81%|████████  | 29/36 [00:00<00:00, 31.10it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.62it/s]100%|██████████| 36/36 [00:01<00:00, 32.32it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 48.07it/s] 28%|██▊       | 10/36 [00:00<00:00, 42.66it/s] 42%|████▏     | 15/36 [00:00<00:00, 32.60it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.99it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.57it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.13it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.69it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.14it/s]100%|██████████| 36/36 [00:01<00:00, 32.32it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 47.19it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.52it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.15it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.16it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.14it/s] 78%|███████▊  | 28/36 [00:00<00:00, 29.92it/s] 89%|████████▉ | 32/36 [00:00<00:00, 29.98it/s]100%|██████████| 36/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 31.92it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 48.11it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.19it/s] 59%|█████▉    | 16/27 [00:00<00:00, 34.30it/s] 74%|███████▍  | 20/27 [00:00<00:00, 32.92it/s] 89%|████████▉ | 24/27 [00:00<00:00, 31.62it/s]100%|██████████| 27/27 [00:00<00:00, 33.37it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 39.50it/s] 22%|██▏       | 8/36 [00:00<00:00, 38.38it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.30it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.56it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.69it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.91it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.25it/s] 89%|████████▉ | 32/36 [00:01<00:00, 30.00it/s]100%|██████████| 36/36 [00:01<00:00, 30.09it/s]100%|██████████| 36/36 [00:01<00:00, 31.61it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.69it/s] 28%|██▊       | 10/36 [00:00<00:00, 38.05it/s] 39%|███▉      | 14/36 [00:00<00:00, 34.03it/s] 50%|█████     | 18/36 [00:00<00:00, 32.16it/s] 61%|██████    | 22/36 [00:00<00:00, 31.14it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.34it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.22it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.96it/s]100%|██████████| 36/36 [00:01<00:00, 31.62it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.54it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.81it/s] 50%|█████     | 18/36 [00:00<00:00, 33.93it/s] 61%|██████    | 22/36 [00:00<00:00, 32.39it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.38it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.75it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.31it/s]100%|██████████| 36/36 [00:01<00:00, 32.51it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.44it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.81it/s] 50%|█████     | 18/36 [00:00<00:00, 33.68it/s] 61%|██████    | 22/36 [00:00<00:00, 32.28it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.62it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.86it/s]100%|██████████| 36/36 [00:01<00:00, 32.51it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task644_T2Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task644_T2Black  ────────
────────  evaluating  (post) Task644_T2Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task645_STIRBlack  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:37,  1.43s/it] 30%|██▉       | 8/27 [00:01<00:02,  6.86it/s] 44%|████▍     | 12/27 [00:01<00:01, 10.18it/s] 59%|█████▉    | 16/27 [00:01<00:00, 13.54it/s] 74%|███████▍  | 20/27 [00:01<00:00, 16.71it/s] 89%|████████▉ | 24/27 [00:02<00:00, 19.53it/s]100%|██████████| 27/27 [00:02<00:00, 12.28it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.70it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.98it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.60it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.50it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.03it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 49.71it/s] 41%|████      | 11/27 [00:00<00:00, 38.25it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.35it/s] 70%|███████   | 19/27 [00:00<00:00, 32.06it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.99it/s]100%|██████████| 27/27 [00:00<00:00, 30.24it/s]100%|██████████| 27/27 [00:00<00:00, 32.81it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 51.24it/s] 48%|████▊     | 13/27 [00:00<00:00, 35.66it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.26it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.89it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.02it/s]100%|██████████| 27/27 [00:00<00:00, 32.84it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.71it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.87it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.07it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.48it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.51it/s]100%|██████████| 27/27 [00:00<00:00, 33.82it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.82it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.97it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.86it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.46it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.41it/s]100%|██████████| 27/27 [00:00<00:00, 33.82it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 53.46it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.93it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.96it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.33it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.34it/s]100%|██████████| 27/27 [00:00<00:00, 33.34it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.78it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.96it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.11it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.54it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.80it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.99it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.46it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.49it/s]100%|██████████| 27/27 [00:00<00:00, 33.82it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 51.51it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.30it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.60it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.12it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.23it/s]100%|██████████| 27/27 [00:00<00:00, 33.05it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.65it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.87it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.98it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.99it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.44it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.43it/s]100%|██████████| 27/27 [00:00<00:00, 33.82it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.13it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.52it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.06it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.18it/s] 81%|████████  | 29/36 [00:00<00:00, 30.62it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.26it/s]100%|██████████| 36/36 [00:01<00:00, 32.04it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.88it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.02it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.50it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.04it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.02it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 54.69it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.05it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.06it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.43it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.42it/s]100%|██████████| 27/27 [00:00<00:00, 33.45it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task645_STIRBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task645_STIRBlack  ────────
────────  evaluating  (post) Task645_STIRBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task646_DWIBlack  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:03<01:52,  3.20s/it] 22%|██▏       | 8/36 [00:03<00:08,  3.25it/s] 33%|███▎      | 12/36 [00:03<00:04,  5.26it/s] 44%|████▍     | 16/36 [00:03<00:02,  7.59it/s] 56%|█████▌    | 20/36 [00:03<00:01, 10.34it/s] 67%|██████▋   | 24/36 [00:03<00:00, 13.05it/s] 78%|███████▊  | 28/36 [00:04<00:00, 16.05it/s] 89%|████████▉ | 32/36 [00:04<00:00, 18.84it/s]100%|██████████| 36/36 [00:04<00:00, 21.08it/s]100%|██████████| 36/36 [00:04<00:00,  8.42it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.91it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 31.74it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.35it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.69it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.74it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 49.55it/s] 37%|███▋      | 10/27 [00:00<00:00, 40.24it/s] 56%|█████▌    | 15/27 [00:00<00:00, 34.72it/s] 70%|███████   | 19/27 [00:00<00:00, 32.32it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.70it/s]100%|██████████| 27/27 [00:00<00:00, 30.27it/s]100%|██████████| 27/27 [00:00<00:00, 32.71it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 34.97it/s] 33%|███▎      | 9/27 [00:00<00:00, 36.79it/s] 48%|████▊     | 13/27 [00:00<00:00, 33.47it/s] 63%|██████▎   | 17/27 [00:00<00:00, 31.85it/s] 78%|███████▊  | 21/27 [00:00<00:00, 30.98it/s] 93%|█████████▎| 25/27 [00:00<00:00, 29.79it/s]100%|██████████| 27/27 [00:00<00:00, 31.36it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 53.74it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.51it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.54it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.94it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.07it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.90it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.54it/s]100%|██████████| 36/36 [00:01<00:00, 30.33it/s]100%|██████████| 36/36 [00:01<00:00, 32.17it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 51.94it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.05it/s] 63%|██████▎   | 17/27 [00:00<00:00, 32.96it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.42it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.66it/s]100%|██████████| 27/27 [00:00<00:00, 33.16it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 48.51it/s] 28%|██▊       | 10/36 [00:00<00:00, 42.96it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.43it/s] 53%|█████▎    | 19/36 [00:00<00:00, 34.03it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.89it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.40it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.87it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 59.07it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.82it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.92it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.35it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.40it/s] 81%|████████  | 29/36 [00:00<00:00, 30.78it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 32.32it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.61it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.89it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.22it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.49it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.68it/s] 81%|████████  | 29/36 [00:00<00:00, 30.98it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.30it/s]100%|██████████| 36/36 [00:01<00:00, 32.50it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 40.38it/s] 31%|███       | 11/36 [00:00<00:00, 39.67it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.53it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.06it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.75it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.88it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.67it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 31.75it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 56.09it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.44it/s] 50%|█████     | 18/36 [00:00<00:00, 32.99it/s] 61%|██████    | 22/36 [00:00<00:00, 32.19it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.03it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.54it/s]100%|██████████| 36/36 [00:01<00:00, 32.48it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.44it/s] 44%|████▍     | 12/27 [00:00<00:00, 37.83it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.86it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.85it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.37it/s]100%|██████████| 27/27 [00:00<00:00, 33.32it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 44.41it/s] 28%|██▊       | 10/36 [00:00<00:00, 40.98it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.27it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.57it/s] 64%|██████▍   | 23/36 [00:00<00:00, 30.09it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.57it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.78it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.64it/s]100%|██████████| 36/36 [00:01<00:00, 32.07it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.49it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 27.77it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.96it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.00it/s] 61%|██████    | 22/36 [00:00<00:00, 32.56it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.55it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.25it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.15it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.19it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.78it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.15it/s] 78%|███████▊  | 28/36 [00:00<00:00, 28.53it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.96it/s]100%|██████████| 36/36 [00:01<00:00, 30.22it/s]100%|██████████| 36/36 [00:01<00:00, 31.85it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task646_DWIBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task646_DWIBlack  ────────
────────  evaluating  (post) Task646_DWIBlack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task647_ADCBLack  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:02<01:34,  2.69s/it] 19%|█▉        | 7/36 [00:02<00:08,  3.36it/s] 31%|███       | 11/36 [00:02<00:04,  5.74it/s] 42%|████▏     | 15/36 [00:03<00:02,  8.41it/s] 53%|█████▎    | 19/36 [00:03<00:01, 11.38it/s] 64%|██████▍   | 23/36 [00:03<00:00, 14.25it/s] 75%|███████▌  | 27/36 [00:03<00:00, 17.34it/s] 86%|████████▌ | 31/36 [00:03<00:00, 19.95it/s] 97%|█████████▋| 35/36 [00:03<00:00, 22.19it/s]100%|██████████| 36/36 [00:03<00:00,  9.55it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 57.49it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.09it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 31.87it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.10it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.13it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.06it/s]100%|██████████| 36/36 [00:01<00:00, 32.51it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.01it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.29it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.60it/s] 78%|███████▊  | 21/27 [00:00<00:00, 33.18it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.04it/s]100%|██████████| 27/27 [00:00<00:00, 33.45it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 55.97it/s] 44%|████▍     | 12/27 [00:00<00:00, 34.45it/s] 59%|█████▉    | 16/27 [00:00<00:00, 33.25it/s] 74%|███████▍  | 20/27 [00:00<00:00, 31.14it/s] 89%|████████▉ | 24/27 [00:00<00:00, 31.23it/s]100%|██████████| 27/27 [00:00<00:00, 32.53it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 52.69it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.70it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.24it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.10it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.49it/s] 81%|████████  | 29/36 [00:00<00:00, 30.26it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.70it/s]100%|██████████| 36/36 [00:01<00:00, 32.16it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.36it/s] 33%|███▎      | 9/27 [00:00<00:00, 36.08it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.02it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.44it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.92it/s] 93%|█████████▎| 25/27 [00:00<00:00, 29.93it/s]100%|██████████| 27/27 [00:00<00:00, 32.19it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.28it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.37it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.87it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.85it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.48it/s] 81%|████████  | 29/36 [00:00<00:00, 30.81it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 31.79it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.94it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.12it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.88it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.42it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.04it/s] 81%|████████  | 29/36 [00:00<00:00, 30.88it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.21it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 38.25it/s] 22%|██▏       | 8/36 [00:00<00:00, 35.03it/s] 39%|███▉      | 14/36 [00:00<00:00, 39.32it/s] 50%|█████     | 18/36 [00:00<00:00, 35.92it/s] 61%|██████    | 22/36 [00:00<00:00, 32.89it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.40it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.53it/s] 94%|█████████▍| 34/36 [00:01<00:00, 28.65it/s]100%|██████████| 36/36 [00:01<00:00, 32.40it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 56.06it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.07it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.49it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.73it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.60it/s] 81%|████████  | 29/36 [00:00<00:00, 30.89it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.38it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 49.93it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.09it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.72it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.19it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.91it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.36it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.77it/s]100%|██████████| 36/36 [00:01<00:00, 29.60it/s]100%|██████████| 36/36 [00:01<00:00, 32.01it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 42.75it/s] 37%|███▋      | 10/27 [00:00<00:00, 36.74it/s] 52%|█████▏    | 14/27 [00:00<00:00, 33.97it/s] 67%|██████▋   | 18/27 [00:00<00:00, 32.07it/s] 81%|████████▏ | 22/27 [00:00<00:00, 30.78it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.19it/s]100%|██████████| 27/27 [00:00<00:00, 32.14it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 56.21it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.36it/s] 50%|█████     | 18/36 [00:00<00:00, 33.78it/s] 61%|██████    | 22/36 [00:00<00:00, 32.28it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.32it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.75it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.33it/s]100%|██████████| 36/36 [00:01<00:00, 32.40it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.46it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.70it/s] 50%|█████     | 18/36 [00:00<00:00, 33.36it/s] 61%|██████    | 22/36 [00:00<00:00, 31.05it/s] 72%|███████▏  | 26/36 [00:00<00:00, 32.31it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.42it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.80it/s]100%|██████████| 36/36 [00:01<00:00, 32.35it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 56.36it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.51it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.39it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.73it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.85it/s] 81%|████████  | 29/36 [00:00<00:00, 31.03it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.85it/s]100%|██████████| 36/36 [00:01<00:00, 32.37it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.72it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.91it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.99it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.32it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.38it/s] 81%|████████  | 29/36 [00:00<00:00, 30.75it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.33it/s]100%|██████████| 36/36 [00:01<00:00, 32.29it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task647_ADCBLack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task647_ADCBLack  ────────
────────  evaluating  (post) Task647_ADCBLack  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task648_DWI_ADC_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:07,  1.92s/it] 22%|██▏       | 8/36 [00:02<00:05,  5.25it/s] 33%|███▎      | 12/36 [00:02<00:02,  8.12it/s] 44%|████▍     | 16/36 [00:02<00:01, 11.08it/s] 56%|█████▌    | 20/36 [00:02<00:01, 14.23it/s] 67%|██████▋   | 24/36 [00:02<00:00, 16.88it/s] 78%|███████▊  | 28/36 [00:02<00:00, 20.20it/s] 89%|████████▉ | 32/36 [00:02<00:00, 22.43it/s]100%|██████████| 36/36 [00:02<00:00, 24.21it/s]100%|██████████| 36/36 [00:02<00:00, 12.05it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.82it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.70it/s] 50%|█████     | 18/36 [00:00<00:00, 33.91it/s] 61%|██████    | 22/36 [00:00<00:00, 31.91it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.83it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.26it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.95it/s]100%|██████████| 36/36 [00:01<00:00, 32.67it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 52.98it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.56it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.56it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.91it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.76it/s]100%|██████████| 27/27 [00:00<00:00, 33.20it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.48it/s] 44%|████▍     | 12/27 [00:00<00:00, 36.00it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.00it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.06it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.94it/s]100%|██████████| 27/27 [00:00<00:00, 32.75it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 37.48it/s] 28%|██▊       | 10/36 [00:00<00:00, 39.82it/s] 39%|███▉      | 14/36 [00:00<00:00, 37.35it/s] 50%|█████     | 18/36 [00:00<00:00, 33.11it/s] 61%|██████    | 22/36 [00:00<00:00, 31.88it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.39it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.61it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.17it/s]100%|██████████| 36/36 [00:01<00:00, 31.83it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 41.25it/s] 37%|███▋      | 10/27 [00:00<00:00, 40.71it/s] 56%|█████▌    | 15/27 [00:00<00:00, 36.07it/s] 70%|███████   | 19/27 [00:00<00:00, 33.03it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.60it/s]100%|██████████| 27/27 [00:00<00:00, 30.59it/s]100%|██████████| 27/27 [00:00<00:00, 32.89it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 48.10it/s] 31%|███       | 11/36 [00:00<00:00, 36.57it/s] 42%|████▏     | 15/36 [00:00<00:00, 33.71it/s] 53%|█████▎    | 19/36 [00:00<00:00, 31.73it/s] 64%|██████▍   | 23/36 [00:00<00:00, 30.82it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.72it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.65it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.20it/s]100%|██████████| 36/36 [00:01<00:00, 31.45it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.13it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.59it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.96it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.86it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.88it/s] 81%|████████  | 29/36 [00:00<00:00, 31.08it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.33it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:01, 29.16it/s] 22%|██▏       | 8/36 [00:00<00:00, 31.74it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.71it/s] 47%|████▋     | 17/36 [00:00<00:00, 29.00it/s] 58%|█████▊    | 21/36 [00:00<00:00, 29.12it/s] 69%|██████▉   | 25/36 [00:00<00:00, 29.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 33.57it/s] 94%|█████████▍| 34/36 [00:01<00:00, 32.64it/s]100%|██████████| 36/36 [00:01<00:00, 31.72it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 49.93it/s] 31%|███       | 11/36 [00:00<00:00, 37.35it/s] 42%|████▏     | 15/36 [00:00<00:00, 33.23it/s] 53%|█████▎    | 19/36 [00:00<00:00, 31.50it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.58it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.87it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.88it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.67it/s]100%|██████████| 36/36 [00:01<00:00, 31.86it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 59.95it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.09it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.75it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.89it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.36it/s] 81%|████████  | 29/36 [00:00<00:00, 30.35it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.79it/s]100%|██████████| 36/36 [00:01<00:00, 32.40it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 34.90it/s] 33%|███▎      | 9/27 [00:00<00:00, 42.29it/s] 52%|█████▏    | 14/27 [00:00<00:00, 35.76it/s] 67%|██████▋   | 18/27 [00:00<00:00, 32.64it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.07it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.33it/s]100%|██████████| 27/27 [00:00<00:00, 32.74it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.43it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.92it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.99it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.34it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.36it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.35it/s]100%|██████████| 36/36 [00:01<00:00, 32.29it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.97it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.03it/s] 50%|█████     | 18/36 [00:00<00:00, 34.11it/s] 61%|██████    | 22/36 [00:00<00:00, 32.54it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.97it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.90it/s] 50%|█████     | 18/36 [00:00<00:00, 34.15it/s] 61%|██████    | 22/36 [00:00<00:00, 32.02it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.67it/s] 83%|████████▎ | 30/36 [00:00<00:00, 29.29it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.56it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.27it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.35it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.15it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.83it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.44it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 31.91it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task648_DWI_ADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task648_DWI_ADC_Black  ────────
────────  evaluating  (post) Task648_DWI_ADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task651_30T2_30STIR_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:02<01:14,  2.13s/it] 22%|██▏       | 8/36 [00:02<00:05,  4.75it/s] 33%|███▎      | 12/36 [00:02<00:03,  7.44it/s] 44%|████▍     | 16/36 [00:02<00:01, 10.33it/s] 56%|█████▌    | 20/36 [00:02<00:01, 13.48it/s] 67%|██████▋   | 24/36 [00:02<00:00, 16.33it/s] 78%|███████▊  | 28/36 [00:02<00:00, 19.22it/s] 89%|████████▉ | 32/36 [00:03<00:00, 21.31it/s]100%|██████████| 36/36 [00:03<00:00, 23.40it/s]100%|██████████| 36/36 [00:03<00:00, 11.23it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 24.86it/s] 30%|██▉       | 8/27 [00:00<00:00, 34.69it/s] 44%|████▍     | 12/27 [00:00<00:00, 35.74it/s] 59%|█████▉    | 16/27 [00:00<00:00, 33.32it/s] 74%|███████▍  | 20/27 [00:00<00:00, 31.84it/s] 89%|████████▉ | 24/27 [00:00<00:00, 30.07it/s]100%|██████████| 27/27 [00:00<00:00, 31.65it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.96it/s] 33%|███▎      | 9/27 [00:00<00:00, 39.07it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.38it/s] 63%|██████▎   | 17/27 [00:00<00:00, 35.08it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.76it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.90it/s]100%|██████████| 27/27 [00:00<00:00, 33.18it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 42.60it/s] 41%|████      | 11/27 [00:00<00:00, 35.08it/s] 56%|█████▌    | 15/27 [00:00<00:00, 32.83it/s] 70%|███████   | 19/27 [00:00<00:00, 31.55it/s] 85%|████████▌ | 23/27 [00:00<00:00, 30.03it/s]100%|██████████| 27/27 [00:00<00:00, 29.37it/s]100%|██████████| 27/27 [00:00<00:00, 31.27it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 41.51it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.65it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.62it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.24it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.88it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.49it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.94it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.16it/s]100%|██████████| 36/36 [00:01<00:00, 31.93it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  7%|▋         | 2/27 [00:00<00:01, 18.96it/s] 26%|██▌       | 7/27 [00:00<00:00, 34.56it/s] 41%|████      | 11/27 [00:00<00:00, 36.85it/s] 56%|█████▌    | 15/27 [00:00<00:00, 34.49it/s] 70%|███████   | 19/27 [00:00<00:00, 32.18it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.80it/s]100%|██████████| 27/27 [00:00<00:00, 31.28it/s]100%|██████████| 27/27 [00:00<00:00, 31.98it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 47.46it/s] 28%|██▊       | 10/36 [00:00<00:00, 36.73it/s] 39%|███▉      | 14/36 [00:00<00:00, 33.96it/s] 50%|█████     | 18/36 [00:00<00:00, 32.15it/s] 61%|██████    | 22/36 [00:00<00:00, 31.17it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.23it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.06it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.13it/s]100%|██████████| 36/36 [00:01<00:00, 31.55it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 56.12it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.95it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.37it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.58it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.73it/s]100%|██████████| 27/27 [00:00<00:00, 33.79it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 34.15it/s] 25%|██▌       | 9/36 [00:00<00:00, 41.89it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.76it/s] 50%|█████     | 18/36 [00:00<00:00, 33.73it/s] 61%|██████    | 22/36 [00:00<00:00, 32.05it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.76it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.96it/s]100%|██████████| 36/36 [00:01<00:00, 31.85it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:09,  3.68it/s] 19%|█▉        | 7/36 [00:00<00:01, 22.39it/s] 31%|███       | 11/36 [00:00<00:00, 25.70it/s] 42%|████▏     | 15/36 [00:00<00:00, 27.73it/s] 53%|█████▎    | 19/36 [00:00<00:00, 27.85it/s] 64%|██████▍   | 23/36 [00:00<00:00, 29.02it/s] 75%|███████▌  | 27/36 [00:01<00:00, 29.16it/s] 86%|████████▌ | 31/36 [00:01<00:00, 28.74it/s] 94%|█████████▍| 34/36 [00:01<00:00, 28.86it/s]100%|██████████| 36/36 [00:01<00:00, 26.65it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.25it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.80it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.42it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.95it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.61it/s] 81%|████████  | 29/36 [00:00<00:00, 31.05it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.34it/s]100%|██████████| 36/36 [00:01<00:00, 32.43it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 43.83it/s] 37%|███▋      | 10/27 [00:00<00:00, 41.29it/s] 56%|█████▌    | 15/27 [00:00<00:00, 33.28it/s] 70%|███████   | 19/27 [00:00<00:00, 33.22it/s] 85%|████████▌ | 23/27 [00:00<00:00, 30.17it/s]100%|██████████| 27/27 [00:00<00:00, 30.84it/s]100%|██████████| 27/27 [00:00<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.65it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.56it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.49it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.78it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.84it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.30it/s] 61%|██████    | 22/36 [00:00<00:00, 32.62it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.11it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.81it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.63it/s]100%|██████████| 36/36 [00:01<00:00, 32.46it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.38it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.05it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.88it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.68it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.94it/s] 81%|████████  | 29/36 [00:00<00:00, 30.48it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.16it/s]100%|██████████| 36/36 [00:01<00:00, 31.79it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task651_30T2_30STIR_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task651_30T2_30STIR_Black  ────────
────────  evaluating  (post) Task651_30T2_30STIR_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task652_30T2_30STIR_ALLDWIADC_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:02,  1.78s/it] 19%|█▉        | 7/36 [00:01<00:05,  4.94it/s] 31%|███       | 11/36 [00:02<00:03,  8.20it/s] 42%|████▏     | 15/36 [00:02<00:01, 11.49it/s] 53%|█████▎    | 19/36 [00:02<00:01, 14.75it/s] 64%|██████▍   | 23/36 [00:02<00:00, 17.78it/s] 75%|███████▌  | 27/36 [00:02<00:00, 19.98it/s] 86%|████████▌ | 31/36 [00:02<00:00, 22.81it/s] 97%|█████████▋| 35/36 [00:02<00:00, 24.55it/s]100%|██████████| 36/36 [00:02<00:00, 12.64it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 59.01it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.44it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.24it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.61it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.58it/s]100%|██████████| 27/27 [00:00<00:00, 33.54it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 59.39it/s] 44%|████▍     | 12/27 [00:00<00:00, 31.50it/s] 59%|█████▉    | 16/27 [00:00<00:00, 31.58it/s] 78%|███████▊  | 21/27 [00:00<00:00, 33.99it/s] 93%|█████████▎| 25/27 [00:00<00:00, 32.20it/s]100%|██████████| 27/27 [00:00<00:00, 33.10it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 51.50it/s] 44%|████▍     | 12/27 [00:00<00:00, 35.17it/s] 59%|█████▉    | 16/27 [00:00<00:00, 33.45it/s] 74%|███████▍  | 20/27 [00:00<00:00, 31.37it/s] 89%|████████▉ | 24/27 [00:00<00:00, 31.30it/s]100%|██████████| 27/27 [00:00<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.83it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.82it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.79it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.68it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.82it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.86it/s]100%|██████████| 36/36 [00:01<00:00, 32.56it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 35.85it/s] 30%|██▉       | 8/27 [00:00<00:00, 36.89it/s] 44%|████▍     | 12/27 [00:00<00:00, 35.57it/s] 59%|█████▉    | 16/27 [00:00<00:00, 35.13it/s] 74%|███████▍  | 20/27 [00:00<00:00, 33.01it/s] 89%|████████▉ | 24/27 [00:00<00:00, 32.31it/s]100%|██████████| 27/27 [00:00<00:00, 32.97it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.85it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.08it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.11it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.66it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.59it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.21it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.59it/s]100%|██████████| 36/36 [00:01<00:00, 29.57it/s]100%|██████████| 36/36 [00:01<00:00, 31.78it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.56it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.75it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.30it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.59it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.82it/s]100%|██████████| 27/27 [00:00<00:00, 33.58it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 49.60it/s] 31%|███       | 11/36 [00:00<00:00, 38.94it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.47it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.39it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.24it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.64it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.45it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.33it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.85it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.03it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.49it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.62it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.03it/s] 81%|████████  | 29/36 [00:00<00:00, 31.06it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.56it/s]100%|██████████| 36/36 [00:01<00:00, 32.35it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 52.34it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.55it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.15it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.64it/s] 67%|██████▋   | 24/36 [00:00<00:00, 29.93it/s] 78%|███████▊  | 28/36 [00:00<00:00, 31.98it/s] 89%|████████▉ | 32/36 [00:00<00:00, 31.14it/s]100%|██████████| 36/36 [00:01<00:00, 29.46it/s]100%|██████████| 36/36 [00:01<00:00, 31.86it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 48.10it/s] 37%|███▋      | 10/27 [00:00<00:00, 41.20it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.21it/s] 70%|███████   | 19/27 [00:00<00:00, 33.14it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.08it/s]100%|██████████| 27/27 [00:00<00:00, 31.32it/s]100%|██████████| 27/27 [00:00<00:00, 33.36it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.30it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.70it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.85it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.27it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.19it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 32.22it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.95it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.99it/s] 50%|█████     | 18/36 [00:00<00:00, 34.13it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.76it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.69it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.55it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.22it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.28it/s] 81%|████████  | 29/36 [00:00<00:00, 30.40it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.31it/s]100%|██████████| 36/36 [00:01<00:00, 32.48it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.46it/s] 36%|███▌      | 13/36 [00:00<00:00, 34.85it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.85it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.67it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.94it/s] 81%|████████  | 29/36 [00:00<00:00, 30.47it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.16it/s]100%|██████████| 36/36 [00:01<00:00, 31.77it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task652_30T2_30STIR_ALLDWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task652_30T2_30STIR_ALLDWIADC_Black  ────────
────────  evaluating  (post) Task652_30T2_30STIR_ALLDWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task653_30T2_30STIR_60DWIADC_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.42s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.90it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.25it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.60it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.76it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.58it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.94it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.47it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.83it/s]100%|██████████| 36/36 [00:02<00:00, 14.43it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.52it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.94it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.02it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.48it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.80it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 57.81it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.79it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.08it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.46it/s]100%|██████████| 27/27 [00:00<00:00, 33.71it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.63it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.31it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.74it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.14it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.32it/s]100%|██████████| 27/27 [00:00<00:00, 33.40it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.20it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.85it/s] 50%|█████     | 18/36 [00:00<00:00, 34.05it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.20it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.57it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.38it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.90it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.01it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.48it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.49it/s]100%|██████████| 27/27 [00:00<00:00, 33.79it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.94it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.21it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.14it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.44it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.29it/s] 81%|████████  | 29/36 [00:00<00:00, 30.80it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.72it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.95it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.01it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.50it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.81it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.91it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.82it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.39it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.38it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.50it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.10it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.82it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.99it/s] 81%|████████  | 29/36 [00:00<00:00, 30.52it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.19it/s]100%|██████████| 36/36 [00:01<00:00, 31.88it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.99it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.81it/s] 50%|█████     | 18/36 [00:00<00:00, 34.15it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 59.02it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.00it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.82it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 50.13it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.00it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.40it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.03it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.14it/s] 81%|████████  | 29/36 [00:00<00:00, 30.58it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.24it/s]100%|██████████| 36/36 [00:01<00:00, 31.98it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 57.70it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.94it/s] 50%|█████     | 18/36 [00:00<00:00, 34.01it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.41it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.68it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.88it/s] 50%|█████     | 18/36 [00:00<00:00, 34.01it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.83it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.22it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.63it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.24it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.82it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.03it/s] 81%|████████  | 29/36 [00:00<00:00, 30.51it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.19it/s]100%|██████████| 36/36 [00:01<00:00, 31.91it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task653_30T2_30STIR_60DWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task653_30T2_30STIR_60DWIADC_Black  ────────
────────  evaluating  (post) Task653_30T2_30STIR_60DWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task654_30T1_30T1C_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.15it/s] 33%|███▎      | 12/36 [00:01<00:02,  9.28it/s] 44%|████▍     | 16/36 [00:02<00:01, 12.53it/s] 56%|█████▌    | 20/36 [00:02<00:01, 15.70it/s] 67%|██████▋   | 24/36 [00:02<00:00, 18.58it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.12it/s] 89%|████████▉ | 32/36 [00:02<00:00, 23.17it/s] 97%|█████████▋| 35/36 [00:02<00:00, 24.50it/s]100%|██████████| 36/36 [00:02<00:00, 13.40it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.56it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.70it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.03it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.92it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.11it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.14it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.85it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 32.00it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 54.30it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.41it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.51it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.29it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.90it/s]100%|██████████| 27/27 [00:00<00:00, 33.86it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 50.93it/s] 48%|████▊     | 13/27 [00:00<00:00, 35.26it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.02it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.74it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.01it/s]100%|██████████| 27/27 [00:00<00:00, 32.71it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.48it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.28it/s] 50%|█████     | 18/36 [00:00<00:00, 34.23it/s] 61%|██████    | 22/36 [00:00<00:00, 32.35it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.65it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.71it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.57it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 59.78it/s] 44%|████▍     | 12/27 [00:00<00:00, 39.38it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.60it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.79it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.66it/s]100%|██████████| 27/27 [00:00<00:00, 33.36it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 54.26it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.54it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.82it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.02it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.31it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.72it/s] 89%|████████▉ | 32/36 [00:00<00:00, 29.94it/s]100%|██████████| 36/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 31.97it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 44.21it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.24it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.93it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.85it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.51it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.97it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.46it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.19it/s]100%|██████████| 36/36 [00:01<00:00, 31.97it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.03it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.37it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.13it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.89it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.61it/s] 81%|████████  | 29/36 [00:00<00:00, 30.32it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.69it/s]100%|██████████| 36/36 [00:01<00:00, 31.30it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 56.39it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.58it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.22it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.77it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.75it/s] 81%|████████  | 29/36 [00:00<00:00, 31.01it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.04it/s]100%|██████████| 36/36 [00:01<00:00, 32.15it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  8%|▊         | 3/36 [00:00<00:01, 26.98it/s] 25%|██▌       | 9/36 [00:00<00:00, 35.52it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.07it/s] 50%|█████     | 18/36 [00:00<00:00, 33.40it/s] 61%|██████    | 22/36 [00:00<00:00, 32.09it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.73it/s] 83%|████████▎ | 30/36 [00:00<00:00, 29.01it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.48it/s]100%|██████████| 36/36 [00:01<00:00, 31.01it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 34.23it/s] 30%|██▉       | 8/27 [00:00<00:00, 35.38it/s] 44%|████▍     | 12/27 [00:00<00:00, 35.60it/s] 63%|██████▎   | 17/27 [00:00<00:00, 35.48it/s] 78%|███████▊  | 21/27 [00:00<00:00, 34.31it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.26it/s]100%|██████████| 27/27 [00:00<00:00, 33.00it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.64it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.70it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.90it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.30it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.35it/s] 81%|████████  | 29/36 [00:00<00:00, 30.74it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.71it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 33.96it/s] 61%|██████    | 22/36 [00:00<00:00, 32.14it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.65it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.97it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.03it/s]100%|██████████| 36/36 [00:01<00:00, 32.57it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 49.93it/s] 31%|███       | 11/36 [00:00<00:00, 39.45it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.68it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.72it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.59it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.82it/s] 89%|████████▉ | 32/36 [00:00<00:00, 29.75it/s]100%|██████████| 36/36 [00:01<00:00, 30.24it/s]100%|██████████| 36/36 [00:01<00:00, 32.15it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.30it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.60it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.25it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.90it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.13it/s] 81%|████████  | 29/36 [00:00<00:00, 30.59it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.23it/s]100%|██████████| 36/36 [00:01<00:00, 31.95it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task654_30T1_30T1C_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task654_30T1_30T1C_Black  ────────
────────  evaluating  (post) Task654_30T1_30T1C_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task655_30T1_30T1C_60DWIADC_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:45,  1.30s/it] 22%|██▏       | 8/36 [00:01<00:03,  7.48it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.96it/s] 44%|████▍     | 16/36 [00:01<00:01, 14.38it/s] 56%|█████▌    | 20/36 [00:01<00:00, 17.52it/s] 67%|██████▋   | 24/36 [00:01<00:00, 20.26it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.52it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.98it/s] 94%|█████████▍| 34/36 [00:02<00:00, 25.23it/s]100%|██████████| 36/36 [00:02<00:00, 15.18it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.86it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.48it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.82it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.58it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.07it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.94it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.97it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.69it/s]100%|██████████| 27/27 [00:00<00:00, 33.77it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 45.77it/s] 37%|███▋      | 10/27 [00:00<00:00, 36.95it/s] 52%|█████▏    | 14/27 [00:00<00:00, 30.81it/s] 67%|██████▋   | 18/27 [00:00<00:00, 31.13it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.34it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.50it/s]100%|██████████| 27/27 [00:00<00:00, 31.89it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.95it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.82it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.76it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.53it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.78it/s] 81%|████████  | 29/36 [00:00<00:00, 30.42it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.70it/s]100%|██████████| 36/36 [00:01<00:00, 32.44it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 55.04it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.76it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.32it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.97it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.72it/s]100%|██████████| 27/27 [00:00<00:00, 33.52it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 54.95it/s] 33%|███▎      | 12/36 [00:00<00:00, 35.75it/s] 44%|████▍     | 16/36 [00:00<00:00, 32.81it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.92it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.78it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.05it/s] 89%|████████▉ | 32/36 [00:01<00:00, 29.54it/s]100%|██████████| 36/36 [00:01<00:00, 27.80it/s]100%|██████████| 36/36 [00:01<00:00, 30.70it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 31.80it/s] 28%|██▊       | 10/36 [00:00<00:00, 39.46it/s] 42%|████▏     | 15/36 [00:00<00:00, 31.95it/s] 56%|█████▌    | 20/36 [00:00<00:00, 33.16it/s] 67%|██████▋   | 24/36 [00:00<00:00, 33.82it/s] 78%|███████▊  | 28/36 [00:00<00:00, 32.22it/s] 89%|████████▉ | 32/36 [00:00<00:00, 31.42it/s]100%|██████████| 36/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.07it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 56.92it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.60it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.17it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.96it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.20it/s] 81%|████████  | 29/36 [00:00<00:00, 31.11it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.63it/s]100%|██████████| 36/36 [00:01<00:00, 32.38it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  6%|▌         | 2/36 [00:00<00:01, 19.51it/s] 19%|█▉        | 7/36 [00:00<00:00, 36.48it/s] 31%|███       | 11/36 [00:00<00:00, 37.93it/s] 42%|████▏     | 15/36 [00:00<00:00, 33.85it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.02it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.00it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.76it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.67it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 31.10it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 42.31it/s] 31%|███       | 11/36 [00:00<00:00, 37.83it/s] 42%|████▏     | 15/36 [00:00<00:00, 27.65it/s] 50%|█████     | 18/36 [00:00<00:00, 26.70it/s] 58%|█████▊    | 21/36 [00:00<00:00, 27.28it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.54it/s] 81%|████████  | 29/36 [00:00<00:00, 28.98it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.48it/s]100%|██████████| 36/36 [00:01<00:00, 29.86it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 47.87it/s] 41%|████      | 11/27 [00:00<00:00, 35.28it/s] 56%|█████▌    | 15/27 [00:00<00:00, 33.59it/s] 70%|███████   | 19/27 [00:00<00:00, 32.02it/s] 85%|████████▌ | 23/27 [00:00<00:00, 30.99it/s]100%|██████████| 27/27 [00:00<00:00, 29.89it/s]100%|██████████| 27/27 [00:00<00:00, 32.01it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.86it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.15it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.98it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.19it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.47it/s] 81%|████████  | 29/36 [00:00<00:00, 30.56it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.07it/s]100%|██████████| 36/36 [00:01<00:00, 32.19it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 35.19it/s] 25%|██▌       | 9/36 [00:00<00:00, 42.38it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.08it/s] 50%|█████     | 18/36 [00:00<00:00, 32.32it/s] 61%|██████    | 22/36 [00:00<00:00, 32.12it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.01it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.67it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.56it/s]100%|██████████| 36/36 [00:01<00:00, 31.84it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.30it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.50it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.83it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.04it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.01it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 32.50it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.83it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task655_30T1_30T1C_60DWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task655_30T1_30T1C_60DWIADC_Black  ────────
────────  evaluating  (post) Task655_30T1_30T1C_60DWIADC_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Task656_30T1_30T1C_60DWIADC_30T2_30STIR_Black  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.61s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.16it/s] 33%|███▎      | 12/36 [00:01<00:02,  9.28it/s] 44%|████▍     | 16/36 [00:02<00:01, 12.53it/s] 56%|█████▌    | 20/36 [00:02<00:01, 15.78it/s] 67%|██████▋   | 24/36 [00:02<00:00, 18.68it/s] 78%|███████▊  | 28/36 [00:02<00:00, 20.66it/s] 89%|████████▉ | 32/36 [00:02<00:00, 23.42it/s]100%|██████████| 36/36 [00:02<00:00, 24.83it/s]100%|██████████| 36/36 [00:02<00:00, 13.40it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 57.70it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.58it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.05it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.47it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.51it/s]100%|██████████| 27/27 [00:00<00:00, 33.77it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 38.26it/s] 37%|███▋      | 10/27 [00:00<00:00, 43.49it/s] 56%|█████▌    | 15/27 [00:00<00:00, 36.16it/s] 70%|███████   | 19/27 [00:00<00:00, 32.87it/s] 85%|████████▌ | 23/27 [00:00<00:00, 32.49it/s]100%|██████████| 27/27 [00:00<00:00, 31.55it/s]100%|██████████| 27/27 [00:00<00:00, 33.54it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 49.79it/s] 44%|████▍     | 12/27 [00:00<00:00, 36.24it/s] 59%|█████▉    | 16/27 [00:00<00:00, 34.07it/s] 74%|███████▍  | 20/27 [00:00<00:00, 32.34it/s] 89%|████████▉ | 24/27 [00:00<00:00, 30.47it/s]100%|██████████| 27/27 [00:00<00:00, 33.01it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.04it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.78it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.16it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.31it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.45it/s] 81%|████████  | 29/36 [00:00<00:00, 30.50it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 32.31it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.28it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.93it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.07it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.52it/s]100%|██████████| 27/27 [00:00<00:00, 33.83it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 48.74it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.29it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.48it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.52it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.26it/s] 78%|███████▊  | 28/36 [00:00<00:00, 29.97it/s] 89%|████████▉ | 32/36 [00:01<00:00, 30.00it/s]100%|██████████| 36/36 [00:01<00:00, 30.31it/s]100%|██████████| 36/36 [00:01<00:00, 31.86it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.76it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.97it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.14it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.54it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.46it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 43.15it/s] 28%|██▊       | 10/36 [00:00<00:00, 37.39it/s] 39%|███▉      | 14/36 [00:00<00:00, 35.08it/s] 50%|█████     | 18/36 [00:00<00:00, 32.28it/s] 61%|██████    | 22/36 [00:00<00:00, 30.66it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 31.48it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 45.86it/s] 31%|███       | 11/36 [00:00<00:00, 32.50it/s] 42%|████▏     | 15/36 [00:00<00:00, 32.01it/s] 53%|█████▎    | 19/36 [00:00<00:00, 31.06it/s] 64%|██████▍   | 23/36 [00:00<00:00, 30.50it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.19it/s] 86%|████████▌ | 31/36 [00:00<00:00, 29.56it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.94it/s]100%|██████████| 36/36 [00:01<00:00, 30.97it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.19it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.25it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.04it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.55it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.82it/s] 81%|████████  | 29/36 [00:00<00:00, 31.25it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.69it/s]100%|██████████| 36/36 [00:01<00:00, 32.26it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  7%|▋         | 2/27 [00:00<00:01, 18.48it/s] 19%|█▊        | 5/27 [00:00<00:00, 25.02it/s] 33%|███▎      | 9/27 [00:00<00:00, 27.94it/s] 44%|████▍     | 12/27 [00:00<00:00, 26.91it/s] 59%|█████▉    | 16/27 [00:00<00:00, 27.11it/s] 78%|███████▊  | 21/27 [00:00<00:00, 30.39it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.25it/s]100%|██████████| 27/27 [00:00<00:00, 28.19it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.29it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.36it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.10it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.82it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.03it/s] 81%|████████  | 29/36 [00:00<00:00, 30.51it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 31.87it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.62it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.53it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.11it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.26it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.51it/s] 81%|████████  | 29/36 [00:00<00:00, 30.78it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.28it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.87it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.25it/s] 50%|█████     | 18/36 [00:00<00:00, 34.25it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.62it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.38it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.58it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.33it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.83it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.93it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.29it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.38it/s] 81%|████████  | 29/36 [00:00<00:00, 30.78it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.26it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Task656_30T1_30T1C_60DWIADC_30T2_30STIR_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Task656_30T1_30T1C_60DWIADC_30T2_30STIR_Black  ────────
────────  evaluating  (post) Task656_30T1_30T1C_60DWIADC_30T2_30STIR_Black  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

✅  all BLACK combinations finished using labelsTsreal

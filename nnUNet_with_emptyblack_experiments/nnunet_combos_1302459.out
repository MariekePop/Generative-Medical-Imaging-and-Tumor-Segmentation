
EnvironmentNameNotFound: Could not find conda environment: nestedformer
You can list all discoverable environments with `conda info --envs`.


────────  predicting Dataset541_allGen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.41s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.94it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.28it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.67it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.51it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.78it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.57it/s] 89%|████████▉ | 32/36 [00:02<00:00, 24.23it/s]100%|██████████| 36/36 [00:02<00:00, 25.47it/s]100%|██████████| 36/36 [00:02<00:00, 14.47it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.87it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.18it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.59it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.69it/s] 83%|████████▎ | 30/36 [00:00<00:00, 29.20it/s] 94%|█████████▍| 34/36 [00:01<00:00, 31.00it/s]100%|██████████| 36/36 [00:01<00:00, 32.57it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 47.61it/s] 37%|███▋      | 10/27 [00:00<00:00, 41.84it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.11it/s] 70%|███████   | 19/27 [00:00<00:00, 32.26it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.26it/s]100%|██████████| 27/27 [00:00<00:00, 30.50it/s]100%|██████████| 27/27 [00:00<00:00, 32.85it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.69it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.96it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.50it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.09it/s]100%|██████████| 27/27 [00:00<00:00, 33.83it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.40it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.57it/s] 50%|█████     | 18/36 [00:00<00:00, 34.14it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.53it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.53it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.50it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.95it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.52it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.53it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 45.95it/s] 28%|██▊       | 10/36 [00:00<00:00, 39.90it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.44it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.28it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.04it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.60it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.71it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.61it/s]100%|██████████| 36/36 [00:01<00:00, 32.19it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 47.54it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.41it/s] 42%|████▏     | 15/36 [00:00<00:00, 33.94it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.62it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.98it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.13it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.61it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.25it/s]100%|██████████| 36/36 [00:01<00:00, 32.18it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.39it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.52it/s] 50%|█████     | 18/36 [00:00<00:00, 33.96it/s] 61%|██████    | 22/36 [00:00<00:00, 32.83it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.91it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.23it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.62it/s]100%|██████████| 36/36 [00:01<00:00, 32.14it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 45.21it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.14it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.84it/s] 53%|█████▎    | 19/36 [00:00<00:00, 30.69it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.30it/s] 75%|███████▌  | 27/36 [00:00<00:00, 29.92it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.67it/s] 97%|█████████▋| 35/36 [00:01<00:00, 28.90it/s]100%|██████████| 36/36 [00:01<00:00, 31.48it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.32it/s] 36%|███▌      | 13/36 [00:00<00:00, 34.98it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.05it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.31it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.39it/s] 81%|████████  | 29/36 [00:00<00:00, 30.60it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.12it/s]100%|██████████| 36/36 [00:01<00:00, 32.02it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.94it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.17it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.93it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.77it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.88it/s]100%|██████████| 27/27 [00:00<00:00, 33.86it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:01, 30.96it/s] 25%|██▌       | 9/36 [00:00<00:00, 38.32it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.78it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.14it/s] 58%|█████▊    | 21/36 [00:00<00:00, 30.07it/s] 69%|██████▉   | 25/36 [00:00<00:00, 29.15it/s] 78%|███████▊  | 28/36 [00:00<00:00, 28.24it/s] 89%|████████▉ | 32/36 [00:01<00:00, 28.61it/s]100%|██████████| 36/36 [00:01<00:00, 31.54it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.62it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 34.09it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.90it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.49it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.80it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.03it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.56it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.90it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.67it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.73it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.35it/s] 61%|██████    | 22/36 [00:00<00:00, 32.65it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.64it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.93it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.49it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset541_allGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset541_allGen  ────────
────────  evaluating  (post) Dataset541_allGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset542_T1Gen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.40s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.99it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.35it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.71it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.74it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.74it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.70it/s] 89%|████████▉ | 32/36 [00:02<00:00, 24.11it/s]100%|██████████| 36/36 [00:02<00:00, 25.55it/s]100%|██████████| 36/36 [00:02<00:00, 14.55it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.37it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.25it/s] 50%|█████     | 18/36 [00:00<00:00, 34.20it/s] 61%|██████    | 22/36 [00:00<00:00, 32.19it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.64it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.18it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.52it/s]100%|██████████| 36/36 [00:01<00:00, 32.54it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.90it/s] 37%|███▋      | 10/27 [00:00<00:00, 42.78it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.63it/s] 70%|███████   | 19/27 [00:00<00:00, 33.87it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.62it/s]100%|██████████| 27/27 [00:00<00:00, 31.30it/s]100%|██████████| 27/27 [00:00<00:00, 33.26it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 51.23it/s] 48%|████▊     | 13/27 [00:00<00:00, 35.37it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.06it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.78it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.97it/s]100%|██████████| 27/27 [00:00<00:00, 32.74it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.68it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 33.64it/s] 61%|██████    | 22/36 [00:00<00:00, 32.56it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.11it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.12it/s] 44%|████▍     | 12/27 [00:00<00:00, 38.78it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.87it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.34it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.42it/s]100%|██████████| 27/27 [00:00<00:00, 33.72it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.23it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.63it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.79it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.22it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.28it/s] 81%|████████  | 29/36 [00:00<00:00, 30.69it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.30it/s]100%|██████████| 36/36 [00:01<00:00, 32.18it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.58it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.05it/s] 61%|██████    | 22/36 [00:00<00:00, 32.19it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.54it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.40it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.23it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 54.52it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.10it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.43it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.77it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.63it/s] 81%|████████  | 29/36 [00:00<00:00, 31.13it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.93it/s]100%|██████████| 36/36 [00:01<00:00, 32.47it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.52it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.90it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.41it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.73it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 31.92it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.66it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.82it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.52it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 43.36it/s] 37%|███▋      | 10/27 [00:00<00:00, 45.00it/s] 56%|█████▌    | 15/27 [00:00<00:00, 36.18it/s] 70%|███████   | 19/27 [00:00<00:00, 33.29it/s] 85%|████████▌ | 23/27 [00:00<00:00, 32.20it/s]100%|██████████| 27/27 [00:00<00:00, 30.91it/s]100%|██████████| 27/27 [00:00<00:00, 33.51it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.35it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.88it/s] 50%|█████     | 18/36 [00:00<00:00, 34.03it/s] 61%|██████    | 22/36 [00:00<00:00, 32.26it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.39it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.11it/s] 50%|█████     | 18/36 [00:00<00:00, 33.70it/s] 61%|██████    | 22/36 [00:00<00:00, 31.99it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.46it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.29it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.55it/s]100%|██████████| 36/36 [00:01<00:00, 32.39it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 48.46it/s] 28%|██▊       | 10/36 [00:00<00:00, 42.69it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.71it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.62it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.81it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.30it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.05it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.28it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 57.63it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 32.48it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.85it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset542_T1Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset542_T1Gen  ────────
────────  evaluating  (post) Dataset542_T1Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset543_T1CGen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:47,  1.37s/it] 22%|██▏       | 8/36 [00:01<00:03,  7.16it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.57it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.96it/s] 56%|█████▌    | 20/36 [00:01<00:00, 17.13it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.90it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.25it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.74it/s] 94%|█████████▍| 34/36 [00:02<00:00, 25.05it/s]100%|██████████| 36/36 [00:02<00:00, 14.79it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 56.51it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.20it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.60it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.17it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.25it/s] 81%|████████  | 29/36 [00:00<00:00, 30.71it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.00it/s]100%|██████████| 36/36 [00:01<00:00, 31.96it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 43.39it/s] 37%|███▋      | 10/27 [00:00<00:00, 18.08it/s] 59%|█████▉    | 16/27 [00:00<00:00, 26.28it/s] 74%|███████▍  | 20/27 [00:00<00:00, 27.00it/s] 89%|████████▉ | 24/27 [00:00<00:00, 27.95it/s]100%|██████████| 27/27 [00:01<00:00, 26.66it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  7%|▋         | 2/27 [00:00<00:01, 14.31it/s] 30%|██▉       | 8/27 [00:00<00:00, 35.68it/s] 44%|████▍     | 12/27 [00:00<00:00, 31.68it/s] 59%|█████▉    | 16/27 [00:00<00:00, 30.21it/s] 74%|███████▍  | 20/27 [00:00<00:00, 30.49it/s] 89%|████████▉ | 24/27 [00:00<00:00, 29.47it/s]100%|██████████| 27/27 [00:00<00:00, 29.91it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.30it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.90it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.37it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.83it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.66it/s] 81%|████████  | 29/36 [00:00<00:00, 30.94it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.19it/s]100%|██████████| 36/36 [00:01<00:00, 32.43it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 26.18it/s] 30%|██▉       | 8/27 [00:00<00:00, 38.26it/s] 44%|████▍     | 12/27 [00:00<00:00, 34.07it/s] 59%|█████▉    | 16/27 [00:00<00:00, 30.85it/s] 74%|███████▍  | 20/27 [00:00<00:00, 32.23it/s] 89%|████████▉ | 24/27 [00:00<00:00, 31.47it/s]100%|██████████| 27/27 [00:00<00:00, 32.07it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.62it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.98it/s] 50%|█████     | 18/36 [00:00<00:00, 33.97it/s] 61%|██████    | 22/36 [00:00<00:00, 32.55it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.83it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.13it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.61it/s]100%|██████████| 36/36 [00:01<00:00, 32.42it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.44it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.89it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.80it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.63it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.83it/s] 81%|████████  | 29/36 [00:00<00:00, 30.15it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.88it/s]100%|██████████| 36/36 [00:01<00:00, 32.57it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:09,  3.73it/s] 19%|█▉        | 7/36 [00:00<00:01, 21.65it/s] 31%|███       | 11/36 [00:00<00:00, 25.93it/s] 42%|████▏     | 15/36 [00:00<00:00, 25.55it/s] 53%|█████▎    | 19/36 [00:00<00:00, 27.84it/s] 64%|██████▍   | 23/36 [00:00<00:00, 29.25it/s] 75%|███████▌  | 27/36 [00:01<00:00, 28.74it/s] 86%|████████▌ | 31/36 [00:01<00:00, 29.00it/s] 97%|█████████▋| 35/36 [00:01<00:00, 27.85it/s]100%|██████████| 36/36 [00:01<00:00, 25.96it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 51.06it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.86it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.62it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.06it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.23it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.76it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 31.97it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 47.83it/s] 28%|██▊       | 10/36 [00:00<00:00, 43.16it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.97it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.43it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.02it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.99it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.64it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.41it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 30.42it/s] 30%|██▉       | 8/27 [00:00<00:00, 29.45it/s] 44%|████▍     | 12/27 [00:00<00:00, 29.47it/s] 56%|█████▌    | 15/27 [00:00<00:00, 27.23it/s] 67%|██████▋   | 18/27 [00:00<00:00, 26.53it/s] 78%|███████▊  | 21/27 [00:00<00:00, 27.19it/s] 93%|█████████▎| 25/27 [00:00<00:00, 29.86it/s]100%|██████████| 27/27 [00:00<00:00, 29.71it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.65it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.75it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.87it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.31it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.33it/s] 81%|████████  | 29/36 [00:00<00:00, 30.67it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.24it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.82it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.80it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.88it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.74it/s] 81%|████████  | 29/36 [00:00<00:00, 30.03it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.18it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  8%|▊         | 3/36 [00:00<00:01, 28.67it/s] 19%|█▉        | 7/36 [00:00<00:00, 33.95it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.22it/s] 44%|████▍     | 16/36 [00:00<00:00, 31.75it/s] 56%|█████▌    | 20/36 [00:00<00:00, 33.83it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.57it/s] 78%|███████▊  | 28/36 [00:00<00:00, 31.32it/s] 89%|████████▉ | 32/36 [00:01<00:00, 30.13it/s]100%|██████████| 36/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 31.62it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.53it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.25it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.03it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.78it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.01it/s] 81%|████████  | 29/36 [00:00<00:00, 30.56it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.22it/s]100%|██████████| 36/36 [00:01<00:00, 31.88it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset543_T1CGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset543_T1CGen  ────────
────────  evaluating  (post) Dataset543_T1CGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset544_T2Gen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:46,  1.33s/it] 22%|██▏       | 8/36 [00:01<00:03,  7.31it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.76it/s] 44%|████▍     | 16/36 [00:01<00:01, 14.16it/s] 56%|█████▌    | 20/36 [00:01<00:00, 17.31it/s] 67%|██████▋   | 24/36 [00:01<00:00, 20.08it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.38it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.84it/s] 94%|█████████▍| 34/36 [00:02<00:00, 25.14it/s]100%|██████████| 36/36 [00:02<00:00, 14.98it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.75it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.85it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 22%|██▏       | 6/27 [00:00<00:00, 56.24it/s] 44%|████▍     | 12/27 [00:00<00:00, 39.44it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.48it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.18it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.82it/s]100%|██████████| 27/27 [00:00<00:00, 33.73it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.79it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.94it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.05it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.51it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.83it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.72it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 32.19it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.57it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.10it/s]100%|██████████| 36/36 [00:01<00:00, 32.29it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.74it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.95it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.80it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.73it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.80it/s]100%|██████████| 27/27 [00:00<00:00, 33.81it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.38it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.64it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.78it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.26it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.31it/s] 81%|████████  | 29/36 [00:00<00:00, 30.71it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.31it/s]100%|██████████| 36/36 [00:01<00:00, 32.19it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.76it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.96it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 31.65it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.60it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.01it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.54it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.64it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.59it/s] 50%|█████     | 18/36 [00:00<00:00, 34.35it/s] 61%|██████    | 22/36 [00:00<00:00, 32.66it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.84it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.14it/s] 94%|█████████▍| 34/36 [00:01<00:00, 28.18it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.26it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.72it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.27it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.92it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.07it/s] 81%|████████  | 29/36 [00:00<00:00, 30.58it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.22it/s]100%|██████████| 36/36 [00:01<00:00, 31.95it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.19it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.33it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.62it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.14it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.23it/s] 81%|████████  | 29/36 [00:00<00:00, 30.67it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 32.10it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.65it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.87it/s] 67%|██████▋   | 18/27 [00:00<00:00, 31.66it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.75it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.53it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 41.66it/s] 28%|██▊       | 10/36 [00:00<00:00, 35.58it/s] 39%|███▉      | 14/36 [00:00<00:00, 33.50it/s] 50%|█████     | 18/36 [00:00<00:00, 32.48it/s] 61%|██████    | 22/36 [00:00<00:00, 30.54it/s] 72%|███████▏  | 26/36 [00:00<00:00, 30.98it/s] 83%|████████▎ | 30/36 [00:00<00:00, 29.79it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 31.43it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.57it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.46it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.73it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 34.02it/s] 61%|██████    | 22/36 [00:00<00:00, 32.31it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.68it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 33.29it/s] 61%|██████    | 22/36 [00:00<00:00, 31.80it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.86it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.35it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.81it/s]100%|██████████| 36/36 [00:01<00:00, 32.31it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset544_T2Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset544_T2Gen  ────────
────────  evaluating  (post) Dataset544_T2Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset545_STIRGen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:47,  1.37s/it] 22%|██▏       | 8/36 [00:01<00:03,  7.16it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.57it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.95it/s] 56%|█████▌    | 20/36 [00:01<00:00, 17.11it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.91it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.23it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.73it/s] 94%|█████████▍| 34/36 [00:02<00:00, 25.03it/s]100%|██████████| 36/36 [00:02<00:00, 14.78it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 34.50it/s] 22%|██▏       | 8/36 [00:00<00:00, 36.32it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.21it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.69it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.96it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.78it/s] 81%|████████  | 29/36 [00:00<00:00, 30.58it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.60it/s]100%|██████████| 36/36 [00:01<00:00, 31.94it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.74it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.63it/s] 67%|██████▋   | 18/27 [00:00<00:00, 32.23it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.95it/s] 96%|█████████▋| 26/27 [00:00<00:00, 32.00it/s]100%|██████████| 27/27 [00:00<00:00, 33.80it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 54.35it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.67it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.84it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.24it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.83it/s]100%|██████████| 27/27 [00:00<00:00, 33.24it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.03it/s] 61%|██████    | 22/36 [00:00<00:00, 32.44it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.76it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.94it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.03it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.46it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.49it/s]100%|██████████| 27/27 [00:00<00:00, 33.81it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.83it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.78it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.88it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.28it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.32it/s] 81%|████████  | 29/36 [00:00<00:00, 30.70it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.30it/s]100%|██████████| 36/36 [00:01<00:00, 32.22it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.42it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.00it/s] 61%|██████    | 22/36 [00:00<00:00, 32.44it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.48it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.41it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.76it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 34.03it/s] 61%|██████    | 22/36 [00:00<00:00, 32.46it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.59it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.03it/s] 50%|█████     | 18/36 [00:00<00:00, 34.11it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.75it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.98it/s] 50%|█████     | 18/36 [00:00<00:00, 34.05it/s] 61%|██████    | 22/36 [00:00<00:00, 32.48it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.83it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.52it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.92it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.07it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.49it/s]100%|██████████| 27/27 [00:00<00:00, 33.76it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.27it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.34it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.64it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.14it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.23it/s] 81%|████████  | 29/36 [00:00<00:00, 30.64it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.26it/s]100%|██████████| 36/36 [00:01<00:00, 32.09it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.66it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.98it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.35it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.62it/s] 28%|██▊       | 10/36 [00:00<00:00, 39.62it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.40it/s] 53%|█████▎    | 19/36 [00:00<00:00, 33.78it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.02it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.28it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.40it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.52it/s]100%|██████████| 36/36 [00:01<00:00, 32.24it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.40it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.96it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.42it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.00it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.14it/s] 81%|████████  | 29/36 [00:00<00:00, 30.57it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.23it/s]100%|██████████| 36/36 [00:01<00:00, 32.00it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset545_STIRGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset545_STIRGen  ────────
────────  evaluating  (post) Dataset545_STIRGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset546_DWIGen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.42s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.92it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.24it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.63it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.81it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.62it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.98it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.52it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.86it/s]100%|██████████| 36/36 [00:02<00:00, 14.46it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:04,  8.28it/s] 19%|█▉        | 7/36 [00:00<00:00, 34.27it/s] 31%|███       | 11/36 [00:00<00:00, 33.77it/s] 42%|████▏     | 15/36 [00:00<00:00, 31.84it/s] 53%|█████▎    | 19/36 [00:00<00:00, 31.44it/s] 64%|██████▍   | 23/36 [00:00<00:00, 30.73it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.31it/s] 86%|████████▌ | 31/36 [00:01<00:00, 30.03it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.86it/s]100%|██████████| 36/36 [00:01<00:00, 30.10it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 29.28it/s] 30%|██▉       | 8/27 [00:00<00:00, 32.19it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.13it/s] 63%|██████▎   | 17/27 [00:00<00:00, 36.41it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.24it/s] 93%|█████████▎| 25/27 [00:00<00:00, 32.40it/s]100%|██████████| 27/27 [00:00<00:00, 33.00it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 56.07it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.43it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.85it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.36it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.38it/s]100%|██████████| 27/27 [00:00<00:00, 33.56it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.92it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.81it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.91it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.30it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.24it/s] 81%|████████  | 29/36 [00:00<00:00, 30.73it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.78it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.93it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.60it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.45it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.07it/s]100%|██████████| 27/27 [00:00<00:00, 33.51it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 50.93it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.79it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.36it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.98it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.12it/s] 81%|████████  | 29/36 [00:00<00:00, 30.58it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 31.96it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 57.50it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.62it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.30it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.59it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.22it/s] 81%|████████  | 29/36 [00:00<00:00, 31.01it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.49it/s]100%|██████████| 36/36 [00:01<00:00, 32.45it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 52.73it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.42it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.18it/s] 58%|█████▊    | 21/36 [00:00<00:00, 30.27it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.06it/s] 81%|████████  | 29/36 [00:00<00:00, 30.87it/s] 92%|█████████▏| 33/36 [00:01<00:00, 28.95it/s]100%|██████████| 36/36 [00:01<00:00, 32.00it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.99it/s] 50%|█████     | 18/36 [00:00<00:00, 34.11it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.77it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.55it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.55it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.67it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.61it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.98it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.52it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.52it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.89it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.01it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.08it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.05it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.06it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.04it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.59it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.23it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.58it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.11it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.22it/s] 81%|████████  | 29/36 [00:00<00:00, 30.65it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 32.08it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset546_DWIGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset546_DWIGen  ────────
────────  evaluating  (post) Dataset546_DWIGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset547_ADCGen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:53,  1.52s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.50it/s] 33%|███▎      | 12/36 [00:01<00:02,  9.73it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.04it/s] 56%|█████▌    | 20/36 [00:02<00:00, 16.21it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.07it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.53it/s] 89%|████████▉ | 32/36 [00:02<00:00, 23.53it/s] 97%|█████████▋| 35/36 [00:02<00:00, 24.77it/s]100%|██████████| 36/36 [00:02<00:00, 13.89it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.62it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.65it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.95it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.11it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.52it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.52it/s]100%|██████████| 27/27 [00:00<00:00, 33.85it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:00<00:09,  2.60it/s] 26%|██▌       | 7/27 [00:00<00:01, 17.44it/s] 41%|████      | 11/27 [00:00<00:00, 20.69it/s] 52%|█████▏    | 14/27 [00:00<00:00, 22.95it/s] 63%|██████▎   | 17/27 [00:00<00:00, 24.69it/s] 74%|███████▍  | 20/27 [00:00<00:00, 26.01it/s] 85%|████████▌ | 23/27 [00:01<00:00, 27.00it/s] 96%|█████████▋| 26/27 [00:01<00:00, 27.71it/s]100%|██████████| 27/27 [00:01<00:00, 22.62it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.54it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.90it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.30it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.93it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.04it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.65it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.96it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.83it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.58it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.93it/s]100%|██████████| 27/27 [00:00<00:00, 33.45it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.04it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.88it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.50it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.51it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.83it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.06it/s] 50%|█████     | 18/36 [00:00<00:00, 34.14it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.48it/s]100%|██████████| 36/36 [00:01<00:00, 32.68it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.76it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.01it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.89it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.94it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.20it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.17it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.47it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.42it/s] 81%|████████  | 29/36 [00:00<00:00, 30.82it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.39it/s]100%|██████████| 36/36 [00:01<00:00, 32.41it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.51it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.30it/s] 50%|█████     | 18/36 [00:00<00:00, 33.80it/s] 61%|██████    | 22/36 [00:00<00:00, 32.32it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.38it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.79it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.34it/s]100%|██████████| 36/36 [00:01<00:00, 32.43it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.69it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.98it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.10it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.84it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.55it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.08it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.50it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.07it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.18it/s] 81%|████████  | 29/36 [00:00<00:00, 30.63it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.05it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.56it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.75it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.32it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.95it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.12it/s] 81%|████████  | 29/36 [00:00<00:00, 30.59it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.24it/s]100%|██████████| 36/36 [00:01<00:00, 31.98it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 59.05it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.05it/s] 50%|█████     | 18/36 [00:00<00:00, 34.13it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.66it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.30it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.10it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.07it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.41it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.41it/s] 81%|████████  | 29/36 [00:00<00:00, 30.78it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset547_ADCGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset547_ADCGen  ────────
────────  evaluating  (post) Dataset547_ADCGen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset548_DWI_ADC_Gen  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<01:06,  1.90s/it] 22%|██▏       | 8/36 [00:02<00:05,  5.29it/s] 33%|███▎      | 12/36 [00:02<00:02,  8.16it/s] 44%|████▍     | 16/36 [00:02<00:01, 11.23it/s] 56%|█████▌    | 20/36 [00:02<00:01, 14.31it/s] 67%|██████▋   | 24/36 [00:02<00:00, 17.34it/s] 78%|███████▊  | 28/36 [00:02<00:00, 19.94it/s] 86%|████████▌ | 31/36 [00:02<00:00, 21.81it/s] 94%|█████████▍| 34/36 [00:02<00:00, 23.39it/s]100%|██████████| 36/36 [00:02<00:00, 12.08it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.00it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.25it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.70it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.99it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.00it/s] 81%|████████  | 29/36 [00:00<00:00, 31.25it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.06it/s]100%|██████████| 36/36 [00:01<00:00, 32.42it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 27.60it/s] 26%|██▌       | 7/27 [00:00<00:00, 34.58it/s] 41%|████      | 11/27 [00:00<00:00, 34.90it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.88it/s] 70%|███████   | 19/27 [00:00<00:00, 33.57it/s] 85%|████████▌ | 23/27 [00:00<00:00, 32.46it/s]100%|██████████| 27/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 25.92it/s] 30%|██▉       | 8/27 [00:00<00:00, 33.61it/s] 44%|████▍     | 12/27 [00:00<00:00, 34.54it/s] 59%|█████▉    | 16/27 [00:00<00:00, 30.24it/s] 74%|███████▍  | 20/27 [00:00<00:00, 30.17it/s] 89%|████████▉ | 24/27 [00:00<00:00, 27.70it/s]100%|██████████| 27/27 [00:00<00:00, 29.69it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  8%|▊         | 3/36 [00:00<00:01, 27.63it/s] 22%|██▏       | 8/36 [00:00<00:00, 34.40it/s] 33%|███▎      | 12/36 [00:00<00:00, 33.65it/s] 44%|████▍     | 16/36 [00:00<00:00, 31.64it/s] 56%|█████▌    | 20/36 [00:00<00:00, 31.50it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.48it/s] 78%|███████▊  | 28/36 [00:00<00:00, 29.92it/s] 86%|████████▌ | 31/36 [00:01<00:00, 28.19it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.18it/s]100%|██████████| 36/36 [00:01<00:00, 30.67it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 39.41it/s] 33%|███▎      | 9/27 [00:00<00:00, 39.78it/s] 48%|████▊     | 13/27 [00:00<00:00, 33.79it/s] 63%|██████▎   | 17/27 [00:00<00:00, 31.35it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.50it/s] 93%|█████████▎| 25/27 [00:00<00:00, 30.58it/s]100%|██████████| 27/27 [00:00<00:00, 32.09it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:03,  9.57it/s] 14%|█▍        | 5/36 [00:00<00:01, 21.96it/s] 22%|██▏       | 8/36 [00:00<00:01, 23.85it/s] 31%|███       | 11/36 [00:00<00:01, 23.70it/s] 42%|████▏     | 15/36 [00:00<00:00, 28.67it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.09it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.96it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.66it/s] 86%|████████▌ | 31/36 [00:01<00:00, 29.66it/s] 97%|█████████▋| 35/36 [00:01<00:00, 32.22it/s]100%|██████████| 36/36 [00:01<00:00, 28.86it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 46.79it/s] 28%|██▊       | 10/36 [00:00<00:00, 40.72it/s] 42%|████▏     | 15/36 [00:00<00:00, 34.68it/s] 53%|█████▎    | 19/36 [00:00<00:00, 31.74it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.35it/s] 75%|███████▌  | 27/36 [00:00<00:00, 29.72it/s] 86%|████████▌ | 31/36 [00:00<00:00, 31.01it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.04it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.80it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.63it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.61it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.03it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.52it/s] 81%|████████  | 29/36 [00:00<00:00, 30.90it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.13it/s]100%|██████████| 36/36 [00:01<00:00, 32.29it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 36.96it/s] 22%|██▏       | 8/36 [00:00<00:00, 36.24it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.98it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.73it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.43it/s] 69%|██████▉   | 25/36 [00:00<00:00, 32.42it/s] 81%|████████  | 29/36 [00:00<00:00, 30.26it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.09it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 55.63it/s] 33%|███▎      | 12/36 [00:00<00:00, 35.18it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.09it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.20it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.27it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.67it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 29.96it/s]100%|██████████| 36/36 [00:01<00:00, 31.83it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.38it/s] 33%|███▎      | 9/27 [00:00<00:00, 42.90it/s] 52%|█████▏    | 14/27 [00:00<00:00, 35.57it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.54it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.46it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.57it/s]100%|██████████| 27/27 [00:00<00:00, 33.09it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  8%|▊         | 3/36 [00:00<00:01, 28.98it/s] 19%|█▉        | 7/36 [00:00<00:00, 31.52it/s] 36%|███▌      | 13/36 [00:00<00:00, 39.12it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.51it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.83it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.10it/s] 81%|████████  | 29/36 [00:00<00:00, 31.53it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.55it/s]100%|██████████| 36/36 [00:01<00:00, 31.63it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.14it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.31it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.07it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.78it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.02it/s] 81%|████████  | 29/36 [00:00<00:00, 30.54it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.24it/s]100%|██████████| 36/36 [00:01<00:00, 31.88it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.54it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.96it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.50it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.85it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.70it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.94it/s] 50%|█████     | 18/36 [00:00<00:00, 34.09it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.85it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.12it/s]100%|██████████| 36/36 [00:01<00:00, 32.44it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset548_DWI_ADC_Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset548_DWI_ADC_Gen  ────────
────────  evaluating  (post) Dataset548_DWI_ADC_Gen  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset551_30T2_30STIR  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:50,  1.43s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.87it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.20it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.56it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.73it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.56it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.94it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.48it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.84it/s]100%|██████████| 36/36 [00:02<00:00, 14.40it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.01it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.49it/s] 50%|█████     | 18/36 [00:00<00:00, 34.27it/s] 61%|██████    | 22/36 [00:00<00:00, 32.62it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.58it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.93it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.46it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.26it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.32it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.23it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.59it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.56it/s]100%|██████████| 27/27 [00:00<00:00, 33.86it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.78it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.99it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.55it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.85it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.55it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.01it/s] 50%|█████     | 18/36 [00:00<00:00, 34.05it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 51.28it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.14it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.50it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.08it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.23it/s]100%|██████████| 27/27 [00:00<00:00, 33.04it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.80it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.09it/s] 61%|██████    | 22/36 [00:00<00:00, 32.48it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 54.36it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.16it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.03it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.43it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.43it/s] 81%|████████  | 29/36 [00:00<00:00, 30.83it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.40it/s]100%|██████████| 36/36 [00:01<00:00, 32.30it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.96it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.99it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.00it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.36it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.41it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 32.32it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 50.39it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.49it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.87it/s] 58%|█████▊    | 21/36 [00:00<00:00, 33.13it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.85it/s] 81%|████████  | 29/36 [00:00<00:00, 31.07it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.56it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.76it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.61it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.81it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.26it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.27it/s] 81%|████████  | 29/36 [00:00<00:00, 29.60it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.65it/s]100%|██████████| 36/36 [00:01<00:00, 32.18it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 56.45it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.35it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.76it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.31it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.39it/s]100%|██████████| 27/27 [00:00<00:00, 33.58it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 53.99it/s] 33%|███▎      | 12/36 [00:00<00:00, 39.46it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.72it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.57it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.81it/s] 81%|████████  | 29/36 [00:00<00:00, 30.17it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.55it/s]100%|██████████| 36/36 [00:01<00:00, 32.33it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.33it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.99it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.44it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.03it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.07it/s] 81%|████████  | 29/36 [00:00<00:00, 29.42it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.57it/s]100%|██████████| 36/36 [00:01<00:00, 31.90it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.10it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.50it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.01it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.21it/s] 81%|████████  | 29/36 [00:00<00:00, 30.65it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 32.06it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.65it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.61it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset551_30T2_30STIR  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset551_30T2_30STIR  ────────
────────  evaluating  (post) Dataset551_30T2_30STIR  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset552_30T2_30STIR_ALLDWIADC  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:50,  1.43s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.87it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.20it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.55it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.72it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.53it/s] 78%|███████▊  | 28/36 [00:02<00:00, 21.91it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.45it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.81it/s]100%|██████████| 36/36 [00:02<00:00, 14.39it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.50it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.81it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.68it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.74it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.60it/s] 81%|████████  | 29/36 [00:00<00:00, 30.91it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.31it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.28it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.30it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.17it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.52it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.78it/s]100%|██████████| 27/27 [00:00<00:00, 33.69it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 53.58it/s] 48%|████▊     | 13/27 [00:00<00:00, 35.97it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.42it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.98it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.12it/s]100%|██████████| 27/27 [00:00<00:00, 33.00it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.21it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.28it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.58it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.06it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.18it/s] 81%|████████  | 29/36 [00:00<00:00, 30.62it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.25it/s]100%|██████████| 36/36 [00:01<00:00, 32.05it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.57it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.92it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.22it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.51it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.66it/s]100%|██████████| 27/27 [00:00<00:00, 33.79it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.43it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.25it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.35it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.16it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.24it/s] 81%|████████  | 29/36 [00:00<00:00, 30.63it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.06it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.77it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.00it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.99it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.31it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.36it/s] 81%|████████  | 29/36 [00:00<00:00, 30.73it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.21it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.69it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.04it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.46it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.80it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.37it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.66it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.93it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.93it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.32it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.33it/s] 81%|████████  | 29/36 [00:00<00:00, 30.71it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 32.26it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.40it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.66it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.24it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.87it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.06it/s] 81%|████████  | 29/36 [00:00<00:00, 30.52it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.11it/s]100%|██████████| 36/36 [00:01<00:00, 31.91it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.52it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.90it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.04it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.42it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.46it/s]100%|██████████| 27/27 [00:00<00:00, 33.78it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.77it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.96it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.40it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.98it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.13it/s] 81%|████████  | 29/36 [00:00<00:00, 30.57it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 32.04it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.85it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.49it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.71it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.17it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.24it/s] 81%|████████  | 29/36 [00:00<00:00, 30.65it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.13it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.88it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.87it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.48it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.82it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.39it/s]100%|██████████| 36/36 [00:01<00:00, 32.60it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.45it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.63it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.22it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.87it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.04it/s] 81%|████████  | 29/36 [00:00<00:00, 30.52it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.18it/s]100%|██████████| 36/36 [00:01<00:00, 31.90it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset552_30T2_30STIR_ALLDWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset552_30T2_30STIR_ALLDWIADC  ────────
────────  evaluating  (post) Dataset552_30T2_30STIR_ALLDWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset553_30T2_30STIR_60DWIADC  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:55,  1.59s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.25it/s] 33%|███▎      | 12/36 [00:01<00:02,  9.40it/s] 44%|████▍     | 16/36 [00:02<00:01, 11.94it/s] 58%|█████▊    | 21/36 [00:02<00:00, 16.77it/s] 69%|██████▉   | 25/36 [00:02<00:00, 19.41it/s] 81%|████████  | 29/36 [00:02<00:00, 21.72it/s] 92%|█████████▏| 33/36 [00:02<00:00, 23.62it/s]100%|██████████| 36/36 [00:02<00:00, 13.53it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.75it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.43it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.89it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.91it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.57it/s] 81%|████████  | 29/36 [00:00<00:00, 30.95it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.50it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 57.22it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.65it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.90it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.36it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.41it/s]100%|██████████| 27/27 [00:00<00:00, 33.66it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 51.07it/s] 48%|████▊     | 13/27 [00:00<00:00, 35.38it/s] 63%|██████▎   | 17/27 [00:00<00:00, 33.06it/s] 78%|███████▊  | 21/27 [00:00<00:00, 31.82it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.00it/s]100%|██████████| 27/27 [00:00<00:00, 32.74it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 59.12it/s] 33%|███▎      | 12/36 [00:00<00:00, 38.34it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.11it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.46it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.45it/s] 81%|████████  | 29/36 [00:00<00:00, 30.80it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 32.38it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.32it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.84it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.82it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.52it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.22it/s]100%|██████████| 27/27 [00:00<00:00, 33.33it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.37it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.88it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.36it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.92it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.10it/s] 81%|████████  | 29/36 [00:00<00:00, 30.56it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.21it/s]100%|██████████| 36/36 [00:01<00:00, 31.96it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.46it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.90it/s] 50%|█████     | 18/36 [00:00<00:00, 33.99it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.83it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.39it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.49it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.89it/s] 50%|█████     | 18/36 [00:00<00:00, 34.03it/s] 61%|██████    | 22/36 [00:00<00:00, 32.44it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.81it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.21it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.28it/s] 50%|█████     | 18/36 [00:00<00:00, 33.70it/s] 61%|██████    | 22/36 [00:00<00:00, 32.26it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.31it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.73it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.46it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.86it/s] 50%|█████     | 18/36 [00:00<00:00, 33.58it/s] 61%|██████    | 22/36 [00:00<00:00, 32.59it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.55it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.91it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.50it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.87it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.04it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.46it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.45it/s]100%|██████████| 27/27 [00:00<00:00, 33.77it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.70it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.38it/s] 50%|█████     | 18/36 [00:00<00:00, 33.78it/s] 61%|██████    | 22/36 [00:00<00:00, 32.29it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.35it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.73it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.41it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.51it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.92it/s] 50%|█████     | 18/36 [00:00<00:00, 33.99it/s] 61%|██████    | 22/36 [00:00<00:00, 32.44it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.48it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.80it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.58it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.67it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.02it/s] 61%|██████    | 22/36 [00:00<00:00, 32.45it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.47it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.82it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.39it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.03it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.55it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.75it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.21it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.23it/s] 81%|████████  | 29/36 [00:00<00:00, 30.69it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 32.15it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset553_30T2_30STIR_60DWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset553_30T2_30STIR_60DWIADC  ────────
────────  evaluating  (post) Dataset553_30T2_30STIR_60DWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset554_30T1_30T1C  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:03<02:07,  3.64s/it] 22%|██▏       | 8/36 [00:03<00:09,  2.89it/s] 33%|███▎      | 12/36 [00:03<00:05,  4.69it/s] 44%|████▍     | 16/36 [00:04<00:02,  6.88it/s] 56%|█████▌    | 20/36 [00:04<00:01,  9.42it/s] 67%|██████▋   | 24/36 [00:04<00:00, 12.19it/s] 78%|███████▊  | 28/36 [00:04<00:00, 15.00it/s] 86%|████████▌ | 31/36 [00:04<00:00, 17.12it/s] 97%|█████████▋| 35/36 [00:04<00:00, 19.98it/s]100%|██████████| 36/36 [00:04<00:00,  7.65it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 44.90it/s] 28%|██▊       | 10/36 [00:00<00:00, 42.55it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.36it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.15it/s] 64%|██████▍   | 23/36 [00:00<00:00, 32.10it/s] 75%|███████▌  | 27/36 [00:00<00:00, 31.22it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.51it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.28it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 54.64it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.63it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.10it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.76it/s] 96%|█████████▋| 26/27 [00:00<00:00, 30.68it/s]100%|██████████| 27/27 [00:00<00:00, 33.45it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s]  7%|▋         | 2/27 [00:00<00:01, 18.48it/s] 19%|█▊        | 5/27 [00:00<00:01, 21.81it/s] 33%|███▎      | 9/27 [00:00<00:00, 26.78it/s] 48%|████▊     | 13/27 [00:00<00:00, 30.14it/s] 67%|██████▋   | 18/27 [00:00<00:00, 31.19it/s] 81%|████████▏ | 22/27 [00:00<00:00, 29.79it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.51it/s]100%|██████████| 27/27 [00:00<00:00, 30.37it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.37it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.36it/s] 50%|█████     | 18/36 [00:00<00:00, 33.22it/s] 61%|██████    | 22/36 [00:00<00:00, 32.47it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.46it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.84it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.42it/s]100%|██████████| 36/36 [00:01<00:00, 32.43it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.62it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.98it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.06it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.49it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.50it/s]100%|██████████| 27/27 [00:00<00:00, 33.51it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 14%|█▍        | 5/36 [00:00<00:00, 49.10it/s] 28%|██▊       | 10/36 [00:00<00:00, 41.67it/s] 42%|████▏     | 15/36 [00:00<00:00, 35.06it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.06it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.77it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.15it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.62it/s] 97%|█████████▋| 35/36 [00:01<00:00, 29.86it/s]100%|██████████| 36/36 [00:01<00:00, 32.25it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.02it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.08it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.07it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.40it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.35it/s] 81%|████████  | 29/36 [00:00<00:00, 30.74it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.38it/s]100%|██████████| 36/36 [00:01<00:00, 32.34it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.35it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.70it/s] 50%|█████     | 18/36 [00:00<00:00, 34.33it/s] 61%|██████    | 22/36 [00:00<00:00, 32.37it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.72it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.02it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.54it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 56.94it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.12it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 32.07it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.67it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.64it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.48it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 51.20it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.26it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.62it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.15it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.24it/s] 81%|████████  | 29/36 [00:00<00:00, 30.64it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.28it/s]100%|██████████| 36/36 [00:01<00:00, 32.09it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.66it/s] 48%|████▊     | 13/27 [00:00<00:00, 38.02it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.08it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.53it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.48it/s]100%|██████████| 27/27 [00:00<00:00, 33.85it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.91it/s] 50%|█████     | 18/36 [00:00<00:00, 34.10it/s] 61%|██████    | 22/36 [00:00<00:00, 32.50it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.50it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.47it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.71it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.85it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.28it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.34it/s] 81%|████████  | 29/36 [00:00<00:00, 30.74it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.34it/s]100%|██████████| 36/36 [00:01<00:00, 32.24it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:09,  3.58it/s] 22%|██▏       | 8/36 [00:00<00:01, 23.60it/s] 33%|███▎      | 12/36 [00:00<00:00, 25.83it/s] 44%|████▍     | 16/36 [00:00<00:00, 27.12it/s] 56%|█████▌    | 20/36 [00:00<00:00, 27.90it/s] 67%|██████▋   | 24/36 [00:00<00:00, 28.41it/s] 75%|███████▌  | 27/36 [00:01<00:00, 28.68it/s] 83%|████████▎ | 30/36 [00:01<00:00, 28.90it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.07it/s]100%|██████████| 36/36 [00:01<00:00, 29.19it/s]100%|██████████| 36/36 [00:01<00:00, 26.49it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.52it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.96it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.50it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.86it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.44it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset554_30T1_30T1C  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset554_30T1_30T1C  ────────
────────  evaluating  (post) Dataset554_30T1_30T1C  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset555_30T1_30T1C_60DWIADC  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.41s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.83it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.35it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.64it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.92it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.72it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.08it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.59it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.92it/s]100%|██████████| 36/36 [00:02<00:00, 14.49it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:00<00:09,  3.53it/s] 19%|█▉        | 7/36 [00:00<00:01, 21.74it/s] 31%|███       | 11/36 [00:00<00:01, 24.81it/s] 42%|████▏     | 15/36 [00:00<00:00, 26.02it/s] 53%|█████▎    | 19/36 [00:00<00:00, 27.56it/s] 64%|██████▍   | 23/36 [00:00<00:00, 28.34it/s] 75%|███████▌  | 27/36 [00:01<00:00, 28.64it/s] 83%|████████▎ | 30/36 [00:01<00:00, 28.93it/s] 92%|█████████▏| 33/36 [00:01<00:00, 28.86it/s]100%|██████████| 36/36 [00:01<00:00, 28.34it/s]100%|██████████| 36/36 [00:01<00:00, 25.96it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 11%|█         | 3/27 [00:00<00:00, 29.26it/s] 30%|██▉       | 8/27 [00:00<00:00, 34.63it/s] 48%|████▊     | 13/27 [00:00<00:00, 39.88it/s] 63%|██████▎   | 17/27 [00:00<00:00, 35.08it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.89it/s] 93%|█████████▎| 25/27 [00:00<00:00, 32.40it/s]100%|██████████| 27/27 [00:00<00:00, 33.28it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.69it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.99it/s] 67%|██████▋   | 18/27 [00:00<00:00, 34.09it/s] 81%|████████▏ | 22/27 [00:00<00:00, 32.54it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.53it/s]100%|██████████| 27/27 [00:00<00:00, 33.85it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  6%|▌         | 2/36 [00:00<00:02, 15.74it/s] 19%|█▉        | 7/36 [00:00<00:00, 33.02it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.93it/s] 44%|████▍     | 16/36 [00:00<00:00, 33.45it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.22it/s] 67%|██████▋   | 24/36 [00:00<00:00, 30.83it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.40it/s] 89%|████████▉ | 32/36 [00:01<00:00, 29.94it/s]100%|██████████| 36/36 [00:01<00:00, 30.35it/s]100%|██████████| 36/36 [00:01<00:00, 30.86it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 47.65it/s] 37%|███▋      | 10/27 [00:00<00:00, 40.56it/s] 56%|█████▌    | 15/27 [00:00<00:00, 34.19it/s] 70%|███████   | 19/27 [00:00<00:00, 33.16it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.88it/s]100%|██████████| 27/27 [00:00<00:00, 31.09it/s]100%|██████████| 27/27 [00:00<00:00, 33.20it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.70it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.96it/s] 50%|█████     | 18/36 [00:00<00:00, 34.09it/s] 61%|██████    | 22/36 [00:00<00:00, 32.51it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.07it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.56it/s]100%|██████████| 36/36 [00:01<00:00, 32.49it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.49it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.80it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.12it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.44it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.43it/s] 81%|████████  | 29/36 [00:00<00:00, 30.81it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.19it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.56it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.92it/s] 50%|█████     | 18/36 [00:00<00:00, 34.07it/s] 61%|██████    | 22/36 [00:00<00:00, 31.68it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.68it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.24it/s] 94%|█████████▍| 34/36 [00:01<00:00, 29.70it/s]100%|██████████| 36/36 [00:01<00:00, 32.62it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 49.35it/s] 31%|███       | 11/36 [00:00<00:00, 36.71it/s] 42%|████▏     | 15/36 [00:00<00:00, 33.18it/s] 53%|█████▎    | 19/36 [00:00<00:00, 32.72it/s] 64%|██████▍   | 23/36 [00:00<00:00, 31.19it/s] 75%|███████▌  | 27/36 [00:00<00:00, 30.96it/s] 86%|████████▌ | 31/36 [00:00<00:00, 30.04it/s] 97%|█████████▋| 35/36 [00:01<00:00, 30.29it/s]100%|██████████| 36/36 [00:01<00:00, 31.90it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.76it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.17it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.12it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.44it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.38it/s] 81%|████████  | 29/36 [00:00<00:00, 30.80it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.71it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.34it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.82it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.30it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.70it/s]100%|██████████| 27/27 [00:00<00:00, 33.57it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 11%|█         | 4/36 [00:00<00:00, 34.80it/s] 25%|██▌       | 9/36 [00:00<00:00, 38.13it/s] 36%|███▌      | 13/36 [00:00<00:00, 35.29it/s] 47%|████▋     | 17/36 [00:00<00:00, 32.10it/s] 58%|█████▊    | 21/36 [00:00<00:00, 31.09it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.28it/s] 81%|████████  | 29/36 [00:00<00:00, 29.99it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.88it/s]100%|██████████| 36/36 [00:01<00:00, 30.99it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 55.17it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.99it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.02it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.36it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.38it/s] 81%|████████  | 29/36 [00:00<00:00, 30.77it/s] 92%|█████████▏| 33/36 [00:01<00:00, 29.54it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.54it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.99it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.34it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.57it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.90it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.63it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.75it/s] 36%|███▌      | 13/36 [00:00<00:00, 38.00it/s] 50%|█████     | 18/36 [00:00<00:00, 34.06it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.49it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.60it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.32it/s]100%|██████████| 36/36 [00:01<00:00, 32.59it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset555_30T1_30T1C_60DWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset555_30T1_30T1C_60DWIADC  ────────
────────  evaluating  (post) Dataset555_30T1_30T1C_60DWIADC  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

────────  predicting Dataset556_30T1_30T1C_60DWIADC_30T2_30STIR  ────────
/home/rth/jdekok/my-scratch/.conda/envs/nnunet_env2/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

There are 16 cases in the source folder
I am process 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 16 cases that I would like to predict

Predicting 000:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:49,  1.41s/it] 22%|██▏       | 8/36 [00:01<00:04,  6.97it/s] 33%|███▎      | 12/36 [00:01<00:02, 10.34it/s] 44%|████▍     | 16/36 [00:01<00:01, 13.70it/s] 56%|█████▌    | 20/36 [00:01<00:00, 16.87it/s] 67%|██████▋   | 24/36 [00:02<00:00, 19.68it/s] 78%|███████▊  | 28/36 [00:02<00:00, 22.03it/s] 86%|████████▌ | 31/36 [00:02<00:00, 23.56it/s] 94%|█████████▍| 34/36 [00:02<00:00, 24.89it/s]100%|██████████| 36/36 [00:02<00:00, 14.53it/s]
sending off prediction to background worker for resampling and export
done with 000

Predicting 001:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.62it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.89it/s] 50%|█████     | 18/36 [00:00<00:00, 34.05it/s] 61%|██████    | 22/36 [00:00<00:00, 31.85it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.56it/s] 83%|████████▎ | 30/36 [00:00<00:00, 31.05it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.56it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 001

Predicting 002:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 19%|█▊        | 5/27 [00:00<00:00, 47.36it/s] 37%|███▋      | 10/27 [00:00<00:00, 42.99it/s] 56%|█████▌    | 15/27 [00:00<00:00, 35.83it/s] 70%|███████   | 19/27 [00:00<00:00, 32.69it/s] 85%|████████▌ | 23/27 [00:00<00:00, 31.58it/s]100%|██████████| 27/27 [00:00<00:00, 31.24it/s]100%|██████████| 27/27 [00:00<00:00, 33.49it/s]
sending off prediction to background worker for resampling and export
done with 002

Predicting 003:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 55.62it/s] 48%|████▊     | 13/27 [00:00<00:00, 36.99it/s] 63%|██████▎   | 17/27 [00:00<00:00, 34.02it/s] 78%|███████▊  | 21/27 [00:00<00:00, 32.39it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.40it/s]100%|██████████| 27/27 [00:00<00:00, 33.45it/s]
sending off prediction to background worker for resampling and export
done with 003

Predicting 004:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.79it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.04it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.43it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.41it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.56it/s] 81%|████████  | 29/36 [00:00<00:00, 30.54it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.52it/s]100%|██████████| 36/36 [00:01<00:00, 32.35it/s]
sending off prediction to background worker for resampling and export
done with 004

Predicting 005:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 26%|██▌       | 7/27 [00:00<00:00, 58.22it/s] 48%|████▊     | 13/27 [00:00<00:00, 37.93it/s] 67%|██████▋   | 18/27 [00:00<00:00, 33.96it/s] 81%|████████▏ | 22/27 [00:00<00:00, 31.86it/s] 96%|█████████▋| 26/27 [00:00<00:00, 31.73it/s]100%|██████████| 27/27 [00:00<00:00, 33.83it/s]
sending off prediction to background worker for resampling and export
done with 005

Predicting 006:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.27it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.97it/s] 50%|█████     | 18/36 [00:00<00:00, 34.11it/s] 61%|██████    | 22/36 [00:00<00:00, 32.52it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.88it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.64it/s]
sending off prediction to background worker for resampling and export
done with 006

Predicting 007:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.74it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.95it/s] 50%|█████     | 18/36 [00:00<00:00, 33.71it/s] 61%|██████    | 22/36 [00:00<00:00, 32.64it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.61it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.90it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.34it/s]100%|██████████| 36/36 [00:01<00:00, 32.37it/s]
sending off prediction to background worker for resampling and export
done with 007

Predicting 008:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 50.21it/s] 33%|███▎      | 12/36 [00:00<00:00, 37.63it/s] 44%|████▍     | 16/36 [00:00<00:00, 34.80it/s] 56%|█████▌    | 20/36 [00:00<00:00, 32.18it/s] 67%|██████▋   | 24/36 [00:00<00:00, 31.98it/s] 78%|███████▊  | 28/36 [00:00<00:00, 30.94it/s] 89%|████████▉ | 32/36 [00:00<00:00, 30.70it/s]100%|██████████| 36/36 [00:01<00:00, 29.93it/s]100%|██████████| 36/36 [00:01<00:00, 32.17it/s]
sending off prediction to background worker for resampling and export
done with 008

Predicting 009:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 53.94it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.10it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.54it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.09it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.20it/s] 81%|████████  | 29/36 [00:00<00:00, 30.64it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.27it/s]100%|██████████| 36/36 [00:01<00:00, 32.12it/s]
sending off prediction to background worker for resampling and export
done with 009

Predicting 010:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 17%|█▋        | 6/36 [00:00<00:00, 58.70it/s] 33%|███▎      | 12/36 [00:00<00:00, 36.71it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.59it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.19it/s] 69%|██████▉   | 25/36 [00:00<00:00, 30.45it/s] 81%|████████  | 29/36 [00:00<00:00, 30.85it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.25it/s]100%|██████████| 36/36 [00:01<00:00, 32.15it/s]
sending off prediction to background worker for resampling and export
done with 010

Predicting 011:
perform_everything_on_device: True
  0%|          | 0/27 [00:00<?, ?it/s] 15%|█▍        | 4/27 [00:00<00:00, 36.64it/s] 30%|██▉       | 8/27 [00:00<00:00, 37.84it/s] 44%|████▍     | 12/27 [00:00<00:00, 34.99it/s] 63%|██████▎   | 17/27 [00:00<00:00, 35.68it/s] 78%|███████▊  | 21/27 [00:00<00:00, 34.02it/s] 93%|█████████▎| 25/27 [00:00<00:00, 31.87it/s]100%|██████████| 27/27 [00:00<00:00, 33.53it/s]
sending off prediction to background worker for resampling and export
done with 011

Predicting 012:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 54.37it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.12it/s] 47%|████▋     | 17/36 [00:00<00:00, 34.08it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.41it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.42it/s] 81%|████████  | 29/36 [00:00<00:00, 30.79it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.36it/s]100%|██████████| 36/36 [00:01<00:00, 32.36it/s]
sending off prediction to background worker for resampling and export
done with 012

Predicting 013:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.68it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.96it/s] 50%|█████     | 18/36 [00:00<00:00, 34.08it/s] 61%|██████    | 22/36 [00:00<00:00, 32.49it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.52it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.90it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.45it/s]100%|██████████| 36/36 [00:01<00:00, 32.65it/s]
sending off prediction to background worker for resampling and export
done with 013

Predicting 014:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 58.54it/s] 36%|███▌      | 13/36 [00:00<00:00, 37.93it/s] 50%|█████     | 18/36 [00:00<00:00, 34.12it/s] 61%|██████    | 22/36 [00:00<00:00, 32.53it/s] 72%|███████▏  | 26/36 [00:00<00:00, 31.53it/s] 83%|████████▎ | 30/36 [00:00<00:00, 30.87it/s] 94%|█████████▍| 34/36 [00:01<00:00, 30.43it/s]100%|██████████| 36/36 [00:01<00:00, 32.10it/s]
sending off prediction to background worker for resampling and export
done with 014

Predicting 015:
perform_everything_on_device: True
  0%|          | 0/36 [00:00<?, ?it/s] 19%|█▉        | 7/36 [00:00<00:00, 52.87it/s] 36%|███▌      | 13/36 [00:00<00:00, 36.80it/s] 47%|████▋     | 17/36 [00:00<00:00, 33.90it/s] 58%|█████▊    | 21/36 [00:00<00:00, 32.31it/s] 69%|██████▉   | 25/36 [00:00<00:00, 31.35it/s] 81%|████████  | 29/36 [00:00<00:00, 30.73it/s] 92%|█████████▏| 33/36 [00:01<00:00, 30.34it/s]100%|██████████| 36/36 [00:01<00:00, 32.26it/s]
sending off prediction to background worker for resampling and export
done with 015
────────  evaluating  (raw) Dataset556_30T1_30T1C_60DWIADC_30T2_30STIR  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer
────────  post-processing Dataset556_30T1_30T1C_60DWIADC_30T2_30STIR  ────────
────────  evaluating  (post) Dataset556_30T1_30T1C_60DWIADC_30T2_30STIR  ────────
Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer

✅  all combinations finished

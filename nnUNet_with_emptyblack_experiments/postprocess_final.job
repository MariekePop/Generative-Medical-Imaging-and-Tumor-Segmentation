#!/bin/bash
#
# slurm specific parameters should be defined as comment line starting with #SBATCH
#SBATCH --job-name=post_final
#SBATCH --output=post_final.out
#SBATCH --gres=gpu:1g.10gb:1       # number of GPUs (type MIG 1g.10gb)
#SBATCH --partition=luna-gpu-short  # using luna-gpu-short queue for a job that request up to 8h
#SBATCH --mem=4G                   # max memory per node
#SBATCH --cpus-per-task=1          # max CPU cores per process
#SBATCH --time=00-0:30             # time limit (DD-HH:MM)
#SBATCH --nice=1               # allow other priority jobs to go first

export MKL_INTERFACE_LAYER=${MKL_INTERFACE_LAYER:-LP64}

export nnUNet_raw=/home/rth/jdekok/my-scratch/nnunetv2/nnUNet/nnUNet_raw
export nnUNet_preprocessed=/home/rth/jdekok/my-scratch/nnunetv2/nnUNet/nnUNet_preprocessed
export nnUNet_results=/home/rth/jdekok/my-scratch/nnunetv2/nnUNet/nnUNet_results

module load Anaconda3/2024.02-1

# some applications can use a specific number of cores, so specify how many are reserved
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

# just print which gpu device was selected by slurm
echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"

# make sure the required applications and versions are enabled

# Activate your virtual environment
conda activate nnunet_env2


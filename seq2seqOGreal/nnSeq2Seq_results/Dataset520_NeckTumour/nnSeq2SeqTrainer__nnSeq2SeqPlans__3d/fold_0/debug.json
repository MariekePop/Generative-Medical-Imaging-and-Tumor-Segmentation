{
    "_best_ema": "None",
    "batch_size": "1",
    "configuration_manager": "{'data_identifier': 'nnSeq2SeqPlans_3d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [10, 192, 192], 'median_image_size_in_voxels': [29.0, 515.0, 560.0], 'spacing': [4.400000095367432, 0.4296875, 0.4296875], 'normalization_schemes': ['Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'nnseq2seq.networks.seq2seq.seq2seq.Seq2Seq3d', 'arch_kwargs': {'image_encoder': {'in_channels': 1, 'conv_channels': [16, 32, 64, 128, 256], 'conv_kernel': [3, 2, 2, 2, 2], 'conv_stride': [1, 2, 2, 2, 2], 'resblock_n': [0, 1, 2, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'vq_n_embed': 8192, 'vq_beta': 0.25}, 'image_decoder': {'out_channels': 1, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'deep_supervision': True, 'focal_mode': 'focal_mix'}, 'segmentor': {'in_channels': 1, 'num_classes': 2, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'latent_space_dim': 3, 'deep_supervision': True}, 'discriminator': {'in_channels': 1, 'ndf': 16, 'hyper_conv_dim': 16, 'style_dim': 6, 'layer_scale_init_value': 1e-06, 'n_layers': 3, 'kw': 4, 'padw': 1}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False}",
    "configuration_name": "3d",
    "cudnn_version": "None",
    "current_epoch": "0",
    "dataloader_train": "<nnseq2seq.training.data_augmentation.custom_transforms.limited_length_multithreaded_augmenter.LimitedLenWrapper object at 0x000002307317B280>",
    "dataloader_train.generator": "<nnseq2seq.training.dataloading.data_loader_3d.nnSeq2SeqDataLoader3D object at 0x000002307317A830>",
    "dataloader_train.num_processes": "12",
    "dataloader_train.transform": "Compose ( [Convert3DTo2DTransform( apply_to_keys = ('data', 'seg') ), SpatialTransform( independent_scale_for_each_axis = False, p_rot_per_sample = 0.2, p_scale_per_sample = 0.2, p_el_per_sample = 0, data_key = 'data', label_key = 'seg', patch_size = [192, 192], patch_center_dist_from_border = None, do_elastic_deform = False, alpha = (0, 0), sigma = (0, 0), do_rotation = True, angle_x = (-3.141592653589793, 3.141592653589793), angle_y = (0, 0), angle_z = (0, 0), do_scale = True, scale = (0.7, 1.4), border_mode_data = 'nearest', border_cval_data = 0, order_data = 3, border_mode_seg = 'constant', border_cval_seg = -1, order_seg = 1, random_crop = False, p_rot_per_axis = 1, p_independent_scale_per_axis = 1 ), Convert2DTo3DTransform( apply_to_keys = ('data', 'seg') ), MirrorTransform( p_per_sample = 1, data_key = 'data', label_key = 'seg', axes = (0, 1, 2) ), CopyDataTransform( output_key = 'ori_data', input_key = 'data' ), GaussianNoiseTransform( p_per_sample = 0.1, data_key = 'data', noise_variance = (0, 0.1), p_per_channel = 1, per_channel = False ), GaussianBlurTransform( p_per_sample = 0.2, different_sigma_per_channel = True, p_per_channel = 0.5, data_key = 'data', blur_sigma = (0.5, 1.0), different_sigma_per_axis = False, p_isotropic = 0 ), BrightnessMultiplicativeTransform( p_per_sample = 0.15, data_key = 'data', multiplier_range = (0.75, 1.25), per_channel = True ), ContrastAugmentationTransform( p_per_sample = 0.15, data_key = 'data', contrast_range = (0.75, 1.25), preserve_range = True, per_channel = True, p_per_channel = 1 ), SimulateLowResolutionTransform( order_upsample = 3, order_downsample = 0, channels = None, per_channel = True, p_per_channel = 0.5, p_per_sample = 0.25, data_key = 'data', zoom_range = (0.5, 1), ignore_axes = (0,) ), GammaTransform( p_per_sample = 0.1, retain_stats = True, per_channel = True, data_key = 'data', gamma_range = (0.7, 1.5), invert_image = True ), GammaTransform( p_per_sample = 0.3, retain_stats = True, per_channel = True, data_key = 'data', gamma_range = (0.7, 1.5), invert_image = False ), RemoveLabelTransform( output_key = 'seg', input_key = 'seg', replace_with = 0, remove_label = -1 ), RenameTransform( delete_old = True, out_key = 'target', in_key = 'seg' ), DownsampleSegForDSTransform2( axes = None, output_key = 'target', input_key = 'target', order = 0, ds_scales = [1.0, 0.5, 0.25, 0.125, 0.0625] ), NumpyToTensor( keys = ['ori_data', 'data', 'target'], cast_to = 'float' )] )",
    "dataloader_val": "<nnseq2seq.training.data_augmentation.custom_transforms.limited_length_multithreaded_augmenter.LimitedLenWrapper object at 0x000002307317BCD0>",
    "dataloader_val.generator": "<nnseq2seq.training.dataloading.data_loader_3d.nnSeq2SeqDataLoader3D object at 0x000002307317B760>",
    "dataloader_val.num_processes": "6",
    "dataloader_val.transform": "Compose ( [RemoveLabelTransform( output_key = 'seg', input_key = 'seg', replace_with = 0, remove_label = -1 ), RenameTransform( delete_old = True, out_key = 'target', in_key = 'seg' ), DownsampleSegForDSTransform2( axes = None, output_key = 'target', input_key = 'target', order = 0, ds_scales = [1.0, 0.5, 0.25, 0.125, 0.0625] ), NumpyToTensor( keys = ['data', 'target'], cast_to = 'float' )] )",
    "dataset_json": "{'channel_names': {'0': 'T1', '1': 'T1C', '2': 'T2', '3': 'STIR', '4': 'DWI', '5': 'ADC'}, 'labels': {'background': 0, 'cancer': 1}, 'numChannel': 6, 'numTraining': 2, 'file_ending': '.nii.gz', 'overwrite_image_reader_writer': 'SimpleITKIO'}",
    "device": "cpu",
    "disable_checkpointing": "False",
    "enable_deep_supervision": "True",
    "fold": "0",
    "folder_with_segs_from_previous_stage": "None",
    "grad_scaler": "None",
    "hostname": "8CC23829NC",
    "img_dis": "None",
    "inference_allowed_mirroring_axes": "(0, 1, 2)",
    "initial_lr": "0.0002",
    "is_cascaded": "False",
    "is_ddp": "False",
    "label_manager": "<nnseq2seq.utilities.label_handling.label_handling.LabelManager object at 0x00000230722F7F70>",
    "local_rank": "0",
    "log_file": "C:\\Users\\P095789\\OneDrive - Amsterdam UMC\\Documenten\\mri_seq2seq-main\\nnSeq2Seq_results\\Dataset520_NeckTumour\\nnSeq2SeqTrainer__nnSeq2SeqPlans__3d\\fold_0\\training_log_2025_3_3_14_19_32.txt",
    "logger": "<nnseq2seq.training.logging.nnseq2seq_logger.nnSeq2SeqLogger object at 0x00000230722F7E20>",
    "loss": "DeepSupervisionWrapper(\n  (loss): L1_SSIM_and_Perceptual_loss(\n    (l1): L1Loss()\n    (ssim): SSIMLoss()\n    (perceptual): AdaptivePerceptualLoss(\n      (vgg): Sequential(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): ReLU(inplace=True)\n        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (3): ReLU(inplace=True)\n        (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (6): ReLU(inplace=True)\n        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (8): ReLU(inplace=True)\n        (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (11): ReLU(inplace=True)\n        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (13): ReLU(inplace=True)\n        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (15): ReLU(inplace=True)\n        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (17): ReLU(inplace=True)\n        (18): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (20): ReLU(inplace=True)\n        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (22): ReLU(inplace=True)\n        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (24): ReLU(inplace=True)\n        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (26): ReLU(inplace=True)\n        (27): AvgPool2d(kernel_size=2, stride=2, padding=0)\n        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (29): ReLU(inplace=True)\n        (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (31): ReLU(inplace=True)\n        (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (33): ReLU(inplace=True)\n        (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (35): ReLU(inplace=True)\n        (36): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n    )\n  )\n)",
    "lr_scheduler": "<nnseq2seq.training.lr_scheduler.polylr.WarmupCosineLRScheduler object at 0x0000023073179EA0>",
    "my_init_kwargs": "{'plans': {'dataset_name': 'Dataset520_NeckTumour', 'plans_name': 'nnSeq2SeqPlans', 'original_median_spacing_after_transp': [4.400000095367432, 0.4296875, 0.4296875], 'original_median_shape_after_transp': [29, 515, 560], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'configurations': {'2d': {'data_identifier': 'nnSeq2SeqPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [256, 320], 'median_image_size_in_voxels': [515.0, 560.0], 'spacing': [0.4296875, 0.4296875], 'normalization_schemes': ['Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'nnseq2seq.networks.seq2seq.seq2seq.Seq2Seq2d', 'arch_kwargs': {'image_encoder': {'in_channels': 1, 'conv_channels': [32, 64, 128, 256, 256], 'conv_kernel': [3, 2, 2, 2, 2], 'conv_stride': [1, 2, 2, 2, 2], 'resblock_n': [2, 2, 4, 4, 4], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'vq_n_embed': 8192, 'vq_beta': 0.25}, 'image_decoder': {'out_channels': 1, 'conv_channels': [256, 256, 128, 64, 32], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [4, 4, 4, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'deep_supervision': True, 'focal_mode': 'focal_mix'}, 'segmentor': {'in_channels': 1, 'num_classes': 2, 'conv_channels': [256, 256, 128, 64, 32], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [4, 4, 4, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'latent_space_dim': 3, 'deep_supervision': True}, 'discriminator': {'in_channels': 1, 'ndf': 32, 'hyper_conv_dim': 16, 'style_dim': 6, 'layer_scale_init_value': 1e-06, 'n_layers': 3, 'kw': 4, 'padw': 1}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}, '3d': {'data_identifier': 'nnSeq2SeqPlans_3d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [10, 192, 192], 'median_image_size_in_voxels': [29.0, 515.0, 560.0], 'spacing': [4.400000095367432, 0.4296875, 0.4296875], 'normalization_schemes': ['Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'nnseq2seq.networks.seq2seq.seq2seq.Seq2Seq3d', 'arch_kwargs': {'image_encoder': {'in_channels': 1, 'conv_channels': [16, 32, 64, 128, 256], 'conv_kernel': [3, 2, 2, 2, 2], 'conv_stride': [1, 2, 2, 2, 2], 'resblock_n': [0, 1, 2, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'vq_n_embed': 8192, 'vq_beta': 0.25}, 'image_decoder': {'out_channels': 1, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'deep_supervision': True, 'focal_mode': 'focal_mix'}, 'segmentor': {'in_channels': 1, 'num_classes': 2, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'latent_space_dim': 3, 'deep_supervision': True}, 'discriminator': {'in_channels': 1, 'ndf': 16, 'hyper_conv_dim': 16, 'style_dim': 6, 'layer_scale_init_value': 1e-06, 'n_layers': 3, 'kw': 4, 'padw': 1}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False}}, 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 267.0, 'mean': 105.27149200439453, 'median': 105.0, 'min': 27.0, 'percentile_00_5': 61.0, 'percentile_99_5': 158.0, 'std': 18.445335388183594}, '1': {'max': 622.0, 'mean': 308.62164306640625, 'median': 313.0, 'min': 14.0, 'percentile_00_5': 129.0, 'percentile_99_5': 481.0, 'std': 61.370479583740234}, '2': {'max': 292.2086181640625, 'mean': 94.79603576660156, 'median': 90.01033782958984, 'min': 3.5035572052001953, 'percentile_00_5': 24.245834350585938, 'percentile_99_5': 184.52996826171875, 'std': 30.297283172607422}, '3': {'max': 607.82421875, 'mean': 256.9958801269531, 'median': 256.0714111328125, 'min': 21.118223190307617, 'percentile_00_5': 48.9947395324707, 'percentile_99_5': 449.9946594238281, 'std': 68.48628234863281}, '4': {'max': 782.535400390625, 'mean': 81.82330322265625, 'median': 33.67308044433594, 'min': 8.940948486328125, 'percentile_00_5': 10.96875, 'percentile_99_5': 506.26910400390625, 'std': 113.0}, '5': {'max': 4095.0, 'mean': 1518.48828125, 'median': 1545.581787109375, 'min': 0.0, 'percentile_00_5': 4.1741180419921875, 'percentile_99_5': 3541.29931640625, 'std': 716.7125854492188}}}, 'configuration': '3d', 'fold': 0, 'dataset_json': {'channel_names': {'0': 'T1', '1': 'T1C', '2': 'T2', '3': 'STIR', '4': 'DWI', '5': 'ADC'}, 'labels': {'background': 0, 'cancer': 1}, 'numChannel': 6, 'numTraining': 2, 'file_ending': '.nii.gz', 'overwrite_image_reader_writer': 'SimpleITKIO'}, 'unpack_dataset': True, 'device': device(type='cuda')}",
    "network": "Seq2Seq3d",
    "network_ema": "<nnseq2seq.networks.ema.EMAModel object at 0x0000023073179D80>",
    "num_epochs": "2000",
    "num_epochs_for_pretrain": "1000",
    "num_input_channels": "6",
    "num_iterations_per_epoch": "250",
    "num_val_iterations_per_epoch": "50",
    "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    initial_lr: 0.0002\n    lr: 1e-07\n    maximize: False\n    weight_decay: 0.05\n)",
    "optimizer_d": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.95)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0002\n    maximize: False\n    weight_decay: 0.05\n)",
    "output_folder": "C:\\Users\\P095789\\OneDrive - Amsterdam UMC\\Documenten\\mri_seq2seq-main\\nnSeq2Seq_results\\Dataset520_NeckTumour\\nnSeq2SeqTrainer__nnSeq2SeqPlans__3d\\fold_0",
    "output_folder_base": "C:\\Users\\P095789\\OneDrive - Amsterdam UMC\\Documenten\\mri_seq2seq-main\\nnSeq2Seq_results\\Dataset520_NeckTumour\\nnSeq2SeqTrainer__nnSeq2SeqPlans__3d",
    "oversample_foreground_percent": "0.33",
    "plans_manager": "{'dataset_name': 'Dataset520_NeckTumour', 'plans_name': 'nnSeq2SeqPlans', 'original_median_spacing_after_transp': [4.400000095367432, 0.4296875, 0.4296875], 'original_median_shape_after_transp': [29, 515, 560], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'configurations': {'2d': {'data_identifier': 'nnSeq2SeqPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [256, 320], 'median_image_size_in_voxels': [515.0, 560.0], 'spacing': [0.4296875, 0.4296875], 'normalization_schemes': ['Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'nnseq2seq.networks.seq2seq.seq2seq.Seq2Seq2d', 'arch_kwargs': {'image_encoder': {'in_channels': 1, 'conv_channels': [32, 64, 128, 256, 256], 'conv_kernel': [3, 2, 2, 2, 2], 'conv_stride': [1, 2, 2, 2, 2], 'resblock_n': [2, 2, 4, 4, 4], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'vq_n_embed': 8192, 'vq_beta': 0.25}, 'image_decoder': {'out_channels': 1, 'conv_channels': [256, 256, 128, 64, 32], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [4, 4, 4, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'deep_supervision': True, 'focal_mode': 'focal_mix'}, 'segmentor': {'in_channels': 1, 'num_classes': 2, 'conv_channels': [256, 256, 128, 64, 32], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [4, 4, 4, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'latent_space_dim': 3, 'deep_supervision': True}, 'discriminator': {'in_channels': 1, 'ndf': 32, 'hyper_conv_dim': 16, 'style_dim': 6, 'layer_scale_init_value': 1e-06, 'n_layers': 3, 'kw': 4, 'padw': 1}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True}, '3d': {'data_identifier': 'nnSeq2SeqPlans_3d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 1, 'patch_size': [10, 192, 192], 'median_image_size_in_voxels': [29.0, 515.0, 560.0], 'spacing': [4.400000095367432, 0.4296875, 0.4296875], 'normalization_schemes': ['Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization', 'Rescale0_995to01Normalization'], 'use_mask_for_norm': [False, False, False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'nnseq2seq.networks.seq2seq.seq2seq.Seq2Seq3d', 'arch_kwargs': {'image_encoder': {'in_channels': 1, 'conv_channels': [16, 32, 64, 128, 256], 'conv_kernel': [3, 2, 2, 2, 2], 'conv_stride': [1, 2, 2, 2, 2], 'resblock_n': [0, 1, 2, 2, 2], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'vq_n_embed': 8192, 'vq_beta': 0.25}, 'image_decoder': {'out_channels': 1, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'hyper_conv_dim': 16, 'latent_space_dim': 3, 'style_dim': 6, 'deep_supervision': True, 'focal_mode': 'focal_mix'}, 'segmentor': {'in_channels': 1, 'num_classes': 2, 'conv_channels': [256, 128, 64, 32, 16], 'conv_kernel': [3, 3, 3, 3, 3], 'conv_stride': [2, 2, 2, 2, 1], 'resblock_n': [2, 2, 2, 1, 0], 'resblock_kernel': [3, 3, 3, 3, 3], 'resblock_padding': [1, 1, 1, 1, 1], 'layer_scale_init_value': 1e-06, 'latent_space_dim': 3, 'deep_supervision': True}, 'discriminator': {'in_channels': 1, 'ndf': 16, 'hyper_conv_dim': 16, 'style_dim': 6, 'layer_scale_init_value': 1e-06, 'n_layers': 3, 'kw': 4, 'padw': 1}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False}}, 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 267.0, 'mean': 105.27149200439453, 'median': 105.0, 'min': 27.0, 'percentile_00_5': 61.0, 'percentile_99_5': 158.0, 'std': 18.445335388183594}, '1': {'max': 622.0, 'mean': 308.62164306640625, 'median': 313.0, 'min': 14.0, 'percentile_00_5': 129.0, 'percentile_99_5': 481.0, 'std': 61.370479583740234}, '2': {'max': 292.2086181640625, 'mean': 94.79603576660156, 'median': 90.01033782958984, 'min': 3.5035572052001953, 'percentile_00_5': 24.245834350585938, 'percentile_99_5': 184.52996826171875, 'std': 30.297283172607422}, '3': {'max': 607.82421875, 'mean': 256.9958801269531, 'median': 256.0714111328125, 'min': 21.118223190307617, 'percentile_00_5': 48.9947395324707, 'percentile_99_5': 449.9946594238281, 'std': 68.48628234863281}, '4': {'max': 782.535400390625, 'mean': 81.82330322265625, 'median': 33.67308044433594, 'min': 8.940948486328125, 'percentile_00_5': 10.96875, 'percentile_99_5': 506.26910400390625, 'std': 113.0}, '5': {'max': 4095.0, 'mean': 1518.48828125, 'median': 1545.581787109375, 'min': 0.0, 'percentile_00_5': 4.1741180419921875, 'percentile_99_5': 3541.29931640625, 'std': 716.7125854492188}}}",
    "preprocessed_dataset_folder": "C:\\Users\\P095789\\OneDrive - Amsterdam UMC\\Documenten\\mri_seq2seq-main\\nnSeq2Seq_preprocessed\\Dataset520_NeckTumour\\nnSeq2SeqPlans_3d",
    "preprocessed_dataset_folder_base": "C:\\Users\\P095789\\OneDrive - Amsterdam UMC\\Documenten\\mri_seq2seq-main\\nnSeq2Seq_preprocessed\\Dataset520_NeckTumour",
    "save_every": "50",
    "seg_loss": "None",
    "tgt_seq_pool": "None",
    "torch_version": "2.6.0+cpu",
    "train_segmentation_only": "False",
    "train_translation_only": "True",
    "unpack_dataset": "True",
    "was_initialized": "True",
    "weight_decay": "0.05"
}